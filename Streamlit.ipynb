{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSpIkIStCYP/k0ez8H47LX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/springboardmentor345a-create/Projects_2/blob/Harshdeep-Singh/Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "060dc9a7",
        "outputId": "c19eadaf-ff1a-40fe-cc57-d094cfe239fd"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Upload the .pkl model files from your local machine\n",
        "uploaded = files.upload()\n",
        "\n",
        "# You can verify the uploaded files by listing the current directory content\n",
        "print(\"Files uploaded:\", uploaded.keys())\n",
        "print(\"Files in current directory:\", os.listdir('.'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3bda5ce4-ddd6-4cfb-bcbf-15239f186dea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3bda5ce4-ddd6-4cfb-bcbf-15239f186dea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving To predict total points team can score.pkl to To predict total points team can score.pkl\n",
            "Saving team league winner or not_LogisticRegression.pkl to team league winner or not_LogisticRegression.pkl\n",
            "Saving Match winner.pkl to Match winner.pkl\n",
            "Saving Goals_Assist_model.pkl to Goals_Assist_model.pkl\n",
            "Files uploaded: dict_keys(['To predict total points team can score.pkl', 'team league winner or not_LogisticRegression.pkl', 'Match winner.pkl', 'Goals_Assist_model.pkl'])\n",
            "Files in current directory: ['.config', 'To predict total points team can score.pkl', 'Match winner.pkl', 'team league winner or not_LogisticRegression.pkl', 'Goals_Assist_model.pkl', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13132f38",
        "outputId": "7c257c75-615b-4d9b-f50b-d032bbbec3ff"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea9520cb",
        "outputId": "5b49d81d-6ffd-403c-adcf-9fe0f1ed29fb"
      },
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "st.set_page_config(page_title=\"EPL Predictions Hub\", layout=\"wide\")\n",
        "\n",
        "# Function to safely load a model\n",
        "def load_model(filepath):\n",
        "    if os.path.exists(filepath):\n",
        "        try:\n",
        "            with open(filepath, 'rb') as f:\n",
        "                model = pickle.load(f)\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error loading model {filepath}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        st.warning(f\"Model file not found: {filepath}\")\n",
        "        return None\n",
        "\n",
        "# --- Main Home Page ---\n",
        "def home_page():\n",
        "    st.title(\"‚öΩ EPL Predictions Hub\")\n",
        "    st.markdown(\"\"\"\n",
        "    Welcome to the English Premier League (EPL) Prediction application.\n",
        "    Use the sidebar navigation to access different prediction models:\n",
        "    - **Match Winner:** Predicts the outcome of a single match.\n",
        "    - **Total Team Points:** Estimates total points a team can score in a season.\n",
        "    - **Team League Winner:** Predicts if a team will win the league title.\n",
        "    - **Goals & Assists:** Predicts player performance metrics.\n",
        "    \"\"\")\n",
        "\n",
        "# --- Model 1: Match Winner Prediction ---\n",
        "def match_winner_page():\n",
        "    st.title(\"üèÜ Match Winner Prediction\")\n",
        "    st.markdown(\"Enter team and performance statistics to predict a match outcome.\")\n",
        "\n",
        "    # Load Model (place this inside function for single-file app structure)\n",
        "    model = load_model('Match winner.pkl')\n",
        "    if model is None:\n",
        "        st.stop()\n",
        "\n",
        "    with st.form(\"match_winner_form\"):\n",
        "        col1, col2 = st.columns(2)\n",
        "        with col1:\n",
        "            home_team = st.text_input(\"Home Team\", \"Arsenal\")\n",
        "            ht_form_pts = st.number_input(\"Home Team Form Pts (HTFormPts)\", min_value=0, value=7)\n",
        "            ht_gd = st.number_input(\"Home Team Goal Difference (HTGD)\", value=2)\n",
        "            diff_pts = st.number_input(\"Points Difference (DiffPts)\", value=3)\n",
        "\n",
        "        with col2:\n",
        "            away_team = st.text_input(\"Away Team\", \"Man United\")\n",
        "            at_form_pts = st.number_input(\"Away Team Form Pts (ATFormPts)\", min_value=0, value=5)\n",
        "            at_gd = st.number_input(\"Away Team Goal Difference (ATGD)\", value=-1)\n",
        "            diff_form_pts = st.number_input(\"Form Points Difference (DiffFormPts)\", value=2)\n",
        "\n",
        "        submitted = st.form_submit_button(\"Predict Match Winner\")\n",
        "\n",
        "    if submitted:\n",
        "        input_data = pd.DataFrame([{\n",
        "            \"HomeTeam\": home_team,\n",
        "            \"AwayTeam\": away_team,\n",
        "            \"HTFormPts\": ht_form_pts,\n",
        "            \"ATFormPts\": at_form_pts,\n",
        "            \"HTGD\": ht_gd,\n",
        "            \"ATGD\": at_gd,\n",
        "            \"DiffPts\": diff_pts,\n",
        "            \"DiffFormPts\": diff_form_pts\n",
        "        }])\n",
        "\n",
        "        # Note: Your model might expect features in a specific order or format (e.g., one-hot encoded teams).\n",
        "        # This example assumes numerical features can be passed directly to the model's predict method.\n",
        "        try:\n",
        "            # Drop string columns before prediction if the model only takes numerical inputs\n",
        "            features_for_pred = input_data.drop(columns=['HomeTeam', 'AwayTeam'])\n",
        "            prediction = model.predict(features_for_pred)\n",
        "            st.success(f\"Prediction: {prediction[0]}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred during prediction. Check your model's expected input format. Error: {e}\")\n",
        "\n",
        "# --- Model 2: To predict total points team can score ---\n",
        "def total_points_page():\n",
        "    st.title(\"üìä Total Team Points Prediction\")\n",
        "    st.markdown(\"Predict the total points a team can score in a season based on performance metrics.\")\n",
        "\n",
        "    model_path = 'To predict total points team can score.pkl'\n",
        "    model = load_model(model_path)\n",
        "    if model is None:\n",
        "        st.stop()\n",
        "\n",
        "    with st.form(\"total_points_form\"):\n",
        "        matches_played = st.number_input(\"Matches Played\", min_value=0, value=38)\n",
        "        goals_scored = st.number_input(\"Goals Scored\", min_value=0, value=75)\n",
        "        goals_conceded = st.number_input(\"Goals Conceded\", min_value=0, value=35)\n",
        "\n",
        "        submitted = st.form_submit_button(\"Predict Total Points\")\n",
        "\n",
        "    if submitted:\n",
        "        input_data = pd.DataFrame([{\n",
        "            'matches_played': matches_played,\n",
        "            'goals_scored': goals_scored,\n",
        "            'goals_conceded': goals_conceded\n",
        "        }])\n",
        "        try:\n",
        "            prediction = model.predict(input_data)\n",
        "            st.success(f\"Predicted Total Points: {prediction[0]:.2f}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred during prediction: {e}\")\n",
        "\n",
        "# --- Model 3: Team league winner or not_LogisticRegression ---\n",
        "def league_winner_page():\n",
        "    st.title(\"üèÜ League Winner Prediction\")\n",
        "    st.markdown(\"Predict whether a team will win the league title using performance stats and target points.\")\n",
        "\n",
        "    model_path = 'team league winner or not_LogisticRegression.pkl'\n",
        "    model = load_model(model_path)\n",
        "    if model is None:\n",
        "        st.stop()\n",
        "\n",
        "    with st.form(\"league_winner_form\"):\n",
        "        matches_played = st.number_input(\"Matches Played\", min_value=0, value=38)\n",
        "        goals_scored = st.number_input(\"Goals Scored\", min_value=0, value=80)\n",
        "        goals_conceded = st.number_input(\"Goals Conceded\", min_value=0, value=30)\n",
        "        target_total_points = st.number_input(\"Target Total Points\", min_value=0, value=90)\n",
        "\n",
        "        submitted = st.form_submit_button(\"Predict League Winner\")\n",
        "\n",
        "    if submitted:\n",
        "        input_data = pd.DataFrame([{\n",
        "            'matches_played': matches_played,\n",
        "            'goals_scored': goals_scored,\n",
        "            'goals_conceded': goals_conceded,\n",
        "            'target_total_points': target_total_points\n",
        "        }])\n",
        "        try:\n",
        "            prediction = model.predict(input_data)\n",
        "            prediction_proba = model.predict_proba(input_data)\n",
        "            result = \"Yes, likely to win the league\" if prediction[0] == 1 else \"No, unlikely to win the league\"\n",
        "            st.success(f\"Prediction: {result}\")\n",
        "            st.info(f\"Confidence Score (Probability of Winning): {prediction_proba[0][1]:.2%}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred during prediction: {e}\")\n",
        "\n",
        "# --- Model 4: Goals_Assist_model ---\n",
        "def goals_assists_page():\n",
        "    st.title(\"‚öΩ Player Goals & Assists Prediction\")\n",
        "    st.markdown(\"Predict player performance (goals/assists) per 90 minutes using player metrics.\")\n",
        "\n",
        "    model_path = 'Goals_Assist_model.pkl'\n",
        "    model = load_model(model_path)\n",
        "    if model is None:\n",
        "        st.stop()\n",
        "\n",
        "    st.warning(\"Note: This model requires numeric inputs corresponding to complex per-90 stats. The exact output (goals? assists?) depends on how the model was trained.\")\n",
        "\n",
        "    with st.form(\"goals_assists_form\"):\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            position = st.selectbox(\"Position\", [\"DF\", \"FW\", \"MF\", \"GK\"])\n",
        "            matches_played = st.number_input(\"Matches Played\", min_value=0, value=31)\n",
        "            minutes = st.number_input(\"Minutes Played\", min_value=0, value=2560)\n",
        "            goals_per_90 = st.number_input(\"Goals Per 90\", min_value=0.0, value=0.04, step=0.01)\n",
        "            non_penalty_goals_per_90 = st.number_input(\"Non-Penalty Goals Per 90\", min_value=0.0, value=0.40, step=0.01)\n",
        "\n",
        "        with col2:\n",
        "            age = st.number_input(\"Age\", min_value=16, max_value=45, value=25)\n",
        "            starts = st.number_input(\"Starts\", min_value=0, value=30)\n",
        "            ninetys_played = st.number_input(\"90s Played\", min_value=0.0, value=28.4, step=0.1)\n",
        "            assists_per_90 = st.number_input(\"Assists Per 90\", min_value=0.0, value=0.04, step=0.01)\n",
        "            xg_per_90 = st.number_input(\"xG Per 90\", min_value=0.0, value=0.06, step=0.01)\n",
        "\n",
        "        with col3:\n",
        "            # Empty column 3 for spacing\n",
        "            st.markdown(\"### xAG & npxG\")\n",
        "            xag_per_90 = st.number_input(\"xAG Per 90\", min_value=0.0, value=0.03, step=0.01)\n",
        "            npxg_per_90 = st.number_input(\"npxG Per 90\", min_value=0.0, value=0.06, step=0.01)\n",
        "\n",
        "\n",
        "        submitted = st.form_submit_button(\"Predict Player Performance\")\n",
        "\n",
        "    if submitted:\n",
        "        # Need to one-hot encode the 'Position' feature before passing to the model\n",
        "        input_data = pd.DataFrame([{\n",
        "            \"Position\": position,\n",
        "            \"Age\": age,\n",
        "            \"Matches Played\": matches_played,\n",
        "            \"Starts\": starts,\n",
        "            \"Minutes\": minutes,\n",
        "            \"90s Played\": ninetys_played,\n",
        "            \"Goals Per 90\": goals_per_90,\n",
        "            \"Assists Per 90\": assists_per_90,\n",
        "            \"Non-Penalty Goals Per 90\": non_penalty_goals_per_90,\n",
        "            \"xG Per 90\": xg_per_90,\n",
        "            \"xAG Per 90\": xag_per_90,\n",
        "            \"npxG Per 90\": npxg_per_90\n",
        "        }])\n",
        "\n",
        "        # Example of simple one-hot encoding for position for prediction\n",
        "        # (You must ensure this matches how the model was trained)\n",
        "        positions_df = pd.get_dummies(input_data['Position'], prefix='Position')\n",
        "        input_data = pd.concat([input_data.drop('Position', axis=1), positions_df], axis=1)\n",
        "\n",
        "        # Ensure all possible position columns exist with 0 if not present in the input row\n",
        "        all_positions = ['Position_DF', 'Position_FW', 'Position_MF', 'Position_GK']\n",
        "        for pos_col in all_positions:\n",
        "            if pos_col not in input_data.columns:\n",
        "                input_data[pos_col] = 0\n",
        "\n",
        "        try:\n",
        "            # Reorder columns to match the training order if necessary (highly likely)\n",
        "            # You might need to adjust this part to match your model's exact input requirement\n",
        "            input_data = input_data[\n",
        "                ['Age', 'Matches Played', 'Starts', 'Minutes', '90s Played',\n",
        "                 'Goals Per 90', 'Assists Per 90', 'Non-Penalty Goals Per 90',\n",
        "                 'xG Per 90', 'xAG Per 90', 'npxG Per 90',\n",
        "                 'Position_DF', 'Position_FW', 'Position_MF', 'Position_GK']\n",
        "            ]\n",
        "\n",
        "            prediction = model.predict(input_data)\n",
        "            st.success(f\"Predicted Output (Goals/Assists depending on model): {prediction[0]:.2f}\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"An error occurred during prediction. Check your model's expected input format/encoding. Error: {e}\")\n",
        "\n",
        "# --- Navigation Setup (Sidebar) ---\n",
        "st.sidebar.title(\"Navigation\")\n",
        "page = st.sidebar.radio(\"Go to\", [\"Home\", \"Match Winner\", \"Total Team Points\", \"League Winner\", \"Goals & Assists Model\"])\n",
        "\n",
        "if page == \"Home\":\n",
        "    home_page()\n",
        "elif page == \"Match Winner\":\n",
        "    match_winner_page()\n",
        "elif page == \"Total Team Points\":\n",
        "    total_points_page()\n",
        "elif page == \"League Winner\":\n",
        "    league_winner_page()\n",
        "elif page == \"Goals & Assists Model\":\n",
        "    goals_assists_page()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb64d93a",
        "outputId": "9a9d0fd8-c3be-43d4-a464-578a9277c77b"
      },
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20G\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.127.3.213:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}