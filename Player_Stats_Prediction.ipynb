{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# EPL Player Stats Prediction (Goals & Assists)\n",
                "\n",
                "This notebook predicts player performance metrics including goals, assists, and identifies top performers in the English Premier League.\n",
                "\n",
                "**Prediction Targets**:\n",
                "- Total Goals (regression)\n",
                "- Total Assists (regression)\n",
                "- Top Scorer Classification (>15 goals)\n",
                "- Top Assister Classification (>10 assists)\n",
                "\n",
                "**Dataset**: Goals & Assist.xlsx (2,274 players with 34 features)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data manipulation\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Machine Learning\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
                "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
                "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "\n",
                "# XGBoost\n",
                "try:\n",
                "    import xgboost as xgb\n",
                "    xgb_available = True\n",
                "except ImportError:\n",
                "    xgb_available = False\n",
                "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
                "\n",
                "# Settings\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "RANDOM_STATE = 42\n",
                "np.random.seed(RANDOM_STATE)\n",
                "\n",
                "# Set visualization style\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "\n",
                "print(\"‚úì Libraries imported successfully!\")\n",
                "print(f\"‚úì Random seed set to {RANDOM_STATE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load and Explore Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" LOADING AND EXPLORING DATASET\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Load the dataset\n",
                "df = pd.read_excel('../Data/Goals & Assist.xlsx')\n",
                "\n",
                "print(f\"\\n‚úì Dataset loaded successfully!\")\n",
                "print(f\"  Shape: {df.shape[0]:,} players √ó {df.shape[1]} features\")\n",
                "print(f\"\\n{df.head(10)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset info\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\" DATASET INFORMATION\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "print(f\"\\nColumns ({len(df.columns)}):\")\n",
                "for i, col in enumerate(df.columns, 1):\n",
                "    dtype = df[col].dtype\n",
                "    unique = df[col].nunique()\n",
                "    print(f\"  {i:2d}. {col:40s} [{dtype}] - {unique} unique values\")\n",
                "\n",
                "print(f\"\\n\\nData Types:\\n{df.dtypes.value_counts()}\")\n",
                "print(f\"\\n\\nMissing Values: {df.isnull().sum().sum()} total\")\n",
                "\n",
                "if df.isnull().sum().sum() > 0:\n",
                "    print(f\"\\nColumns with missing values:\")\n",
                "    missing = df.isnull().sum()\n",
                "    print(missing[missing > 0])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Statistical summary\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\" STATISTICAL SUMMARY\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "print(\"\\nNumerical Features Summary:\")\n",
                "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
                "print(df[numerical_cols].describe().T)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Cleaning and Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" DATA CLEANING\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Remove unnecessary columns\n",
                "if 'Unnamed: 0' in df.columns:\n",
                "    df = df.drop('Unnamed: 0', axis=1)\n",
                "    print(\"\\n‚úì Removed 'Unnamed: 0' column\")\n",
                "\n",
                "# Check for duplicate rows\n",
                "duplicates = df.duplicated().sum()\n",
                "print(f\"\\n‚úì Duplicate rows: {duplicates}\")\n",
                "\n",
                "if duplicates > 0:\n",
                "    df = df.drop_duplicates()\n",
                "    print(f\"  Removed {duplicates} duplicate rows\")\n",
                "\n",
                "# Filter players with minimal playing time (less than 5 matches)\n",
                "if 'Matches Played' in df.columns:\n",
                "    initial_count = len(df)\n",
                "    df = df[df['Matches Played'] >= 5]\n",
                "    removed = initial_count - len(df)\n",
                "    print(f\"\\n‚úì Removed {removed} players with < 5 matches played\")\n",
                "\n",
                "# Fill missing values with 0 (missing means no activity)\n",
                "df = df.fillna(0)\n",
                "print(f\"\\n‚úì Missing values handled\")\n",
                "\n",
                "print(f\"\\n‚úì Clean dataset shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Target Variables Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" TARGET VARIABLES ANALYSIS\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Analyze Goals and Assists\n",
                "if 'Goals' in df.columns and 'Assists' in df.columns:\n",
                "    print(\"\\nGoals Statistics:\")\n",
                "    print(f\"  Mean: {df['Goals'].mean():.2f}\")\n",
                "    print(f\"  Median: {df['Goals'].median():.0f}\")\n",
                "    print(f\"  Max: {df['Goals'].max():.0f}\")\n",
                "    print(f\"  Players with 15+ goals: {(df['Goals'] >= 15).sum()}\")\n",
                "    \n",
                "    print(\"\\nAssists Statistics:\")\n",
                "    print(f\"  Mean: {df['Assists'].mean():.2f}\")\n",
                "    print(f\"  Median: {df['Assists'].median():.0f}\")\n",
                "    print(f\"  Max: {df['Assists'].max():.0f}\")\n",
                "    print(f\"  Players with 10+ assists: {(df['Assists'] >= 10).sum()}\")\n",
                "    \n",
                "    # Top scorers\n",
                "    print(\"\\nTop 10 Goal Scorers:\")\n",
                "    if 'Player' in df.columns:\n",
                "        top_scorers = df.nlargest(10, 'Goals')[['Player', 'Goals', 'Assists']]\n",
                "        print(top_scorers.to_string(index=False))\n",
                "    \n",
                "    # Top assisters\n",
                "    print(\"\\nTop 10 Assist Providers:\")\n",
                "    if 'Player' in df.columns:\n",
                "        top_assisters = df.nlargest(10, 'Assists')[['Player', 'Goals', 'Assists']]\n",
                "        print(top_assisters.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize Goals and Assists distribution\n",
                "if 'Goals' in df.columns and 'Assists' in df.columns:\n",
                "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "    \n",
                "    # Goals distribution\n",
                "    axes[0, 0].hist(df['Goals'], bins=30, color='#2ecc71', alpha=0.7, edgecolor='black')\n",
                "    axes[0, 0].set_title('Goals Distribution', fontsize=12, fontweight='bold')\n",
                "    axes[0, 0].set_xlabel('Goals', fontsize=10)\n",
                "    axes[0, 0].set_ylabel('Number of Players', fontsize=10)\n",
                "    axes[0, 0].axvline(df['Goals'].mean(), color='red', linestyle='--', \n",
                "                       label=f'Mean: {df[\"Goals\"].mean():.2f}')\n",
                "    axes[0, 0].legend()\n",
                "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    # Assists distribution\n",
                "    axes[0, 1].hist(df['Assists'], bins=30, color='#3498db', alpha=0.7, edgecolor='black')\n",
                "    axes[0, 1].set_title('Assists Distribution', fontsize=12, fontweight='bold')\n",
                "    axes[0, 1].set_xlabel('Assists', fontsize=10)\n",
                "    axes[0, 1].set_ylabel('Number of Players', fontsize=10)\n",
                "    axes[0, 1].axvline(df['Assists'].mean(), color='red', linestyle='--',\n",
                "                       label=f'Mean: {df[\"Assists\"].mean():.2f}')\n",
                "    axes[0, 1].legend()\n",
                "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    # Goals vs Assists scatter\n",
                "    axes[1, 0].scatter(df['Goals'], df['Assists'], alpha=0.5, color='#9b59b6')\n",
                "    axes[1, 0].set_title('Goals vs Assists', fontsize=12, fontweight='bold')\n",
                "    axes[1, 0].set_xlabel('Goals', fontsize=10)\n",
                "    axes[1, 0].set_ylabel('Assists', fontsize=10)\n",
                "    axes[1, 0].grid(alpha=0.3)\n",
                "    \n",
                "    # Combined Goals + Assists\n",
                "    df['Goals_Plus_Assists'] = df['Goals'] + df['Assists']\n",
                "    axes[1, 1].hist(df['Goals_Plus_Assists'], bins=30, color='#e74c3c', alpha=0.7, edgecolor='black')\n",
                "    axes[1, 1].set_title('Goals + Assists Distribution', fontsize=12, fontweight='bold')\n",
                "    axes[1, 1].set_xlabel('Goals + Assists', fontsize=10)\n",
                "    axes[1, 1].set_ylabel('Number of Players', fontsize=10)\n",
                "    axes[1, 1].grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Performance by Position"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\" PERFORMANCE BY POSITION\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "if 'Position' in df.columns:\n",
                "    print(\"\\nPlayers by Position:\")\n",
                "    print(df['Position'].value_counts())\n",
                "    \n",
                "    print(\"\\nAverage Stats by Position:\")\n",
                "    position_stats = df.groupby('Position')[['Goals', 'Assists', 'Minutes']].mean()\n",
                "    print(position_stats.round(2))\n",
                "    \n",
                "    # Visualize\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "    \n",
                "    # Goals by position\n",
                "    position_goals = df.groupby('Position')['Goals'].mean().sort_values(ascending=False)\n",
                "    axes[0].bar(range(len(position_goals)), position_goals.values, \n",
                "               color='#2ecc71', alpha=0.8)\n",
                "    axes[0].set_xticks(range(len(position_goals)))\n",
                "    axes[0].set_xticklabels(position_goals.index, rotation=45, ha='right')\n",
                "    axes[0].set_title('Average Goals by Position', fontsize=12, fontweight='bold')\n",
                "    axes[0].set_ylabel('Average Goals', fontsize=10)\n",
                "    axes[0].grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    # Assists by position\n",
                "    position_assists = df.groupby('Position')['Assists'].mean().sort_values(ascending=False)\n",
                "    axes[1].bar(range(len(position_assists)), position_assists.values,\n",
                "               color='#3498db', alpha=0.8)\n",
                "    axes[1].set_xticks(range(len(position_assists)))\n",
                "    axes[1].set_xticklabels(position_assists.index, rotation=45, ha='right')\n",
                "    axes[1].set_title('Average Assists by Position', fontsize=12, fontweight='bold')\n",
                "    axes[1].set_ylabel('Average Assists', fontsize=10)\n",
                "    axes[1].grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 Age Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\" AGE ANALYSIS\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "if 'Age' in df.columns:\n",
                "    print(f\"\\nAge Statistics:\")\n",
                "    print(f\"  Mean age: {df['Age'].mean():.1f} years\")\n",
                "    print(f\"  Median age: {df['Age'].median():.0f} years\")\n",
                "    print(f\"  Age range: {df['Age'].min():.0f} - {df['Age'].max():.0f} years\")\n",
                "    \n",
                "    # Age vs Performance\n",
                "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "    \n",
                "    # Age vs Goals\n",
                "    axes[0].scatter(df['Age'], df['Goals'], alpha=0.5, color='#2ecc71')\n",
                "    axes[0].set_title('Age vs Goals', fontsize=12, fontweight='bold')\n",
                "    axes[0].set_xlabel('Age', fontsize=10)\n",
                "    axes[0].set_ylabel('Goals', fontsize=10)\n",
                "    axes[0].grid(alpha=0.3)\n",
                "    \n",
                "    # Age vs Assists\n",
                "    axes[1].scatter(df['Age'], df['Assists'], alpha=0.5, color='#3498db')\n",
                "    axes[1].set_title('Age vs Assists', fontsize=12, fontweight='bold')\n",
                "    axes[1].set_xlabel('Age', fontsize=10)\n",
                "    axes[1].set_ylabel('Assists', fontsize=10)\n",
                "    axes[1].grid(alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.4 Expected Goals (xG) Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\" EXPECTED GOALS (xG) ANALYSIS\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Find xG columns\n",
                "xg_cols = [col for col in df.columns if 'xG' in col or 'xAG' in col]\n",
                "\n",
                "if len(xg_cols) > 0:\n",
                "    print(f\"\\nExpected metrics available: {xg_cols}\")\n",
                "    \n",
                "    # Check if xG Per 90 exists\n",
                "    if 'xG Per 90' in df.columns and 'Goals Per 90' in df.columns:\n",
                "        # xG vs Actual Goals correlation\n",
                "        correlation = df['xG Per 90'].corr(df['Goals Per 90'])\n",
                "        print(f\"\\nCorrelation between xG Per 90 and Goals Per 90: {correlation:.3f}\")\n",
                "        \n",
                "        # Visualize xG vs Actual Goals\n",
                "        plt.figure(figsize=(10, 6))\n",
                "        plt.scatter(df['xG Per 90'], df['Goals Per 90'], alpha=0.5, color='#9b59b6')\n",
                "        plt.plot([0, df['xG Per 90'].max()], [0, df['xG Per 90'].max()], \n",
                "                'r--', label='Perfect prediction line')\n",
                "        plt.title('Expected Goals vs Actual Goals (Per 90 Minutes)', \n",
                "                 fontsize=14, fontweight='bold')\n",
                "        plt.xlabel('xG Per 90', fontsize=12)\n",
                "        plt.ylabel('Goals Per 90', fontsize=12)\n",
                "        plt.legend()\n",
                "        plt.grid(alpha=0.3)\n",
                "        plt.tight_layout()\n",
                "        plt.show()\n",
                "        \n",
                "        # Find overperformers and underperformers\n",
                "        df['xG_Difference'] = df['Goals Per 90'] - df['xG Per 90']\n",
                "        \n",
                "        print(\"\\nTop 5 Overperformers (Goals > xG):\")\n",
                "        if 'Player' in df.columns:\n",
                "            overperformers = df.nlargest(5, 'xG_Difference')[['Player', 'Goals Per 90', 'xG Per 90', 'xG_Difference']]\n",
                "            print(overperformers.to_string(index=False))\n",
                "        \n",
                "        print(\"\\nTop 5 Underperformers (xG > Goals):\")\n",
                "        if 'Player' in df.columns:\n",
                "            underperformers = df.nsmallest(5, 'xG_Difference')[['Player', 'Goals Per 90', 'xG Per 90', 'xG_Difference']]\n",
                "            print(underperformers.to_string(index=False))\n",
                "else:\n",
                "    print(\"\\n‚ö† No xG metrics found in dataset\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.5 Correlation Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\" CORRELATION ANALYSIS\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Select important numerical features\n",
                "important_features = ['Age', 'Matches Played', 'Starts', 'Minutes', '90s Played',\n",
                "                     'Goals', 'Assists', 'Goals Per 90', 'Assists Per 90']\n",
                "available_features = [f for f in important_features if f in df.columns]\n",
                "\n",
                "if len(available_features) > 3:\n",
                "    correlation_matrix = df[available_features].corr()\n",
                "    \n",
                "    plt.figure(figsize=(12, 10))\n",
                "    sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
                "                center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
                "    plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold', pad=20)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    print(\"\\n‚úì Correlation analysis complete\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" FEATURE ENGINEERING\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Create a copy for feature engineering\n",
                "df_model = df.copy()\n",
                "\n",
                "# Encode Position\n",
                "if 'Position' in df_model.columns:\n",
                "    le_position = LabelEncoder()\n",
                "    df_model['Position_Encoded'] = le_position.fit_transform(df_model['Position'])\n",
                "    print(\"\\n‚úì Encoded Position\")\n",
                "\n",
                "# Create efficiency metrics\n",
                "if 'Goals' in df_model.columns and 'Minutes' in df_model.columns:\n",
                "    df_model['Goals_Per_Minute'] = df_model['Goals'] / (df_model['Minutes'] + 1)\n",
                "    print(\"‚úì Created Goals_Per_Minute feature\")\n",
                "\n",
                "if 'Assists' in df_model.columns and 'Minutes' in df_model.columns:\n",
                "    df_model['Assists_Per_Minute'] = df_model['Assists'] / (df_model['Minutes'] + 1)\n",
                "    print(\"‚úì Created Assists_Per_Minute feature\")\n",
                "\n",
                "# Create age categories\n",
                "if 'Age' in df_model.columns:\n",
                "    df_model['Age_Category'] = pd.cut(df_model['Age'], \n",
                "                                      bins=[0, 23, 28, 100],\n",
                "                                      labels=[0, 1, 2])  # 0=Young, 1=Prime, 2=Veteran\n",
                "    df_model['Age_Category'] = df_model['Age_Category'].astype(int)\n",
                "    print(\"‚úì Created Age_Category feature (0=Young, 1=Prime, 2=Veteran)\")\n",
                "\n",
                "# Create playing time ratio\n",
                "if 'Starts' in df_model.columns and 'Matches Played' in df_model.columns:\n",
                "    df_model['Starting_Ratio'] = df_model['Starts'] / (df_model['Matches Played'] + 1)\n",
                "    print(\"‚úì Created Starting_Ratio feature\")\n",
                "\n",
                "# Create productivity score\n",
                "if 'Goals' in df_model.columns and 'Assists' in df_model.columns and '90s Played' in df_model.columns:\n",
                "    df_model['Productivity_Score'] = (df_model['Goals'] + df_model['Assists']) / (df_model['90s Played'] + 1)\n",
                "    print(\"‚úì Created Productivity_Score feature\")\n",
                "\n",
                "# Create target variables for classification\n",
                "if 'Goals' in df_model.columns:\n",
                "    df_model['Top_Scorer'] = (df_model['Goals'] >= 15).astype(int)\n",
                "    print(\"‚úì Created Top_Scorer binary target (15+ goals)\")\n",
                "\n",
                "if 'Assists' in df_model.columns:\n",
                "    df_model['Top_Assister'] = (df_model['Assists'] >= 10).astype(int)\n",
                "    print(\"‚úì Created Top_Assister binary target (10+ assists)\")\n",
                "\n",
                "print(f\"\\n‚úì Feature engineering complete\")\n",
                "print(f\"  New dataset shape: {df_model.shape[0]:,} rows √ó {df_model.shape[1]} columns\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Prepare Data for Modeling"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" FEATURE SELECTION FOR MODELING\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Define feature columns (excluding target and non-predictive columns)\n",
                "exclude_cols = ['Player', 'Nation', 'Position', 'Goals', 'Assists', 'Top_Scorer', \n",
                "                'Top_Assister', 'Goals_Plus_Assists', 'xG_Difference',\n",
                "                'Goals Per 90', 'Assists Per 90']  # Exclude per 90 stats to avoid data leakage\n",
                "\n",
                "feature_cols = [col for col in df_model.columns if col not in exclude_cols]\n",
                "\n",
                "# Ensure all feature columns are numerical\n",
                "feature_cols = [col for col in feature_cols if df_model[col].dtype in ['int64', 'float64', 'int32', 'float32']]\n",
                "\n",
                "print(f\"\\nSelected {len(feature_cols)} features for modeling:\")\n",
                "for i, col in enumerate(feature_cols, 1):\n",
                "    print(f\"  {i:2d}. {col}\")\n",
                "\n",
                "# Prepare feature matrix\n",
                "X = df_model[feature_cols].copy()\n",
                "\n",
                "# Replace any inf values with 0\n",
                "X = X.replace([np.inf, -np.inf], 0)\n",
                "\n",
                "print(f\"\\n‚úì Feature matrix X shape: {X.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Goals Prediction (Regression)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.1 Prepare Data for Goals Prediction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" GOALS PREDICTION - DATA PREPARATION\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Target variable\n",
                "y_goals = df_model['Goals'].copy()\n",
                "\n",
                "print(f\"\\nTarget (Goals) statistics:\")\n",
                "print(f\"  Mean: {y_goals.mean():.2f}\")\n",
                "print(f\"  Std: {y_goals.std():.2f}\")\n",
                "print(f\"  Min: {y_goals.min():.0f}\")\n",
                "print(f\"  Max: {y_goals.max():.0f}\")\n",
                "\n",
                "# Train-test split\n",
                "X_train_goals, X_test_goals, y_train_goals, y_test_goals = train_test_split(\n",
                "    X, y_goals, test_size=0.2, random_state=RANDOM_STATE\n",
                ")\n",
                "\n",
                "print(f\"\\n‚úì Data split completed\")\n",
                "print(f\"  Training set: {X_train_goals.shape}\")\n",
                "print(f\"  Test set: {X_test_goals.shape}\")\n",
                "\n",
                "# Feature scaling\n",
                "scaler_goals = StandardScaler()\n",
                "X_train_goals_scaled = scaler_goals.fit_transform(X_train_goals)\n",
                "X_test_goals_scaled = scaler_goals.transform(X_test_goals)\n",
                "\n",
                "print(f\"\\n‚úì Features scaled\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 Train Goals Prediction Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\" TRAINING GOALS PREDICTION MODELS\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Linear Regression\n",
                "print(\"\\n1. Linear Regression:\")\n",
                "lr_goals = LinearRegression()\n",
                "lr_goals.fit(X_train_goals_scaled, y_train_goals)\n",
                "\n",
                "lr_goals_pred = lr_goals.predict(X_test_goals_scaled)\n",
                "lr_goals_mae = mean_absolute_error(y_test_goals, lr_goals_pred)\n",
                "lr_goals_rmse = np.sqrt(mean_squared_error(y_test_goals, lr_goals_pred))\n",
                "lr_goals_r2 = r2_score(y_test_goals, lr_goals_pred)\n",
                "\n",
                "print(f\"  MAE: {lr_goals_mae:.2f}\")\n",
                "print(f\"  RMSE: {lr_goals_rmse:.2f}\")\n",
                "print(f\"  R¬≤ Score: {lr_goals_r2:.4f}\")\n",
                "\n",
                "# Ridge Regression\n",
                "print(\"\\n2. Ridge Regression:\")\n",
                "ridge_goals = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
                "ridge_goals.fit(X_train_goals_scaled, y_train_goals)\n",
                "\n",
                "ridge_goals_pred = ridge_goals.predict(X_test_goals_scaled)\n",
                "ridge_goals_mae = mean_absolute_error(y_test_goals, ridge_goals_pred)\n",
                "ridge_goals_rmse = np.sqrt(mean_squared_error(y_test_goals, ridge_goals_pred))\n",
                "ridge_goals_r2 = r2_score(y_test_goals, ridge_goals_pred)\n",
                "\n",
                "print(f\"  MAE: {ridge_goals_mae:.2f}\")\n",
                "print(f\"  RMSE: {ridge_goals_rmse:.2f}\")\n",
                "print(f\"  R¬≤ Score: {ridge_goals_r2:.4f}\")\n",
                "\n",
                "# Random Forest Regressor\n",
                "print(\"\\n3. Random Forest Regressor:\")\n",
                "rf_goals = RandomForestRegressor(n_estimators=100, max_depth=10,\n",
                "                                random_state=RANDOM_STATE, n_jobs=-1)\n",
                "rf_goals.fit(X_train_goals, y_train_goals)\n",
                "\n",
                "rf_goals_pred = rf_goals.predict(X_test_goals)\n",
                "rf_goals_mae = mean_absolute_error(y_test_goals, rf_goals_pred)\n",
                "rf_goals_rmse = np.sqrt(mean_squared_error(y_test_goals, rf_goals_pred))\n",
                "rf_goals_r2 = r2_score(y_test_goals, rf_goals_pred)\n",
                "\n",
                "print(f\"  MAE: {rf_goals_mae:.2f}\")\n",
                "print(f\"  RMSE: {rf_goals_rmse:.2f}\")\n",
                "print(f\"  R¬≤ Score: {rf_goals_r2:.4f}\")\n",
                "\n",
                "# Gradient Boosting Regressor\n",
                "print(\"\\n4. Gradient Boosting Regressor:\")\n",
                "gb_goals = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1,\n",
                "                                     max_depth=5, random_state=RANDOM_STATE)\n",
                "gb_goals.fit(X_train_goals, y_train_goals)\n",
                "\n",
                "gb_goals_pred = gb_goals.predict(X_test_goals)\n",
                "gb_goals_mae = mean_absolute_error(y_test_goals, gb_goals_pred)\n",
                "gb_goals_rmse = np.sqrt(mean_squared_error(y_test_goals, gb_goals_pred))\n",
                "gb_goals_r2 = r2_score(y_test_goals, gb_goals_pred)\n",
                "\n",
                "print(f\"  MAE: {gb_goals_mae:.2f}\")\n",
                "print(f\"  RMSE: {gb_goals_rmse:.2f}\")\n",
                "print(f\"  R¬≤ Score: {gb_goals_r2:.4f}\")\n",
                "\n",
                "print(\"\\n‚úì Goals prediction models trained successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compare goals models\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\" GOALS PREDICTION - MODEL COMPARISON\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "goals_comparison = pd.DataFrame({\n",
                "    'Model': ['Linear Regression', 'Ridge Regression', 'Random Forest', 'Gradient Boosting'],\n",
                "    'MAE': [lr_goals_mae, ridge_goals_mae, rf_goals_mae, gb_goals_mae],\n",
                "    'RMSE': [lr_goals_rmse, ridge_goals_rmse, rf_goals_rmse, gb_goals_rmse],\n",
                "    'R¬≤ Score': [lr_goals_r2, ridge_goals_r2, rf_goals_r2, gb_goals_r2]\n",
                "}).sort_values('MAE')\n",
                "\n",
                "print(\"\\n\" + goals_comparison.to_string(index=False))\n",
                "\n",
                "best_goals_model = goals_comparison.iloc[0]['Model']\n",
                "print(f\"\\nüèÜ Best Goals Predictor: {best_goals_model}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Assists Prediction (Regression)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" ASSISTS PREDICTION\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Target variable\n",
                "y_assists = df_model['Assists'].copy()\n",
                "\n",
                "# Train-test split\n",
                "X_train_assists, X_test_assists, y_train_assists, y_test_assists = train_test_split(\n",
                "    X, y_assists, test_size=0.2, random_state=RANDOM_STATE\n",
                ")\n",
                "\n",
                "# Train Random Forest\n",
                "rf_assists = RandomForestRegressor(n_estimators=100, max_depth=10,\n",
                "                                  random_state=RANDOM_STATE, n_jobs=-1)\n",
                "rf_assists.fit(X_train_assists, y_train_assists)\n",
                "\n",
                "# Predictions and evaluation\n",
                "rf_assists_pred = rf_assists.predict(X_test_assists)\n",
                "rf_assists_mae = mean_absolute_error(y_test_assists, rf_assists_pred)\n",
                "rf_assists_rmse = np.sqrt(mean_squared_error(y_test_assists, rf_assists_pred))\n",
                "rf_assists_r2 = r2_score(y_test_assists, rf_assists_pred)\n",
                "\n",
                "print(f\"\\nRandom Forest - Assists Prediction:\")\n",
                "print(f\"  MAE: {rf_assists_mae:.2f}\")\n",
                "print(f\"  RMSE: {rf_assists_rmse:.2f}\")\n",
                "print(f\"  R¬≤ Score: {rf_assists_r2:.4f}\")\n",
                "\n",
                "print(\"\\n‚úì Assists prediction model trained successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Top Scorer Classification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" TOP SCORER CLASSIFICATION (15+ Goals)\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Target variable\n",
                "y_top_scorer = df_model['Top_Scorer'].copy()\n",
                "\n",
                "print(f\"\\nTarget distribution:\")\n",
                "print(y_top_scorer.value_counts())\n",
                "\n",
                "# Train-test split\n",
                "X_train_ts, X_test_ts, y_train_ts, y_test_ts = train_test_split(\n",
                "    X, y_top_scorer, test_size=0.2, random_state=RANDOM_STATE, stratify=y_top_scorer\n",
                ")\n",
                "\n",
                "# Train Random Forest Classifier\n",
                "rf_top_scorer = RandomForestClassifier(n_estimators=100, max_depth=10,\n",
                "                                       random_state=RANDOM_STATE, n_jobs=-1)\n",
                "rf_top_scorer.fit(X_train_ts, y_train_ts)\n",
                "\n",
                "# Predictions and evaluation\n",
                "rf_ts_pred = rf_top_scorer.predict(X_test_ts)\n",
                "rf_ts_acc = accuracy_score(y_test_ts, rf_ts_pred)\n",
                "\n",
                "print(f\"\\nRandom Forest - Top Scorer Classification:\")\n",
                "print(f\"  Accuracy: {rf_ts_acc:.4f} ({rf_ts_acc*100:.2f}%)\")\n",
                "\n",
                "print(f\"\\nClassification Report:\")\n",
                "print(classification_report(y_test_ts, rf_ts_pred, target_names=['Not Top Scorer', 'Top Scorer']))\n",
                "\n",
                "print(\"\\n‚úì Top scorer classification model trained successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Top Assister Classification"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" TOP ASSISTER CLASSIFICATION (10+ Assists)\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Target variable\n",
                "y_top_assister = df_model['Top_Assister'].copy()\n",
                "\n",
                "print(f\"\\nTarget distribution:\")\n",
                "print(y_top_assister.value_counts())\n",
                "\n",
                "# Train-test split\n",
                "X_train_ta, X_test_ta, y_train_ta, y_test_ta = train_test_split(\n",
                "    X, y_top_assister, test_size=0.2, random_state=RANDOM_STATE, stratify=y_top_assister\n",
                ")\n",
                "\n",
                "# Train Random Forest Classifier\n",
                "rf_top_assister = RandomForestClassifier(n_estimators=100, max_depth=10,\n",
                "                                         random_state=RANDOM_STATE, n_jobs=-1)\n",
                "rf_top_assister.fit(X_train_ta, y_train_ta)\n",
                "\n",
                "# Predictions and evaluation\n",
                "rf_ta_pred = rf_top_assister.predict(X_test_ta)\n",
                "rf_ta_acc = accuracy_score(y_test_ta, rf_ta_pred)\n",
                "\n",
                "print(f\"\\nRandom Forest - Top Assister Classification:\")\n",
                "print(f\"  Accuracy: {rf_ta_acc:.4f} ({rf_ta_acc*100:.2f}%)\")\n",
                "\n",
                "print(f\"\\nClassification Report:\")\n",
                "print(classification_report(y_test_ta, rf_ta_pred, target_names=['Not Top Assister', 'Top Assister']))\n",
                "\n",
                "print(\"\\n‚úì Top assister classification model trained successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Model Summary and Feature Importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" COMPREHENSIVE MODEL SUMMARY\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Create summary table\n",
                "summary = pd.DataFrame({\n",
                "    'Prediction Task': ['Goals (Regression)', 'Assists (Regression)', \n",
                "                       'Top Scorer (15+)', 'Top Assister (10+)'],\n",
                "    'Best Model': [best_goals_model, 'Random Forest', 'Random Forest', 'Random Forest'],\n",
                "    'Primary Metric': ['MAE', 'MAE', 'Accuracy', 'Accuracy'],\n",
                "    'Performance': [\n",
                "        f\"{goals_comparison.iloc[0]['MAE']:.2f}\",\n",
                "        f\"{rf_assists_mae:.2f}\",\n",
                "        f\"{rf_ts_acc:.3f}\",\n",
                "        f\"{rf_ta_acc:.3f}\"\n",
                "    ]\n",
                "})\n",
                "\n",
                "print(\"\\n\" + summary.to_string(index=False))\n",
                "\n",
                "print(\"\\n‚úÖ All player stats models trained and evaluated successfully!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance from goals prediction\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\" FEATURE IMPORTANCE (Goals Prediction)\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "feature_importance = pd.DataFrame({\n",
                "    'feature': feature_cols,\n",
                "    'importance': rf_goals.feature_importances_\n",
                "}).sort_values('importance', ascending=False)\n",
                "\n",
                "print(\"\\nTop 15 Most Important Features:\")\n",
                "print(feature_importance.head(15).to_string(index=False))\n",
                "\n",
                "# Visualize feature importance\n",
                "plt.figure(figsize=(12, 8))\n",
                "top_features = feature_importance.head(20)\n",
                "plt.barh(range(len(top_features)), top_features['importance'], color='#3498db', alpha=0.8)\n",
                "plt.yticks(range(len(top_features)), top_features['feature'])\n",
                "plt.xlabel('Importance', fontsize=12)\n",
                "plt.ylabel('Feature', fontsize=12)\n",
                "plt.title('Top 20 Feature Importances (Goals Prediction)', fontsize=14, fontweight='bold')\n",
                "plt.gca().invert_yaxis()\n",
                "plt.grid(axis='x', alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Sample Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" SAMPLE PREDICTIONS\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "# Get sample predictions on test set\n",
                "sample_size = 10\n",
                "sample_indices = X_test_goals.index[:sample_size]\n",
                "\n",
                "sample_predictions = pd.DataFrame({\n",
                "    'Actual Goals': y_test_goals.loc[sample_indices].values,\n",
                "    'Predicted Goals': np.round(rf_goals_pred[:sample_size], 1),\n",
                "    'Actual Assists': df_model.loc[sample_indices, 'Assists'].values,\n",
                "    'Predicted Assists': np.round(rf_assists.predict(X.loc[sample_indices]), 1)\n",
                "})\n",
                "\n",
                "sample_predictions['Goals Error'] = np.abs(sample_predictions['Actual Goals'] - sample_predictions['Predicted Goals'])\n",
                "\n",
                "print(\"\\nSample Predictions (First 10 test players):\")\n",
                "print(sample_predictions.to_string(index=False))\n",
                "\n",
                "print(f\"\\n‚úì Predictions generated successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Summary and Conclusions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\" SUMMARY AND CONCLUSIONS\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "print(\"\\nüìä Dataset Overview:\")\n",
                "print(f\"  - Total players analyzed: {len(df):,}\")\n",
                "print(f\"  - Players after filtering (5+ matches): {len(df_model):,}\")\n",
                "print(f\"  - Features engineered: {len(feature_cols)}\")\n",
                "print(f\"  - Positions covered: {df['Position'].nunique() if 'Position' in df.columns else 'N/A'}\")\n",
                "\n",
                "print(\"\\nüéØ Model Performance Summary:\")\n",
                "print(f\"  - Goals Prediction: MAE={goals_comparison.iloc[0]['MAE']:.2f} goals (Best: {best_goals_model})\")\n",
                "print(f\"  - Assists Prediction: MAE={rf_assists_mae:.2f} assists\")\n",
                "print(f\"  - Top Scorer Classification: {rf_ts_acc*100:.1f}% accuracy\")\n",
                "print(f\"  - Top Assister Classification: {rf_ta_acc*100:.1f}% accuracy\")\n",
                "\n",
                "print(\"\\nüí° Key Insights:\")\n",
                "top_3_features = feature_importance.head(3)['feature'].tolist()\n",
                "print(f\"  - Most important features: {', '.join(top_3_features)}\")\n",
                "print(f\"  - Average goals per player: {df['Goals'].mean():.2f}\")\n",
                "print(f\"  - Average assists per player: {df['Assists'].mean():.2f}\")\n",
                "if 'Position' in df.columns:\n",
                "    top_position = df.groupby('Position')['Goals'].mean().idxmax()\n",
                "    print(f\"  - Position with most goals: {top_position}\")\n",
                "\n",
                "print(\"\\nüèÜ Applications:\")\n",
                "print(\"  - Predict golden boot winners\")\n",
                "print(\"  - Identify top assist providers\")\n",
                "print(\"  - Find undervalued players (high xG but lower actual goals)\")\n",
                "print(\"  - Scout players based on predicted performance\")\n",
                "\n",
                "print(\"\\n‚úÖ Notebook execution completed successfully!\")\n",
                "print(\"\\nThese models can now predict EPL player performance metrics.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}