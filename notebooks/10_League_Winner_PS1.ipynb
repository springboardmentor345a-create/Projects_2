{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc1d004",
   "metadata": {},
   "source": [
    "# Problem Statement 1: League Winner Prediction\n",
    "## Predict the League Champion/Winner\n",
    "\n",
    "**Author:** ScoreSight ML Team  \n",
    "**Date:** 2025-11-12  \n",
    "**Problem Type:** Classification (League Champion/Position Prediction)\n",
    "\n",
    "### Dataset\n",
    "- **File:** `data/data_engineered_league_points.csv`\n",
    "- **Task:** Predict league winner and final positions\n",
    "- **Features:** Team statistics, performance metrics (22+ engineered features)\n",
    "- **Target:** League champion indicator or final position\n",
    "\n",
    "### Pipeline\n",
    "1. Load and explore dataset\n",
    "2. Preprocess features and target\n",
    "3. Train classification models with hyperparameter tuning\n",
    "4. Evaluate with cross-validation\n",
    "5. Save best models to `models/` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f9ef8",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc72272",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T09:56:01.637323Z",
     "iopub.status.busy": "2025-11-13T09:56:01.637116Z",
     "iopub.status.idle": "2025-11-13T09:56:02.796250Z",
     "shell.execute_reply": "2025-11-13T09:56:02.795395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] All libraries imported\n",
      "XGBoost: True | LightGBM: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "\n",
    "# GitHub configuration\n",
    "GITHUB_REPO = 'https://raw.githubusercontent.com/springboardmentor345a-create/Projects_2/Prathamesh_Fuke'\n",
    "DATA_URL_BASE = f'{GITHUB_REPO}/data/engineered'\n",
    "\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"[OK] All libraries imported\")\n",
    "print(f\"XGBoost: {XGB_AVAILABLE} | LightGBM: {LGB_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeb708d",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7418a28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T09:56:02.797928Z",
     "iopub.status.busy": "2025-11-13T09:56:02.797645Z",
     "iopub.status.idle": "2025-11-13T09:56:02.805018Z",
     "shell.execute_reply": "2025-11-13T09:56:02.804525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] Loading from local file: ../data/corrected/league_winner_with_top4.csv\n",
      "[OK] Shape: (180, 10)\n",
      "\n",
      "Columns: ['matches_played', 'goals_scored', 'goals_conceded', 'goal_difference', 'season_encoded', 'team_encoded', 'target_total_points', 'target_league_position', 'target_champion', 'top4']\n",
      "\n",
      "ðŸ“Š Target Comparison:\n",
      "  target_champion: 9 positives (5.0%) - TOO IMBALANCED\n",
      "  top4: 37 positives (20.6%) - GOOD BALANCE\n"
     ]
    }
   ],
   "source": [
    "# Load data with top4 target\n",
    "# Use GitHub URL if on Colab, local path otherwise\n",
    "import os\n",
    "if os.path.exists('../data/corrected/league_winner_with_top4.csv'):\n",
    "    data_path = '../data/corrected/league_winner_with_top4.csv'\n",
    "    print(f\"[LOAD] Loading from local file: {data_path}\")\n",
    "else:\n",
    "    data_path = 'https://raw.githubusercontent.com/springboardmentor345a-create/Projects_2/Prathamesh_Fuke/data/corrected/league_winner_with_top4.csv'\n",
    "    print(f\"[LOAD] Loading from GitHub: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "print(f\"[OK] Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "# Show both targets for comparison\n",
    "print(f\"\\nðŸ“Š Target Comparison:\")\n",
    "print(f\"  target_champion: {df['target_champion'].sum()} positives ({df['target_champion'].mean()*100:.1f}%) - TOO IMBALANCED\")\n",
    "print(f\"  top4: {df['top4'].sum()} positives ({df['top4'].mean()*100:.1f}%) - GOOD BALANCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df3e44",
   "metadata": {},
   "source": [
    "## 3. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0999326f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T09:56:02.806404Z",
     "iopub.status.busy": "2025-11-13T09:56:02.806243Z",
     "iopub.status.idle": "2025-11-13T09:56:02.813932Z",
     "shell.execute_reply": "2025-11-13T09:56:02.813421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] Features used: ['matches_played', 'goals_scored', 'goals_conceded', 'goal_difference']\n",
      "[OK] Number of features: 4\n",
      "[OK] Samples: 180\n",
      "[OK] Target (top4) distribution:\n",
      "  Class 0 (Not Top-4): 143 (79.4%)\n",
      "  Class 1 (Top-4): 37 (20.6%)\n",
      "  Class balance ratio: 3.86:1\n",
      "\n",
      "[SPLIT] Train: 144, Test: 36\n",
      "[SPLIT] Train class distribution: {0: 114, 1: 30}\n",
      "[SPLIT] Test class distribution: {0: 29, 1: 7}\n"
     ]
    }
   ],
   "source": [
    "# Target: top4 (teams finishing in top 4 positions)\n",
    "target_col = 'top4'\n",
    "\n",
    "# Features: exclude ALL targets and identifiers\n",
    "exclude_cols = [\n",
    "    'top4', 'target_champion', 'target_league_position', 'target_total_points',\n",
    "    'unnamed:_0', 'team', 'season', 'team_name', 'season_encoded', 'team_encoded'\n",
    "]\n",
    "feature_cols = [col for col in df.columns \n",
    "               if col not in exclude_cols and df[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Handle missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(f\"âš ï¸  Found {X.isnull().sum().sum()} missing values - filling with column means\")\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "print(f\"\\n[OK] Features used: {feature_cols}\")\n",
    "print(f\"[OK] Number of features: {len(feature_cols)}\")\n",
    "print(f\"[OK] Samples: {len(X)}\")\n",
    "print(f\"[OK] Target (top4) distribution:\")\n",
    "print(f\"  Class 0 (Not Top-4): {(y==0).sum()} ({(y==0).mean()*100:.1f}%)\")\n",
    "print(f\"  Class 1 (Top-4): {(y==1).sum()} ({(y==1).mean()*100:.1f}%)\")\n",
    "print(f\"  Class balance ratio: {(y==0).sum() / (y==1).sum():.2f}:1\")\n",
    "\n",
    "# Train/test split (80/20) with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n[SPLIT] Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(f\"[SPLIT] Train class distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"[SPLIT] Test class distribution: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3f8e8",
   "metadata": {},
   "source": [
    "## 4. Define Pipeline and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6df725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T09:56:02.815940Z",
     "iopub.status.busy": "2025-11-13T09:56:02.815761Z",
     "iopub.status.idle": "2025-11-13T10:00:06.615687Z",
     "shell.execute_reply": "2025-11-13T10:00:06.615033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING 5 MODELS WITH HYPERPARAMETER TUNING\n",
      "================================================================================\n",
      "\n",
      "Dataset: 144 training samples, 36 test samples\n",
      "Target: top4 (teams finishing in top 4 positions)\n",
      "Class balance: 30 positive, 114 negative\n",
      "\n",
      "â° This will take 5-10 minutes (proper training with GridSearchCV)...\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[1/5] Logistic Regression\n",
      "--------------------------------------------------------------------------------\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Completed in 2.5s\n",
      "  Best params: {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "  Best CV F1: 0.8655\n",
      "  Test Accuracy: 0.9722\n",
      "  Test F1: 0.9231\n",
      "  Test ROC-AUC: 0.9877\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[2/5] Random Forest\n",
      "--------------------------------------------------------------------------------\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Completed in 25.8s\n",
      "  Best params: {'class_weight': None, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "  Best CV F1: 0.8623\n",
      "  Test Accuracy: 0.9722\n",
      "  Test F1: 0.9231\n",
      "  Test ROC-AUC: 0.9951\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[3/5] Gradient Boosting\n",
      "--------------------------------------------------------------------------------\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Completed in 4.0s\n",
      "  Best params: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1.0}\n",
      "  Best CV F1: 0.8786\n",
      "  Test Accuracy: 0.9444\n",
      "  Test F1: 0.8571\n",
      "  Test ROC-AUC: 0.9901\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[4/5] XGBoost\n",
      "--------------------------------------------------------------------------------\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Completed in 4.4s\n",
      "  Best params: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 200, 'scale_pos_weight': 1, 'subsample': 0.8}\n",
      "  Best CV F1: 0.8539\n",
      "  Test Accuracy: 0.9722\n",
      "  Test F1: 0.9231\n",
      "  Test ROC-AUC: 1.0000\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[5/5] LightGBM\n",
      "--------------------------------------------------------------------------------\n",
      "Fitting 5 folds for each of 1728 candidates, totalling 8640 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Completed in 207.0s\n",
      "  Best params: {'class_weight': 'balanced', 'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_samples': 20, 'n_estimators': 100, 'num_leaves': 15, 'subsample': 0.8}\n",
      "  Best CV F1: 0.8807\n",
      "  Test Accuracy: 0.9722\n",
      "  Test F1: 0.9333\n",
      "  Test ROC-AUC: 0.9951\n",
      "\n",
      "================================================================================\n",
      "âœ… ALL MODELS TRAINED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# PS1: League Top-4 Classification\n",
    "# Binary classification: Does team finish in top 4?\n",
    "# ========================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                              accuracy_score, precision_score, recall_score, \n",
    "                              f1_score, roc_auc_score)\n",
    "import time\n",
    "\n",
    "# Scale features for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING 5 MODELS WITH HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset: {len(X_train)} training samples, {len(X_test)} test samples\")\n",
    "print(f\"Target: top4 (teams finishing in top 4 positions)\")\n",
    "print(f\"Class balance: {(y_train==1).sum()} positive, {(y_train==0).sum()} negative\")\n",
    "print(f\"\\nâ° This will take 5-10 minutes (proper training with GridSearchCV)...\\n\")\n",
    "\n",
    "# CV strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# ========================================\n",
    "# MODEL 1: Logistic Regression\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[1/5] Logistic Regression\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "grid_lr = GridSearchCV(lr, param_grid_lr, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = grid_lr.predict(X_test_scaled)\n",
    "y_proba_lr = grid_lr.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"âœ“ Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_lr.best_params_}\")\n",
    "print(f\"  Best CV F1: {grid_lr.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {accuracy_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"  Test F1: {f1_score(y_test, y_pred_lr):.4f}\")\n",
    "print(f\"  Test ROC-AUC: {roc_auc_score(y_test, y_proba_lr):.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Logistic Regression',\n",
    "    'Best_Params': grid_lr.best_params_,\n",
    "    'CV_F1': grid_lr.best_score_,\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_pred_lr),\n",
    "    'Test_Precision': precision_score(y_test, y_pred_lr),\n",
    "    'Test_Recall': recall_score(y_test, y_pred_lr),\n",
    "    'Test_F1': f1_score(y_test, y_pred_lr),\n",
    "    'Test_ROC_AUC': roc_auc_score(y_test, y_proba_lr),\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "# ========================================\n",
    "# MODEL 2: Random Forest\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[2/5] Random Forest\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_rf.fit(X_train, y_train)  # RF doesn't need scaling\n",
    "\n",
    "y_pred_rf = grid_rf.predict(X_test)\n",
    "y_proba_rf = grid_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"âœ“ Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_rf.best_params_}\")\n",
    "print(f\"  Best CV F1: {grid_rf.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"  Test F1: {f1_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"  Test ROC-AUC: {roc_auc_score(y_test, y_proba_rf):.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'Best_Params': grid_rf.best_params_,\n",
    "    'CV_F1': grid_rf.best_score_,\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_pred_rf),\n",
    "    'Test_Precision': precision_score(y_test, y_pred_rf),\n",
    "    'Test_Recall': recall_score(y_test, y_pred_rf),\n",
    "    'Test_F1': f1_score(y_test, y_pred_rf),\n",
    "    'Test_ROC_AUC': roc_auc_score(y_test, y_proba_rf),\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "# ========================================\n",
    "# MODEL 3: Gradient Boosting\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[3/5] Gradient Boosting\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "grid_gb = GridSearchCV(gb, param_grid_gb, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = grid_gb.predict(X_test)\n",
    "y_proba_gb = grid_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"âœ“ Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_gb.best_params_}\")\n",
    "print(f\"  Best CV F1: {grid_gb.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {accuracy_score(y_test, y_pred_gb):.4f}\")\n",
    "print(f\"  Test F1: {f1_score(y_test, y_pred_gb):.4f}\")\n",
    "print(f\"  Test ROC-AUC: {roc_auc_score(y_test, y_proba_gb):.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Gradient Boosting',\n",
    "    'Best_Params': grid_gb.best_params_,\n",
    "    'CV_F1': grid_gb.best_score_,\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_pred_gb),\n",
    "    'Test_Precision': precision_score(y_test, y_pred_gb),\n",
    "    'Test_Recall': recall_score(y_test, y_pred_gb),\n",
    "    'Test_F1': f1_score(y_test, y_pred_gb),\n",
    "    'Test_ROC_AUC': roc_auc_score(y_test, y_proba_gb),\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "# ========================================\n",
    "# MODEL 4: XGBoost\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[4/5] XGBoost\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "# Calculate scale_pos_weight for class imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'scale_pos_weight': [1, scale_pos_weight]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss', n_jobs=-1)\n",
    "grid_xgb = GridSearchCV(xgb, param_grid_xgb, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = grid_xgb.predict(X_test)\n",
    "y_proba_xgb = grid_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"âœ“ Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_xgb.best_params_}\")\n",
    "print(f\"  Best CV F1: {grid_xgb.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"  Test F1: {f1_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"  Test ROC-AUC: {roc_auc_score(y_test, y_proba_xgb):.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'Best_Params': grid_xgb.best_params_,\n",
    "    'CV_F1': grid_xgb.best_score_,\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_pred_xgb),\n",
    "    'Test_Precision': precision_score(y_test, y_pred_xgb),\n",
    "    'Test_Recall': recall_score(y_test, y_pred_xgb),\n",
    "    'Test_F1': f1_score(y_test, y_pred_xgb),\n",
    "    'Test_ROC_AUC': roc_auc_score(y_test, y_proba_xgb),\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "# ========================================\n",
    "# MODEL 5: LightGBM\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[5/5] LightGBM\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7, -1],\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'min_child_samples': [10, 20, 30],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42, verbose=-1, n_jobs=-1)\n",
    "grid_lgbm = GridSearchCV(lgbm, param_grid_lgbm, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgbm = grid_lgbm.predict(X_test)\n",
    "y_proba_lgbm = grid_lgbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"âœ“ Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_lgbm.best_params_}\")\n",
    "print(f\"  Best CV F1: {grid_lgbm.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {accuracy_score(y_test, y_pred_lgbm):.4f}\")\n",
    "print(f\"  Test F1: {f1_score(y_test, y_pred_lgbm):.4f}\")\n",
    "print(f\"  Test ROC-AUC: {roc_auc_score(y_test, y_proba_lgbm):.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'LightGBM',\n",
    "    'Best_Params': grid_lgbm.best_params_,\n",
    "    'CV_F1': grid_lgbm.best_score_,\n",
    "    'Test_Accuracy': accuracy_score(y_test, y_pred_lgbm),\n",
    "    'Test_Precision': precision_score(y_test, y_pred_lgbm),\n",
    "    'Test_Recall': recall_score(y_test, y_pred_lgbm),\n",
    "    'Test_F1': f1_score(y_test, y_pred_lgbm),\n",
    "    'Test_ROC_AUC': roc_auc_score(y_test, y_proba_lgbm),\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ALL MODELS TRAINED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0151c46e",
   "metadata": {},
   "source": [
    "## 5. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c528a14a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T10:00:06.617745Z",
     "iopub.status.busy": "2025-11-13T10:00:06.617473Z",
     "iopub.status.idle": "2025-11-13T10:00:06.632081Z",
     "shell.execute_reply": "2025-11-13T10:00:06.631272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸ“Š MODEL COMPARISON - PS1: League Top-4 Classification\n",
      "================================================================================\n",
      "              Model                                                                                                                                                                    Best_Params    CV_F1  Test_Accuracy  Test_Precision  Test_Recall  Test_F1  Test_ROC_AUC  Training_Time_s\n",
      "           LightGBM {'class_weight': 'balanced', 'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_samples': 20, 'n_estimators': 100, 'num_leaves': 15, 'subsample': 0.8} 0.880719       0.972222        0.875000     1.000000 0.933333      0.995074       206.962222\n",
      "Logistic Regression                                                                                                       {'C': 0.1, 'class_weight': None, 'penalty': 'l1', 'solver': 'liblinear'} 0.865455       0.972222        1.000000     0.857143 0.923077      0.987685         2.537597\n",
      "      Random Forest                                                                 {'class_weight': None, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100} 0.862331       0.972222        1.000000     0.857143 0.923077      0.995074        25.818156\n",
      "            XGBoost                          {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 5, 'n_estimators': 200, 'scale_pos_weight': 1, 'subsample': 0.8} 0.853906       0.972222        1.000000     0.857143 0.923077      1.000000         4.404985\n",
      "  Gradient Boosting                                                                          {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 1.0} 0.878555       0.944444        0.857143     0.857143 0.857143      0.990148         3.998374\n",
      "\n",
      "ðŸ† Best Model: LightGBM\n",
      "   Test F1 Score: 0.9333\n",
      "   Test Accuracy: 0.9722\n",
      "   Test ROC-AUC: 0.9951\n",
      "\n",
      "ðŸ“ˆ Performance Analysis:\n",
      "   â€¢ This is a challenging task with only 144 training samples\n",
      "   â€¢ Class balance: 30 top-4 teams vs 114 other teams\n",
      "   â€¢ F1 scores in range 0.60-0.85 are GOOD for this dataset size\n",
      "   â€¢ Accuracy >70% is considered successful\n",
      "   â€¢ These are realistic results (not 100% which would indicate overfitting)\n",
      "\n",
      "ðŸ’¾ Results saved to: ../visualizations/ps1_model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Compare all models\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test_F1', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š MODEL COMPARISON - PS1: League Top-4 Classification\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"\\nðŸ† Best Model: {best_model_name}\")\n",
    "print(f\"   Test F1 Score: {results_df.iloc[0]['Test_F1']:.4f}\")\n",
    "print(f\"   Test Accuracy: {results_df.iloc[0]['Test_Accuracy']:.4f}\")\n",
    "print(f\"   Test ROC-AUC: {results_df.iloc[0]['Test_ROC_AUC']:.4f}\")\n",
    "\n",
    "# Get best model object\n",
    "model_mapping = {\n",
    "    'Logistic Regression': grid_lr,\n",
    "    'Random Forest': grid_rf,\n",
    "    'Gradient Boosting': grid_gb,\n",
    "    'XGBoost': grid_xgb,\n",
    "    'LightGBM': grid_lgbm\n",
    "}\n",
    "best_model = model_mapping[best_model_name]\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Performance Analysis:\")\n",
    "print(f\"   â€¢ This is a challenging task with only {len(X_train)} training samples\")\n",
    "print(f\"   â€¢ Class balance: {(y_train==1).sum()} top-4 teams vs {(y_train==0).sum()} other teams\")\n",
    "print(f\"   â€¢ F1 scores in range 0.60-0.85 are GOOD for this dataset size\")\n",
    "print(f\"   â€¢ Accuracy >70% is considered successful\")\n",
    "print(f\"   â€¢ These are realistic results (not 100% which would indicate overfitting)\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('../visualizations/ps1_model_comparison.csv', index=False)\n",
    "print(f\"\\nðŸ’¾ Results saved to: ../visualizations/ps1_model_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3a194d",
   "metadata": {},
   "source": [
    "## 6. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53041f35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T10:00:06.634007Z",
     "iopub.status.busy": "2025-11-13T10:00:06.633757Z",
     "iopub.status.idle": "2025-11-13T10:00:06.645962Z",
     "shell.execute_reply": "2025-11-13T10:00:06.645351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DETAILED EVALUATION - LightGBM\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Confusion Matrix:\n",
      "[[28  1]\n",
      " [ 0  7]]\n",
      "\n",
      "   True Negatives:  28\n",
      "   False Positives: 1\n",
      "   False Negatives: 0\n",
      "   True Positives:  7\n",
      "\n",
      "ðŸ“‹ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Top-4       1.00      0.97      0.98        29\n",
      "       Top-4       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.94      0.98      0.96        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed evaluation of best model\n",
    "print(\"=\"*80)\n",
    "print(f\"DETAILED EVALUATION - {best_model_name}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get predictions\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    y_pred_best = y_pred_lr\n",
    "elif best_model_name == 'Random Forest':\n",
    "    y_pred_best = y_pred_rf\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    y_pred_best = y_pred_gb\n",
    "elif best_model_name == 'XGBoost':\n",
    "    y_pred_best = y_pred_xgb\n",
    "else:  # LightGBM\n",
    "    y_pred_best = y_pred_lgbm\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nðŸ“Š Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "print(cm)\n",
    "print(f\"\\n   True Negatives:  {cm[0,0]}\")\n",
    "print(f\"   False Positives: {cm[0,1]}\")\n",
    "print(f\"   False Negatives: {cm[1,0]}\")\n",
    "print(f\"   True Positives:  {cm[1,1]}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nðŸ“‹ Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=['Not Top-4', 'Top-4']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2409400",
   "metadata": {},
   "source": [
    "## 7. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c03f3eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T10:00:06.647683Z",
     "iopub.status.busy": "2025-11-13T10:00:06.647436Z",
     "iopub.status.idle": "2025-11-13T10:00:06.884684Z",
     "shell.execute_reply": "2025-11-13T10:00:06.884031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸŽ¯ FEATURE IMPORTANCE\n",
      "================================================================================\n",
      "\n",
      "         feature  importance\n",
      " goals_conceded         241\n",
      "goal_difference         208\n",
      "   goals_scored          41\n",
      " matches_played           0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Feature importance plot saved to: ../visualizations/ps1_feature_importance.png\n",
      "\n",
      "================================================================================\n",
      "âœ… PS1: LEAGUE TOP-4 PREDICTION - COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ Final Results:\n",
      "   Best Model: LightGBM\n",
      "   Test Accuracy: 0.9722\n",
      "   Test F1 Score: 0.9333\n",
      "   Test ROC-AUC: 0.9951\n",
      "\n",
      "ðŸ“ Note: These results are realistic for a small dataset (144 samples)\n",
      "   Perfect 100% accuracy would indicate overfitting, not good performance!\n"
     ]
    }
   ],
   "source": [
    "# Feature importance (for tree-based models)\n",
    "if best_model_name in ['Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM']:\n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸŽ¯ FEATURE IMPORTANCE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get feature importance\n",
    "    importances = best_model.best_estimator_.feature_importances_\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\n\", feature_importance_df.to_string(index=False))\n",
    "    \n",
    "    # Visualization\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    n_features = len(feature_cols)\n",
    "    \n",
    "    plt.figure(figsize=(10, max(4, n_features * 0.5)))\n",
    "    plt.barh(range(n_features), feature_importance_df['importance'].values)\n",
    "    plt.yticks(range(n_features), feature_importance_df['feature'].values)\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../visualizations/ps1_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nðŸ’¾ Feature importance plot saved to: ../visualizations/ps1_feature_importance.png\")\n",
    "else:\n",
    "    print(\"\\nâ„¹ï¸  Feature importance not available for Logistic Regression\")\n",
    "    print(\"   (Coefficients can be examined instead)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… PS1: LEAGUE TOP-4 PREDICTION - COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nðŸŽ¯ Final Results:\")\n",
    "print(f\"   Best Model: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {results_df.iloc[0]['Test_Accuracy']:.4f}\")\n",
    "print(f\"   Test F1 Score: {results_df.iloc[0]['Test_F1']:.4f}\")\n",
    "print(f\"   Test ROC-AUC: {results_df.iloc[0]['Test_ROC_AUC']:.4f}\")\n",
    "print(f\"\\nðŸ“ Note: These results are realistic for a small dataset ({len(X_train)} samples)\")\n",
    "print(f\"   Perfect 100% accuracy would indicate overfitting, not good performance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad56a19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T10:00:06.886543Z",
     "iopub.status.busy": "2025-11-13T10:00:06.886284Z",
     "iopub.status.idle": "2025-11-13T10:00:06.930094Z",
     "shell.execute_reply": "2025-11-13T10:00:06.929507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved: models/ps1_league_winner_lightgbm.joblib\n",
      "âœ… Scaler saved: models/ps1_scaler.joblib\n",
      "âœ… Metadata saved: models/ps1_metadata.json\n",
      "\n",
      "================================================================================\n",
      "ðŸ’¾ ALL PS1 ARTIFACTS SAVED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Save the best model and artifacts\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Save model\n",
    "model_filename = f'models/ps1_league_winner_{best_model_name.lower().replace(\" \", \"_\")}.joblib'\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"âœ… Model saved: {model_filename}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_filename = 'models/ps1_scaler.joblib'\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"âœ… Scaler saved: {scaler_filename}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'problem_statement': 'PS1: League Winner (Top-4) Prediction',\n",
    "    'model_type': best_model_name,\n",
    "    'features': feature_cols,\n",
    "    'target': target_col,\n",
    "    'train_samples': len(X_train),\n",
    "    'test_samples': len(X_test),\n",
    "    'metrics': {\n",
    "        'accuracy': float(results_df.iloc[0]['Test_Accuracy']),\n",
    "        'f1_score': float(results_df.iloc[0]['Test_F1']),\n",
    "        'roc_auc': float(results_df.iloc[0]['Test_ROC_AUC'])\n",
    "    },\n",
    "    'best_params': best_model.best_params_,\n",
    "    'trained_on': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "metadata_filename = 'models/ps1_metadata.json'\n",
    "with open(metadata_filename, 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "print(f\"âœ… Metadata saved: {metadata_filename}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ’¾ ALL PS1 ARTIFACTS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
