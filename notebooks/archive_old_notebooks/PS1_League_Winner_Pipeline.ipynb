{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f01a4c0e",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13709b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 1: Setup and Configuration\n",
    "# ==================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, RandomizedSearchCV, cross_val_score,\n",
    "    StratifiedKFold, train_test_split\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"IMPORTING LIBRARIES...\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Try importing XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "    print(\"XGBoost available\")\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"XGBoost not installed\")\n",
    "\n",
    "# Global Configuration\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"CONFIGURING PATHS...\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "os.chdir('d:\\\\ScoreSight')\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Create directory structure\n",
    "MODELS_DIR = Path('models')\n",
    "VIZ_DIR = Path('visualizations/ps1_league_winner')\n",
    "REPORTS_DIR = Path('reports')\n",
    "DATA_DIR = Path('data')\n",
    "DATASETS_DIR = Path('datasets')\n",
    "FINAL_DATA_PATH = DATA_DIR / 'league_winner' / 'league_winner_data.csv'\n",
    "\n",
    "for dir_path in [MODELS_DIR, VIZ_DIR, REPORTS_DIR, FINAL_DATA_PATH.parent]:\n",
    "    dir_path.mkdir(exist_ok=True)\n",
    "    print(f\"Created/verified: {dir_path}\")\n",
    "\n",
    "# Raw data path\n",
    "RAW_LEAGUE_DATA_PATH = DATASETS_DIR / 'ScoreSight_ML_Season_LeagueWinner_Champion.csv'\n",
    "\n",
    "# Display options\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"PS1 LEAGUE WINNER PIPELINE\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90802b6",
   "metadata": {},
   "source": [
    "## 2. Data Loading, Cleaning, and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b174e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 2: Data Loading and Engineering\n",
    "# ==================================================\n",
    "print(f\"Loading raw league data from: {RAW_LEAGUE_DATA_PATH}\")\n",
    "try:\n",
    "    df_league_raw = pd.read_csv(RAW_LEAGUE_DATA_PATH)\n",
    "    print(f\"Loaded raw league data: {df_league_raw.shape}\")\n",
    "\n",
    "    # --- Data Cleaning ---\n",
    "    df_league_raw.columns = df_league_raw.columns.str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "    df_league_raw.drop_duplicates(inplace=True)\n",
    "    print(f\"Cleaned data shape: {df_league_raw.shape}\")\n",
    "\n",
    "    # --- Feature Engineering & Selection ---\n",
    "    # These are columns that could cause data leakage\n",
    "    leak_cols = ['points_per_game', 'target_total_points', 'target_league_position']\n",
    "    \n",
    "    # Define feature columns (numeric types, not identifiers or leakage columns)\n",
    "    feature_cols = [c for c in df_league_raw.columns if c not in leak_cols + ['team', 'season_encoded', 'team_encoded', 'target_champion'] and df_league_raw[c].dtype in ['float64', 'int64']]\n",
    "    \n",
    "    # Create the final DataFrame for modeling\n",
    "    df_ps1 = df_league_raw[feature_cols + ['target_champion']].copy()\n",
    "    \n",
    "    # Save the engineered data for traceability\n",
    "    FINAL_DATA_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    df_ps1.to_csv(FINAL_DATA_PATH, index=False)\n",
    "    \n",
    "    print(f\"Engineered dataset created with {len(feature_cols)} features.\")\n",
    "    print(f\"Saved final modeling data to: {FINAL_DATA_PATH}\")\n",
    "    print(\"\\nFinal DataFrame head:\")\n",
    "    display(df_ps1.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Raw data file not found at {RAW_LEAGUE_DATA_PATH}\")\n",
    "    df_ps1 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9031069d",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a743d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 3: Model Training\n",
    "# ==================================================\n",
    "if df_ps1 is not None:\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"PS1: LEAGUE WINNER PREDICTION - TRAINING\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    # Define target and features\n",
    "    TARGET_COL_PS1 = 'target_champion'\n",
    "    \n",
    "    # Exclude the target from the feature list\n",
    "    feature_cols_ps1 = [c for c in df_ps1.columns if c != TARGET_COL_PS1]\n",
    "    \n",
    "    X_ps1 = df_ps1[feature_cols_ps1].copy()\n",
    "    y_ps1 = df_ps1[TARGET_COL_PS1].astype(int)\n",
    "    \n",
    "    print(f\"Features ({len(feature_cols_ps1)}): {feature_cols_ps1}\")\n",
    "    print(f\"Target: {TARGET_COL_PS1}\")\n",
    "\n",
    "    # Check for class imbalance\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(y_ps1.value_counts())\n",
    "    \n",
    "    # Stratified split to maintain class balance\n",
    "    X_train_ps1, X_test_ps1, y_train_ps1, y_test_ps1 = train_test_split(\n",
    "        X_ps1, y_ps1, test_size=0.25, random_state=42, stratify=y_ps1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nData split: {X_train_ps1.shape[0]} train / {X_test_ps1.shape[0]} test\")\n",
    "    \n",
    "    # Model configurations\n",
    "    models_ps1 = {\n",
    "        'RandomForest': RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "        'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
    "    }\n",
    "    \n",
    "    if XGB_AVAILABLE:\n",
    "        pos = y_train_ps1.sum()\n",
    "        neg = len(y_train_ps1) - pos\n",
    "        spw = max((neg / pos) if pos > 0 else 1.0, 1.0)\n",
    "        models_ps1['XGBoost'] = xgb.XGBClassifier(\n",
    "            random_state=42, use_label_encoder=False, eval_metric='logloss', scale_pos_weight=spw\n",
    "        )\n",
    "    \n",
    "    # Parameter grids\n",
    "    param_grids_ps1 = {\n",
    "        'RandomForest': {\n",
    "            'model__n_estimators': [50, 100], 'model__max_depth': [5, 10],\n",
    "            'model__min_samples_leaf': [5, 10], 'model__min_samples_split': [10, 20]\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'model__n_estimators': [50, 100], 'model__learning_rate': [0.01, 0.05],\n",
    "            'model__max_depth': [3, 5], 'model__subsample': [0.7, 0.8]\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'model__n_estimators': [50, 100], 'model__learning_rate': [0.01, 0.05],\n",
    "            'model__max_depth': [3, 5], 'model__subsample': [0.7, 0.8]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # --- Execute Training ---\n",
    "    best_model_data = None\n",
    "    best_f1_score = -1\n",
    "\n",
    "    for model_name, model in models_ps1.items():\n",
    "        print(f\"\\n--- Training {model_name} ---\")\n",
    "        pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=pipeline, param_distributions=param_grids_ps1.get(model_name, {}),\n",
    "            n_iter=10, cv=StratifiedKFold(n_splits=5), scoring='f1_macro', n_jobs=-1, random_state=42\n",
    "        )\n",
    "        search.fit(X_train_ps1, y_train_ps1)\n",
    "        y_pred = search.predict(X_test_ps1)\n",
    "        f1 = f1_score(y_test_ps1, y_pred, average='macro')\n",
    "        \n",
    "        print(f\"  Test F1-Macro: {f1:.4f}\")\n",
    "        print(f\"  Best CV Score: {search.best_score_:.4f}\")\n",
    "\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model_data = {\n",
    "                'name': model_name,\n",
    "                'model': search.best_estimator_,\n",
    "                'f1_score': f1,\n",
    "                'report': classification_report(y_test_ps1, y_pred, output_dict=True)\n",
    "            }\n",
    "\n",
    "    print(f\"\\n--- Best Model: {best_model_data['name']} with F1-Macro: {best_model_data['f1_score']:.4f} ---\")\n",
    "\n",
    "    # --- Save Artifacts ---\n",
    "    model_path = MODELS_DIR / 'ps1_league_winner_best_model.joblib'\n",
    "    metadata_path = MODELS_DIR / 'ps1_league_winner_metadata.json'\n",
    "    \n",
    "    joblib.dump(best_model_data['model'], model_path)\n",
    "    \n",
    "    metadata = {\n",
    "        'problem_name': 'PS1_League_Winner',\n",
    "        'best_model': best_model_data['name'],\n",
    "        'task_type': 'classification',\n",
    "        'test_metrics': {'f1_macro': best_model_data['f1_score']},\n",
    "        'classification_report': best_model_data['report']\n",
    "    }\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "        \n",
    "    print(f\"Model saved: {model_path}\")\n",
    "    print(f\"Metadata saved: {metadata_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping training because data loading failed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
