{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950a3157",
   "metadata": {},
   "source": [
    "# Problem Statement 5: Match Result Prediction\n",
    "## Predict Match Result (Home/Draw/Away)\n",
    "\n",
    "**Author:** ScoreSight ML Team  \n",
    "**Date:** 2025-11-12  \n",
    "**Problem Type:** Multi-class Classification (H/D/A)\n",
    "\n",
    "### Dataset\n",
    "- **File:** `data/match_prediction_corrected.csv`\n",
    "- **Task:** Predict match result (Home/Draw/Away)\n",
    "- **Features:** Match data from corrected dataset\n",
    "- **Target:** Result (H/D/A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e341ee15",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "\n",
    "# GitHub configuration\n",
    "GITHUB_REPO = 'https://raw.githubusercontent.com/springboardmentor345a-create/Projects_2/Prathamesh_Fuke'\n",
    "DATA_URL_BASE_CORRECTED = f'{GITHUB_REPO}/data/corrected'\n",
    "\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"[OK] All libraries imported\")\n",
    "print(f\"XGBoost: {XGB_AVAILABLE} | LightGBM: {LGB_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417ee48",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84749567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from GitHub (from corrected folder, not engineered)\n",
    "data_url = f'{DATA_URL_BASE_CORRECTED}/match_prediction_corrected.csv'\n",
    "print(f\"[LOAD] Loading from GitHub: {data_url}\")\n",
    "\n",
    "df = pd.read_csv(data_url)\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "print(f\"[OK] Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nTarget (mw) distribution:\")\n",
    "print(df['mw'].value_counts())\n",
    "\n",
    "# Prepare features\n",
    "exclude_cols = ['mw', 'unnamed: 0']\n",
    "feature_cols = [col for col in df.columns \n",
    "               if col not in exclude_cols and df[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df['mw'].copy()\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "print(f\"\\n[OK] Features: {len(feature_cols)}, Samples: {len(X)}\")\n",
    "print(f\"[OK] Feature columns: {feature_cols[:10]}... (showing first 10)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518147da",
   "metadata": {},
   "source": [
    "## 3. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a2736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAIN/TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"[SPLIT] Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(f\"[SPLIT] Train class distribution:\\n{y_train.value_counts()}\")\n",
    "print(f\"[SPLIT] Test class distribution:\\n{y_test.value_counts()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETER SEARCH SPACE - Match Result (Large Balanced Dataset)\n",
    "# ============================================================================\n",
    "\n",
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'model__C': [0.1, 1, 10, 100],\n",
    "        'model__solver': ['lbfgs', 'liblinear'],\n",
    "        'model__max_iter': [3000, 5000]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [10, 15, 20, None],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [5, 7, 9],\n",
    "        'model__subsample': [0.8, 0.9]\n",
    "    }\n",
    "}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    param_grids['XGBoost'] = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [5, 7, 9],\n",
    "        'model__subsample': [0.8, 0.9, 1.0]\n",
    "    }\n",
    "\n",
    "if LGB_AVAILABLE:\n",
    "    param_grids['LightGBM'] = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__num_leaves': [30, 50, 70],\n",
    "        'model__min_data_in_leaf': [10, 20]\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING WITH HYPERPARAMETER TUNING\n",
    "# ============================================================================\n",
    "\n",
    "def create_pipeline(model, use_scaling=True):\n",
    "    steps = [('imputer', SimpleImputer(strategy='mean'))]\n",
    "    if use_scaling:\n",
    "        steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', model))\n",
    "    return Pipeline(steps)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING - RandomizedSearchCV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "best_models = {}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models_to_train = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=5000),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    models_to_train['XGBoost'] = xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss', use_label_encoder=False)\n",
    "\n",
    "if LGB_AVAILABLE:\n",
    "    models_to_train['LightGBM'] = lgb.LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)\n",
    "\n",
    "for model_name, model in models_to_train.items():\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(f\"[{model_name}] Hyperparameter Tuning...\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    pipeline = create_pipeline(model)\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        n_iter=25,\n",
    "        cv=cv,\n",
    "        scoring='f1_weighted',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[model_name] = search.best_estimator_\n",
    "    print(f\"\\n[BEST] Params: {search.best_params_}\")\n",
    "    print(f\"[CV] F1 Score: {search.best_score_:.4f}\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    y_pred = best_models[model_name].predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'best_params': search.best_params_,\n",
    "        'cv_f1': float(search.best_score_),\n",
    "        'test_accuracy': float(acc),\n",
    "        'test_f1': float(f1),\n",
    "        'test_precision': float(precision),\n",
    "        'test_recall': float(recall)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n[TEST] Accuracy:  {acc:.4f}\")\n",
    "    print(f\"[TEST] F1:        {f1:.4f}\")\n",
    "    print(f\"[TEST] Precision: {precision:.4f}\")\n",
    "    print(f\"[TEST] Recall:    {recall:.4f}\")\n",
    "    \n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    \n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    trained_models[model_name] = best_models[model_name]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315680ed",
   "metadata": {},
   "source": [
    "## 4. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a48728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IDENTIFY BEST MODEL\n",
    "# ============================================================================\n",
    "\n",
    "best_model_name = max(results, key=lambda x: results[x]['test_f1'])\n",
    "best_metrics = results[best_model_name]\n",
    "\n",
    "print(f\"\\n[WINNER] Best Model: {best_model_name}\")\n",
    "print(f\"[WINNER] Test F1 Score: {best_metrics['test_f1']:.4f}\")\n",
    "print(f\"[WINNER] Test Accuracy: {best_metrics['test_accuracy']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE ALL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SAVING MODELS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    path = models_dir / f\"ps5_match_result_{name.lower().replace(' ', '_')}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"[SAVE] {name:20} -> {path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE TRAINING SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "summary = {\n",
    "    'problem_statement': 'PS5: Match Result Prediction',\n",
    "    'task_type': 'Multi-class Classification (Home/Draw/Away)',\n",
    "    'best_model': best_model_name,\n",
    "    'best_test_f1': best_metrics['test_f1'],\n",
    "    'best_test_accuracy': best_metrics['test_accuracy'],\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'data': {\n",
    "        'url': data_url,\n",
    "        'shape': df.shape,\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'n_features': len(feature_cols),\n",
    "        'n_classes': len(np.unique(y))\n",
    "    },\n",
    "    'cv_strategy': '5-Fold Stratified KFold',\n",
    "    'tuning_method': 'RandomizedSearchCV (25 iterations)',\n",
    "    'all_models': results\n",
    "}\n",
    "\n",
    "summary_path = models_dir / 'ps5_match_result_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n[SAVE] Summary -> {summary_path}\")\n",
    "print(f\"\\n{json.dumps(summary, indent=2, default=str)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
