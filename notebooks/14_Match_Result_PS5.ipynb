{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950a3157",
   "metadata": {},
   "source": [
    "# Problem Statement 5: Match Result Prediction\n",
    "## Predict Match Result (Home/Draw/Away)\n",
    "\n",
    "**Author:** ScoreSight ML Team  \n",
    "**Date:** 2025-11-12  \n",
    "**Problem Type:** Multi-class Classification (H/D/A)\n",
    "\n",
    "### Dataset\n",
    "- **File:** `data/match_prediction_corrected.csv`\n",
    "- **Task:** Predict match result (Home/Draw/Away)\n",
    "- **Features:** Match data from corrected dataset\n",
    "- **Target:** Result (H/D/A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e341ee15",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2fb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    import lightgbm as lgb\n",
    "    BOTH_AVAILABLE = True\n",
    "except:\n",
    "    BOTH_AVAILABLE = False\n",
    "\n",
    "# For Colab: Base directory is /content/drive/MyDrive/ScoreSight\n",
    "SCORESIGHT_DIR = '/content/drive/MyDrive/ScoreSight'\n",
    "DATA_DIR = os.path.join(SCORESIGHT_DIR, 'data')\n",
    "MODELS_DIR = os.path.join(SCORESIGHT_DIR, 'models')\n",
    "\n",
    "Path(MODELS_DIR).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"[OK] Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417ee48",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84749567",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(DATA_DIR, 'corrected', 'match_prediction_corrected.csv')\n",
    "print(f\"Loading from: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Identify target (usually FTR or result)\n",
    "target = None\n",
    "for col in df.columns:\n",
    "    if any(x in col.lower() for x in ['result', 'ftr', 'outcome', 'winner']):\n",
    "        target = col\n",
    "        break\n",
    "\n",
    "if target is None:\n",
    "    target = df.columns[-1]\n",
    "\n",
    "print(f\"\\nTarget: {target}\")\n",
    "print(f\"Classes: {df[target].unique()}\")\n",
    "\n",
    "# Prepare features\n",
    "exclude_cols = [target, 'unnamed: 0', 'date', 'team', 'match']\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols and df[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "X = df[feature_cols].fillna(df[feature_cols].mean())\n",
    "y_raw = df[target]\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "\n",
    "print(f\"\\nFeatures: {len(feature_cols)}, Samples: {len(X)}\")\n",
    "print(f\"Classes: {list(le.classes_)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518147da",
   "metadata": {},
   "source": [
    "## 3. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8a2736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model):\n",
    "    return Pipeline([('imputer', SimpleImputer()), ('model', model)])\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=2000),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "if BOTH_AVAILABLE:\n",
    "    models['XGBoost'] = xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "    models['LightGBM'] = lgb.LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"[{name}] Training...\")\n",
    "    pipeline = create_pipeline(model)\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        temp_pipeline = create_pipeline(model.__class__(**model.get_params()))\n",
    "        temp_pipeline.fit(X_train, y_train)\n",
    "        scores.append(f1_score(y_test, temp_pipeline.predict(X_test), average='weighted'))\n",
    "    \n",
    "    results[name] = np.mean(scores)\n",
    "    trained_models[name] = pipeline\n",
    "    print(f\"  F1: {results[name]:.4f}\")\n",
    "\n",
    "print(\"\\n[OK] Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315680ed",
   "metadata": {},
   "source": [
    "## 4. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a48728",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = Path(MODELS_DIR)\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "best_name = max(results, key=results.get)\n",
    "best_f1 = results[best_name]\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    path = models_dir / f\"match_result_{name.lower().replace(' ', '_')}_ps5.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"[SAVE] {name} -> {path}\")\n",
    "\n",
    "# Save encoder\n",
    "le_path = models_dir / \"match_result_encoder_ps5.joblib\"\n",
    "joblib.dump(le, le_path)\n",
    "print(f\"[SAVE] Encoder -> {le_path}\")\n",
    "\n",
    "summary = {\n",
    "    'problem_statement': 'Match Result Prediction',\n",
    "    'best_model': best_name,\n",
    "    'best_f1': float(best_f1),\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'classes': list(le.classes_),\n",
    "    'models': {name: {'f1': float(results[name])} for name in results.keys()}\n",
    "}\n",
    "\n",
    "summary_path = models_dir / 'match_result_training_summary_ps5.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n[COMPLETE] Best: {best_name} (F1: {best_f1:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
