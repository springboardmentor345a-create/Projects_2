{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d71b956",
   "metadata": {},
   "source": [
    "# Problem Statement 2: Match Winner Prediction\n",
    "## Predict Match Result (Home/Draw/Away)\n",
    "\n",
    "**Author:** ScoreSight ML Team  \n",
    "**Date:** 2025-11-12  \n",
    "**Problem Type:** Multi-class Classification\n",
    "\n",
    "### Dataset\n",
    "- **File:** `data/data_engineered_match_prediction.csv`\n",
    "- **Task:** Predict match winner\n",
    "- **Features:** Match statistics, team form (56+ engineered features)\n",
    "- **Target:** mw (Match winner code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113b22d",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721602ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score,\n",
    "                             confusion_matrix, classification_report)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "\n",
    "# GitHub configuration\n",
    "GITHUB_REPO = 'https://raw.githubusercontent.com/springboardmentor345a-create/Projects_2/Prathamesh_Fuke'\n",
    "DATA_URL_BASE = f'{GITHUB_REPO}/data/engineered'\n",
    "\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"[OK] All libraries imported\")\n",
    "print(f\"XGBoost: {XGB_AVAILABLE} | LightGBM: {LGB_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c08d40",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with FTR target\n",
    "data_path = '../data/corrected/match_prediction_with_ftr.csv'\n",
    "print(f\"[LOAD] Loading from: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "print(f\"[OK] Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "\n",
    "# Show target distribution\n",
    "print(f\"\\nüìä Target (FTR) Distribution:\")\n",
    "print(df['ftr'].value_counts())\n",
    "print(f\"\\nPercentages:\")\n",
    "print(df['ftr'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Prepare features - exclude targets and encodings\n",
    "exclude_cols = ['ftr', 'ftr_encoded', 'hometeam_encoded', 'awayteam_encoded']\n",
    "feature_cols = [col for col in df.columns \n",
    "               if col not in exclude_cols and df[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df['ftr_encoded'].copy()  # 0=H, 1=D, 2=A\n",
    "\n",
    "# Handle missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Found {X.isnull().sum().sum()} missing values - filling with column means\")\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "print(f\"\\n[OK] Features ({len(feature_cols)}): {feature_cols}\")\n",
    "print(f\"[OK] Samples: {len(X)}\")\n",
    "print(f\"[OK] Target encoding: 0=Home Win, 1=Draw, 2=Away Win\")\n",
    "\n",
    "# Train/test split (80/20) with stratification\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n[SPLIT] Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(f\"[SPLIT] Train class distribution:\")\n",
    "for i, label in enumerate(['Home Win', 'Draw', 'Away Win']):\n",
    "    count = (y_train == i).sum()\n",
    "    pct = (y_train == i).mean() * 100\n",
    "    print(f\"  {label}: {count} ({pct:.1f}%)\")\n",
    "print(f\"\\n[SPLIT] Test class distribution:\")\n",
    "for i, label in enumerate(['Home Win', 'Draw', 'Away Win']):\n",
    "    count = (y_test == i).sum()\n",
    "    pct = (y_test == i).mean() * 100\n",
    "    print(f\"  {label}: {count} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d051d85f",
   "metadata": {},
   "source": [
    "## 3. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PS2: Match Winner Prediction (H/D/A)\n",
    "# 3-Class Classification\n",
    "# ========================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, \n",
    "                              recall_score, confusion_matrix, classification_report)\n",
    "import time\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING MATCH WINNER MODELS (3-Class Classification)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset: {len(X_train)} training, {len(X_test)} test samples\")\n",
    "print(f\"Target: FTR (0=Home Win, 1=Draw, 2=Away Win)\")\n",
    "print(f\"Baseline (random): 33.3% accuracy\")\n",
    "print(f\"Goal: 50-60% accuracy = EXCELLENT for football!\\n\")\n",
    "print(f\"‚è∞ This will take 15-20 minutes (large dataset)...\\n\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "# ========================================\n",
    "# MODEL 1: Logistic Regression (Multinomial)\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[1/5] Logistic Regression (Multinomial)\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'class_weight': ['balanced'],\n",
    "    'multi_class': ['multinomial'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "grid_lr = GridSearchCV(lr, param_grid_lr, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_lr = grid_lr.predict(X_test_scaled)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "\n",
    "print(f\"‚úì Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_lr.best_params_}\")\n",
    "print(f\"  Best CV Accuracy: {grid_lr.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {acc_lr:.4f}\")\n",
    "print(f\"  Test F1 (weighted): {f1_lr:.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Logistic Regression',\n",
    "    'Best_Params': grid_lr.best_params_,\n",
    "    'CV_Accuracy': grid_lr.best_score_,\n",
    "    'Test_Accuracy': acc_lr,\n",
    "    'Test_F1': f1_lr,\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "# ========================================\n",
    "# MODEL 2: Random Forest\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[2/5] Random Forest\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [2, 4],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "grid_rf = GridSearchCV(rf, param_grid_rf, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = grid_rf.predict(X_test)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "print(f\"‚úì Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_rf.best_params_}\")\n",
    "print(f\"  Best CV Accuracy: {grid_rf.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {acc_rf:.4f}\")\n",
    "print(f\"  Test F1 (weighted): {f1_rf:.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'Best_Params': grid_rf.best_params_,\n",
    "    'CV_Accuracy': grid_rf.best_score_,\n",
    "    'Test_Accuracy': acc_rf,\n",
    "    'Test_F1': f1_rf,\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "# ========================================\n",
    "# MODEL 3: Gradient Boosting\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[3/5] Gradient Boosting\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [5, 7],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "grid_gb = GridSearchCV(gb, param_grid_gb, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gb = grid_gb.predict(X_test)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "acc_gb = accuracy_score(y_test, y_pred_gb)\n",
    "f1_gb = f1_score(y_test, y_pred_gb, average='weighted')\n",
    "\n",
    "print(f\"‚úì Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_gb.best_params_}\")\n",
    "print(f\"  Best CV Accuracy: {grid_gb.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {acc_gb:.4f}\")\n",
    "print(f\"  Test F1 (weighted): {f1_gb:.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Gradient Boosting',\n",
    "    'Best_Params': grid_gb.best_params_,\n",
    "    'CV_Accuracy': grid_gb.best_score_,\n",
    "    'Test_Accuracy': acc_gb,\n",
    "    'Test_F1': f1_gb,\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "# ========================================\n",
    "# MODEL 4: XGBoost\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[4/5] XGBoost\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'objective': ['multi:softmax'],\n",
    "    'num_class': [3]\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='mlogloss', n_jobs=-1)\n",
    "grid_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = grid_xgb.predict(X_test)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "\n",
    "print(f\"‚úì Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_xgb.best_params_}\")\n",
    "print(f\"  Best CV Accuracy: {grid_xgb.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {acc_xgb:.4f}\")\n",
    "print(f\"  Test F1 (weighted): {f1_xgb:.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'Best_Params': grid_xgb.best_params_,\n",
    "    'CV_Accuracy': grid_xgb.best_score_,\n",
    "    'Test_Accuracy': acc_xgb,\n",
    "    'Test_F1': f1_xgb,\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "# ========================================\n",
    "# MODEL 5: LightGBM\n",
    "# ========================================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"[5/5] LightGBM\")\n",
    "print(\"-\"*80)\n",
    "start_time = time.time()\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [5, 7, -1],\n",
    "    'num_leaves': [31, 63],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42, verbose=-1, n_jobs=-1)\n",
    "grid_lgbm = GridSearchCV(lgbm, param_grid_lgbm, cv=cv, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgbm = grid_lgbm.predict(X_test)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "acc_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
    "f1_lgbm = f1_score(y_test, y_pred_lgbm, average='weighted')\n",
    "\n",
    "print(f\"‚úì Completed in {elapsed:.1f}s\")\n",
    "print(f\"  Best params: {grid_lgbm.best_params_}\")\n",
    "print(f\"  Best CV Accuracy: {grid_lgbm.best_score_:.4f}\")\n",
    "print(f\"  Test Accuracy: {acc_lgbm:.4f}\")\n",
    "print(f\"  Test F1 (weighted): {f1_lgbm:.4f}\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'LightGBM',\n",
    "    'Best_Params': grid_lgbm.best_params_,\n",
    "    'CV_Accuracy': grid_lgbm.best_score_,\n",
    "    'Test_Accuracy': acc_lgbm,\n",
    "    'Test_F1': f1_lgbm,\n",
    "    'Training_Time_s': elapsed\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ALL MODELS TRAINED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db895f1b",
   "metadata": {},
   "source": [
    "## 4. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test_Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä MODEL COMPARISON - PS2: Match Winner Prediction (H/D/A)\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_accuracy = results_df.iloc[0]['Test_Accuracy']\n",
    "best_f1 = results_df.iloc[0]['Test_F1']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"   Test F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "# Get best model object\n",
    "model_mapping = {\n",
    "    'Logistic Regression': grid_lr,\n",
    "    'Random Forest': grid_rf,\n",
    "    'Gradient Boosting': grid_gb,\n",
    "    'XGBoost': grid_xgb,\n",
    "    'LightGBM': grid_lgbm\n",
    "}\n",
    "best_model = model_mapping[best_model_name]\n",
    "\n",
    "print(f\"\\nüìà Performance Analysis:\")\n",
    "print(f\"   ‚Ä¢ Random baseline (guess): 33.3% accuracy\")\n",
    "print(f\"   ‚Ä¢ Your model: {best_accuracy*100:.1f}% accuracy\")\n",
    "print(f\"   ‚Ä¢ Improvement: {(best_accuracy - 0.333) / 0.333 * 100:.1f}% better than random!\")\n",
    "print(f\"   ‚Ä¢ This dataset: {len(X_train)} training samples\")\n",
    "print(f\"   ‚Ä¢ For football match prediction, 50-60% accuracy is EXCELLENT!\")\n",
    "print(f\"   ‚Ä¢ Professional betting models achieve 50-55%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nüìä Confusion Matrix (Best Model):\")\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    y_pred_best = y_pred_lr\n",
    "elif best_model_name == 'Random Forest':\n",
    "    y_pred_best = y_pred_rf\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    y_pred_best = y_pred_gb\n",
    "elif best_model_name == 'XGBoost':\n",
    "    y_pred_best = y_pred_xgb\n",
    "else:\n",
    "    y_pred_best = y_pred_lgbm\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "print(cm)\n",
    "print(f\"\\n   Rows: Actual | Columns: Predicted\")\n",
    "print(f\"   [0] Home Win, [1] Draw, [2] Away Win\")\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, \n",
    "                            target_names=['Home Win', 'Draw', 'Away Win']))\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('../visualizations/ps2_model_comparison.csv', index=False)\n",
    "print(f\"\\nüíæ Results saved to: ../visualizations/ps2_model_comparison.csv\")\n",
    "\n",
    "# Save best model\n",
    "import joblib\n",
    "joblib.dump({\n",
    "    'model': best_model.best_estimator_,\n",
    "    'scaler': scaler,\n",
    "    'features': feature_cols,\n",
    "    'model_name': best_model_name,\n",
    "    'accuracy': best_accuracy,\n",
    "    'f1_score': best_f1,\n",
    "    'class_mapping': {0: 'H', 1: 'D', 2: 'A'},\n",
    "    'class_names': {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
    "}, '../models/ps2_match_winner_model.joblib')\n",
    "\n",
    "print(f\"\\nüíæ Best model saved to: ../models/ps2_match_winner_model.joblib\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PS2: MATCH WINNER PREDICTION - COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüéØ Final Results:\")\n",
    "print(f\"   Best Model: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"   Test F1 Score: {best_f1:.4f}\")\n",
    "print(f\"\\nüìù Output Format for Deployment:\")\n",
    "print(f\"   Input: Home team stats, Away team stats\")\n",
    "print(f\"   Output: Team name (e.g., 'Manchester United') OR 'Draw'\")\n",
    "print(f\"   NO scores, NO probabilities, ONLY winner name or 'Draw'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
