{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d71b956",
   "metadata": {},
   "source": [
    "# Problem Statement 2: Match Winner Prediction\n",
    "## Predict Match Result (Home/Draw/Away)\n",
    "\n",
    "**Author:** ScoreSight ML Team  \n",
    "**Date:** 2025-11-12  \n",
    "**Problem Type:** Multi-class Classification\n",
    "\n",
    "### Dataset\n",
    "- **File:** `data/data_engineered_match_prediction.csv`\n",
    "- **Task:** Predict match winner\n",
    "- **Features:** Match statistics, team form (56+ engineered features)\n",
    "- **Target:** mw (Match winner code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113b22d",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721602ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    import lightgbm as lgb\n",
    "    BOTH_AVAILABLE = True\n",
    "except:\n",
    "    BOTH_AVAILABLE = False\n",
    "\n",
    "# For Colab: Base directory is /content/drive/MyDrive/ScoreSight\n",
    "SCORESIGHT_DIR = '/content/drive/MyDrive/ScoreSight'\n",
    "DATA_DIR = os.path.join(SCORESIGHT_DIR, 'data')\n",
    "MODELS_DIR = os.path.join(SCORESIGHT_DIR, 'models')\n",
    "\n",
    "Path(MODELS_DIR).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"[OK] Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c08d40",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(DATA_DIR, 'engineered', 'data_engineered_match_prediction.csv')\n",
    "print(f\"Loading from: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Target (mw) classes: {sorted(df['mw'].unique())}\")\n",
    "\n",
    "# Prepare features\n",
    "exclude_cols = ['mw', 'unnamed: 0']\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols and df[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "X = df[feature_cols].fillna(df[feature_cols].mean())\n",
    "y = df['mw'].values\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}, Samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d051d85f",
   "metadata": {},
   "source": [
    "## 3. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model):\n",
    "    return Pipeline([('imputer', SimpleImputer()), ('model', model)])\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=2000),\n",
    "    'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "if BOTH_AVAILABLE:\n",
    "    models['XGBoost'] = xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "    models['LightGBM'] = lgb.LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"[{name}] Training...\")\n",
    "    pipeline = create_pipeline(model)\n",
    "    pipeline.fit(X, y)\n",
    "    \n",
    "    scores = []\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        temp_pipeline = create_pipeline(model.__class__(**model.get_params()))\n",
    "        temp_pipeline.fit(X_train, y_train)\n",
    "        scores.append(f1_score(y_test, temp_pipeline.predict(X_test), average='macro'))\n",
    "    \n",
    "    results[name] = np.mean(scores)\n",
    "    trained_models[name] = pipeline\n",
    "    print(f\"  F1: {results[name]:.4f}\")\n",
    "\n",
    "print(\"\\n[OK] Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db895f1b",
   "metadata": {},
   "source": [
    "## 4. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = Path(MODELS_DIR)\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "best_name = max(results, key=results.get)\n",
    "best_f1 = results[best_name]\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    path = models_dir / f\"match_winner_{name.lower().replace(' ', '_')}_ps2.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"[SAVE] {name} -> {path}\")\n",
    "\n",
    "summary = {\n",
    "    'problem_statement': 'Match Winner Prediction',\n",
    "    'best_model': best_name,\n",
    "    'best_f1': float(best_f1),\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'models': {name: {'f1': float(results[name])} for name in results.keys()}\n",
    "}\n",
    "\n",
    "summary_path = models_dir / 'match_winner_training_summary_ps2.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n[COMPLETE] Best: {best_name} (F1: {best_f1:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
