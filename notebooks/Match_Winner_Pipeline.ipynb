{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d279ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MATCH WINNER PREDICTION PIPELINE\n",
      "================================================================================\n",
      "Setup completed at: 2025-11-20 02:33:30\n",
      "SMOTE Available: True\n",
      "XGBoost Available: True\n",
      "Neural Network (MLP) Available: True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# MATCH WINNER PREDICTION PIPELINE\n",
    "# ==================================================\n",
    "\n",
    "# Cell 1: Setup and Configuration\n",
    "# ==================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# SMOTE for handling class imbalance\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    SMOTE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Installing imbalanced-learn...\")\n",
    "    import subprocess, sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'imbalanced-learn'])\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    SMOTE_AVAILABLE = True\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"XGBoost not installed.\")\n",
    "\n",
    "# Neural Network using scikit-learn MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "NN_AVAILABLE = True  # Always available with scikit-learn\n",
    "\n",
    "# Configuration\n",
    "if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Paths\n",
    "MODELS_DIR = Path('models')\n",
    "VIZ_DIR = Path('visualizations/match_winner')\n",
    "DATASETS_DIR = Path('datasets')\n",
    "RAW_MATCH_DATA_PATH = DATASETS_DIR / 'Match Winner.csv'\n",
    "FINAL_DATA_PATH = Path('data/match_winner/match_winner_data.csv')\n",
    "REPORTS_DIR = Path('reports/match_winner')\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [MODELS_DIR, VIZ_DIR, FINAL_DATA_PATH.parent, REPORTS_DIR]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Constants\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "# ==================================================\n",
    "# UTILITY FUNCTIONS\n",
    "# ==================================================\n",
    "\n",
    "def check_data_quality(df):\n",
    "    \"\"\"\n",
    "    Perform comprehensive data quality check.\n",
    "    \"\"\"\n",
    "    print(\"Data Shape:\", df.shape)\n",
    "    print(\"\\nMissing Values:\\n\", df.isnull().sum()[df.isnull().sum() > 0])\n",
    "    print(\"\\nDuplicate Rows:\", df.duplicated().sum())\n",
    "    \n",
    "    # Check for constant columns\n",
    "    constant_cols = [col for col in df.columns if df[col].nunique() <= 1]\n",
    "    if constant_cols:\n",
    "        print(\"\\nConstant Columns (to drop):\", constant_cols)\n",
    "    else:\n",
    "        print(\"\\nNo constant columns found.\")\n",
    "\n",
    "def tune_hyperparameters(model_class, X_train, y_train, param_fn, n_trials=20, cv=5, scoring='f1_weighted', task_type='classification'):\n",
    "    \"\"\"\n",
    "    Reusable Optuna hyperparameter tuning function.\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        params = param_fn(trial)\n",
    "        model = model_class(**params)\n",
    "        \n",
    "        if task_type == 'classification':\n",
    "            cv_strategy = StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "        else:\n",
    "            cv_strategy = KFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
    "            \n",
    "        scores = cross_val_score(model, X_train, y_train, cv=cv_strategy, scoring=scoring, n_jobs=-1)\n",
    "        return scores.mean()\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "        \n",
    "    return study.best_params\n",
    "\n",
    "def evaluate_classification_model(model, X_test, y_test, model_name=\"Model\", class_names=None):\n",
    "    \"\"\"\n",
    "    Evaluate classification model and return metrics.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"--- {model_name} Evaluation ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "    print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "    \n",
    "    if y_prob is not None and len(np.unique(y_test)) > 2: # Multi-class AUC\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
    "            print(f\"ROC AUC (Weighted OVR): {roc_auc:.4f}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"Could not compute ROC AUC: {e}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names, zero_division=0))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1_Score': f1\n",
    "    }\n",
    "\n",
    "def plot_feature_importance(model, feature_names, top_n=20, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Plot feature importance for tree-based models.\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        # Adjust top_n to not exceed number of features\n",
    "        n_features = len(feature_names)\n",
    "        top_n = min(top_n, n_features)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.title(f\"Feature Importances - {model_name}\")\n",
    "        plt.bar(range(top_n), importances[indices[:top_n]], align=\"center\")\n",
    "        plt.xticks(range(top_n), [feature_names[i] for i in indices[:top_n]], rotation=90)\n",
    "        plt.xlim([-1, top_n])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"{model_name} does not support feature importance plotting (e.g., Keras, Logistic Regression).\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MATCH WINNER PREDICTION PIPELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Setup completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"SMOTE Available: {SMOTE_AVAILABLE}\")\n",
    "print(f\"XGBoost Available: {XGB_AVAILABLE}\")\n",
    "print(f\"Neural Network (MLP) Available: {NN_AVAILABLE}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73bdfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA LOADING\n",
      "================================================================================\n",
      "‚úì Standardized target column: Renamed 'ftr' to 'match_outcome'\n",
      "Data Shape: (6840, 40)\n",
      "\n",
      "Missing Values:\n",
      " Series([], dtype: int64)\n",
      "\n",
      "Duplicate Rows: 0\n",
      "\n",
      "No constant columns found.\n",
      "\n",
      "Columns: ['unnamed:_0', 'date', 'hometeam', 'awayteam', 'fthg', 'ftag', 'match_outcome', 'htgs', 'atgs', 'htgc', 'atgc', 'htp', 'atp', 'hm1', 'hm2', 'hm3', 'hm4', 'hm5', 'am1', 'am2', 'am3', 'am4', 'am5', 'mw', 'htformptsstr', 'atformptsstr', 'htformpts', 'atformpts', 'htwinstreak3', 'htwinstreak5', 'htlossstreak3', 'htlossstreak5', 'atwinstreak3', 'atwinstreak5', 'atlossstreak3', 'atlossstreak5', 'htgd', 'atgd', 'diffpts', 'diffformpts']\n",
      "\n",
      "================================================================================\n",
      "ADVANCED FEATURE ENGINEERING\n",
      "================================================================================\n",
      "‚úì Created 24 new features\n",
      "‚úì Total features: 64\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Loading and Advanced Feature Engineering\n",
    "# ==================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure necessary functions and paths (like check_data_quality, RAW_MATCH_DATA_PATH, FINAL_DATA_PATH) \n",
    "# are defined in a previous cell.\n",
    "\n",
    "def load_match_data(file_path):\n",
    "    \"\"\"\n",
    "    Load match data, standardize column names, and ensure the target column exists.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA LOADING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if not file_path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Standardize columns\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "    \n",
    "    # --- FIX: Standardize target column ---\n",
    "    # Look for common target column names and standardize to 'match_outcome'\n",
    "    possible_target_names = {\n",
    "        'ftr': 'match_outcome',\n",
    "        'result': 'match_outcome',\n",
    "        'final_result': 'match_outcome',\n",
    "        'match_result': 'match_outcome'\n",
    "    }\n",
    "    \n",
    "    renamed = False\n",
    "    for name, new_name in possible_target_names.items():\n",
    "        if name in df.columns and new_name not in df.columns:\n",
    "            df.rename(columns={name: new_name}, inplace=True)\n",
    "            print(f\"‚úì Standardized target column: Renamed '{name}' to '{new_name}'\")\n",
    "            renamed = True\n",
    "            break\n",
    "            \n",
    "    if 'match_outcome' not in df.columns:\n",
    "        print(\"! WARNING: Target column 'match_outcome' not found or standardized. Please check the CSV file.\")\n",
    "\n",
    "    # Quality Check\n",
    "    check_data_quality(df)\n",
    "    \n",
    "    print(\"\\nColumns:\", df.columns.tolist())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def engineer_advanced_features(df):\n",
    "    \"\"\"\n",
    "    Create advanced features for better prediction.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ADVANCED FEATURE ENGINEERING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    original_columns = df.columns.tolist()  # Store original columns\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert match result columns to numeric (they might be 'W', 'D', 'L' strings)\n",
    "    match_cols = ['hm1', 'hm2', 'hm3', 'hm4', 'hm5', 'am1', 'am2', 'am3', 'am4', 'am5']\n",
    "    for col in match_cols:\n",
    "        if col in df.columns and df[col].dtype == 'object':\n",
    "            df[col] = df[col].map({'W': 3, 'D': 1, 'L': 0}).fillna(0).astype(float)\n",
    "    \n",
    "    # 1. Goal Difference Features\n",
    "    df['home_goal_advantage'] = df['htgs'] - df['atgs']\n",
    "    df['away_goal_advantage'] = df['atgs'] - df['htgs']\n",
    "    df['home_defense_strength'] = df['htgs'] - df['htgc']\n",
    "    df['away_defense_strength'] = df['atgs'] - df['atgc']\n",
    "    \n",
    "    # 2. Form Momentum\n",
    "    df['form_momentum'] = df['htformpts'] - df['atformpts']\n",
    "    df['form_ratio'] = df['htformpts'] / (df['atformpts'] + 1)\n",
    "    \n",
    "    # 3. Streak Features\n",
    "    df['home_streak_advantage'] = df['htwinstreak3'] - df['atlossstreak3']\n",
    "    df['away_streak_advantage'] = df['atwinstreak3'] - df['htlossstreak3']\n",
    "    \n",
    "    # 4. Points Pressure Features\n",
    "    df['points_gap'] = df['diffpts']\n",
    "    df['points_ratio'] = (df['htp'] + 1) / (df['atp'] + 1)\n",
    "    \n",
    "    # 5. Recent Match Features (weighted)\n",
    "    df['home_recent_weighted'] = (df['hm1'] * 3 + df['hm2'] * 2 + df['hm3'] * 1) / 6\n",
    "    df['away_recent_weighted'] = (df['am1'] * 3 + df['am2'] * 2 + df['am3'] * 1) / 6\n",
    "    df['recent_form_diff'] = df['home_recent_weighted'] - df['away_recent_weighted']\n",
    "    \n",
    "    # 6. Attack vs Defense Matchup\n",
    "    df['home_attack_vs_away_defense'] = df['htgs'] / (df['atgc'] + 1)\n",
    "    df['away_attack_vs_home_defense'] = df['atgs'] / (df['htgc'] + 1)\n",
    "    \n",
    "    # 7. Goal Scoring Efficiency\n",
    "    df['home_goal_efficiency'] = df['htgs'] / (df['mw'] + 1)\n",
    "    df['away_goal_efficiency'] = df['atgs'] / (df['mw'] + 1)\n",
    "    df['goal_efficiency_diff'] = df['home_goal_efficiency'] - df['away_goal_efficiency']\n",
    "    \n",
    "    # 8. Consistency Features\n",
    "    home_recent_matches = df[['hm1', 'hm2', 'hm3', 'hm4', 'hm5']].values\n",
    "    away_recent_matches = df[['am1', 'am2', 'am3', 'am4', 'am5']].values\n",
    "    df['home_consistency'] = -np.var(home_recent_matches, axis=1)\n",
    "    df['away_consistency'] = -np.var(away_recent_matches, axis=1)\n",
    "    \n",
    "    # 9. Interaction Features\n",
    "    df['gd_x_formpts'] = df['htgd'] * df['htformpts']\n",
    "    df['streak_x_points'] = df['htwinstreak3'] * df['htp']\n",
    "    \n",
    "    # 10. Polynomial Features\n",
    "    df['htgd_squared'] = df['htgd'] ** 2\n",
    "    df['diffpts_squared'] = df['diffpts'] ** 2\n",
    "    \n",
    "    # --- FIX: Calculate new features without recalling load_match_data ---\n",
    "    new_features = [col for col in df.columns if col not in original_columns]\n",
    "    print(f\"‚úì Created {len(new_features)} new features\")\n",
    "    print(f\"‚úì Total features: {df.shape[1]}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- Execution ---\n",
    "df = load_match_data(RAW_MATCH_DATA_PATH)\n",
    "df = engineer_advanced_features(df)\n",
    "df.to_csv(FINAL_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a193cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: EDA\n",
    "# ==================================================\n",
    "\n",
    "def perform_eda(df, target_col):\n",
    "    \"\"\"\n",
    "    Perform EDA on the dataset, focusing on a curated set of non-betting features.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPLORATORY DATA ANALYSIS (EDA)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # --- Target Distribution ---\n",
    "    df_eda = df.copy()\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    if target_col in df_eda.columns and df_eda[target_col].dtype == 'object':\n",
    "        df_eda[target_col] = le.fit_transform(df_eda[target_col])\n",
    "        print(f\"Temporarily encoded '{target_col}' for visualization.\")\n",
    "\n",
    "    print(f\"\\nDistribution of Target Variable: '{target_col}'\")\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(x=target_col, data=df, palette='viridis', order=df[target_col].value_counts().index)\n",
    "    plt.title(f'Distribution of {target_col}')\n",
    "    plt.xlabel('Match Outcome')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    \n",
    "    # --- Correlation Matrix on a Curated Subset of Non-Betting Features ---\n",
    "    print(\"\\nGenerating Correlation Matrix for a curated subset of non-betting features...\")\n",
    "    \n",
    "    curated_features = [\n",
    "        # Key engineered features\n",
    "        'form_momentum', 'points_gap', 'home_attack_vs_away_defense', \n",
    "        'away_attack_vs_home_defense', 'recent_form_diff', 'home_consistency',\n",
    "        'home_goal_advantage', 'form_ratio', 'goal_efficiency_diff',\n",
    "        # Key original stats\n",
    "        'htgs', 'atgs', 'htgc', 'atgc', 'htformpts', 'atformpts',\n",
    "        # Target column\n",
    "        target_col\n",
    "    ]\n",
    "    \n",
    "    # Filter to only features that actually exist in the dataframe\n",
    "    existing_curated_features = [f for f in curated_features if f in df_eda.columns]\n",
    "    \n",
    "    if not existing_curated_features:\n",
    "        print(\"! Could not find any of the curated features for correlation analysis. Skipping heatmap.\")\n",
    "        return\n",
    "\n",
    "    print(f\"-> Plotting correlation for {len(existing_curated_features)} features.\")\n",
    "    \n",
    "    plt.figure(figsize=(16, 14))\n",
    "    corr_df = df_eda[existing_curated_features].copy()\n",
    "    corr_df.dropna(axis=1, how='all', inplace=True)\n",
    "    \n",
    "    if corr_df.empty:\n",
    "        print(\"! All selected columns for correlation were empty. Skipping heatmap.\")\n",
    "        return\n",
    "        \n",
    "    corr_matrix = corr_df.corr()\n",
    "    \n",
    "    sns.heatmap(\n",
    "        corr_matrix, \n",
    "        annot=True, \n",
    "        cmap='coolwarm', \n",
    "        fmt='.2f', \n",
    "        linewidths=0.5,\n",
    "        annot_kws={\"size\": 10}\n",
    "    )\n",
    "    plt.title('Correlation Matrix of Curated Non-Betting Features', fontsize=16)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Perform EDA on the dataframe from the previous cell\n",
    "perform_eda(df, 'match_outcome')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b84dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Feature Engineering & Selection\n",
    "# ==================================================\n",
    "\n",
    "def preprocess_data(df, target_col, top_n_features=15):\n",
    "    \"\"\"\n",
    "    Preprocess data for match winner prediction, excluding betting odds and leakage columns.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"FEATURE ENGINEERING & SELECTION (NO BETTING ODDS)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    data = df.copy()\n",
    "    \n",
    "    # --- Encode Target Variable ---\n",
    "    if not pd.api.types.is_numeric_dtype(data[target_col]):\n",
    "        print(f\"Encoding target variable '{target_col}'...\")\n",
    "        le = LabelEncoder()\n",
    "        data[target_col] = le.fit_transform(data[target_col])\n",
    "        class_names = list(le.classes_)\n",
    "        print(f\"‚úì Target classes: {dict(zip(range(len(class_names)), class_names))}\")\n",
    "    else:\n",
    "        le = None\n",
    "        class_names = sorted(data[target_col].unique())\n",
    "\n",
    "    # Drop rows with NaN in target\n",
    "    data.dropna(subset=[target_col], inplace=True)\n",
    "    \n",
    "    # --- Add all betting-related columns to the drop list ---\n",
    "    betting_cols = [col for col in data.columns if any(prefix in col for prefix in ['b365', 'bw', 'iw', 'lb', 'ps', 'wh', 'sj', 'vc', 'gb', 'bs'])]\n",
    "    \n",
    "    # --- CRITICAL: Define Leakage Columns (Match Stats) ---\n",
    "    # 'fthg' (Full Time Home Goals) and 'ftag' (Full Time Away Goals) are direct leakage.\n",
    "    leakage_cols = ['fthg', 'ftag', 'home_team_goal', 'away_team_goal']\n",
    "    \n",
    "    # Drop non-predictive, leakage, and betting columns\n",
    "    drop_cols = [\n",
    "        'match_api_id', 'home_team_api_id', 'away_team_api_id', \n",
    "        'date', \n",
    "        'home_player_1', 'home_player_2', 'home_player_3', 'home_player_4', 'home_player_5', \n",
    "        'home_player_6', 'home_player_7', 'home_player_8', 'home_player_9', 'home_player_10', 'home_player_11',\n",
    "        'away_player_1', 'away_player_2', 'away_player_3', 'away_player_4', 'away_player_5', \n",
    "        'away_player_6', 'away_player_7', 'away_player_8', 'away_player_9', 'away_player_10', 'away_player_11'\n",
    "    ] + betting_cols + leakage_cols\n",
    "    \n",
    "    y = data[target_col]\n",
    "    X = data.drop(columns=[target_col])\n",
    "    \n",
    "    # Drop the specified columns\n",
    "    initial_drop = sorted(list(set([c for c in drop_cols if c in X.columns])))\n",
    "    X = X.drop(columns=initial_drop, errors='ignore')\n",
    "    \n",
    "    # --- FIX: Identify and drop any remaining non-numeric columns before feature selection ---\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    if categorical_cols:\n",
    "        print(f\"\\n! Dropping remaining categorical columns before modeling: {categorical_cols}\")\n",
    "        X = X.drop(columns=categorical_cols, errors='ignore')\n",
    "    \n",
    "    # Combine all dropped columns for the report\n",
    "    dropped = sorted(list(set(initial_drop + categorical_cols)))\n",
    "\n",
    "    # Impute missing values (median for numeric)\n",
    "    numeric_cols = X.select_dtypes(include=np.number).columns\n",
    "    for col in numeric_cols:\n",
    "        if X[col].isnull().any():\n",
    "            median_val = X[col].median()\n",
    "            X[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    # Feature Selection using Mutual Information\n",
    "    from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "    print(\"\\nPerforming feature selection with Mutual Information...\")\n",
    "    mi_scores = mutual_info_classif(X, y)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    \n",
    "    # Select top N features\n",
    "    top_features = mi_scores.head(top_n_features).index.tolist()\n",
    "    \n",
    "    # Filter X to only include top features\n",
    "    X_selected = X[top_features]\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"FEATURE SELECTION SUMMARY\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"Target Column: {target_col}\")\n",
    "    print(f\"\\nExcluded Columns ({len(dropped)}): {', '.join(dropped)}\")\n",
    "    print(f\"\\nTop {top_n_features} Selected Features (based on Mutual Information):\")\n",
    "    for i, col in enumerate(X_selected.columns, 1):\n",
    "        print(f\"  {i}. {col} (MI Score: {mi_scores[col]:.4f})\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    print(f\"\\nTraining Shape: {X_train_scaled.shape}\")\n",
    "    print(f\"Testing Shape: {X_test_scaled.shape}\")\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, le\n",
    "\n",
    "# Preprocess data and select top 15 features\n",
    "X_train, X_test, y_train, y_test, scaler, label_encoder = preprocess_data(df, 'match_outcome', top_n_features=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Model Training and Tuning\n",
    "# ==================================================\n",
    "\n",
    "def train_match_models(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train and tune match winner models, including a Neural Network (MLP).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODEL TRAINING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    best_models = {}\n",
    "    \n",
    "    # 1. Logistic Regression\n",
    "    print(\"\\n--- Tuning Logistic Regression ---\")\n",
    "    def lr_params(trial):\n",
    "        return {\n",
    "            'C': trial.suggest_float('C', 0.01, 10.0, log=True),\n",
    "            'solver': trial.suggest_categorical('solver', ['lbfgs', 'liblinear']),\n",
    "            'class_weight': trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "            'max_iter': 1000\n",
    "        }\n",
    "    lr_best_params = tune_hyperparameters(\n",
    "        LogisticRegression, X_train, y_train, lr_params, n_trials=15, scoring='f1_weighted'\n",
    "    )\n",
    "    lr_model = LogisticRegression(**lr_best_params)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    best_models['LogisticRegression'] = lr_model\n",
    "    \n",
    "    # 2. Random Forest\n",
    "    print(\"\\n--- Tuning Random Forest ---\")\n",
    "    def rf_params(trial):\n",
    "        return {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 200, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 10, 30),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "            'class_weight': trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample']),\n",
    "            'random_state': RANDOM_STATE,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "    rf_best_params = tune_hyperparameters(\n",
    "        RandomForestClassifier, X_train, y_train, rf_params, n_trials=30, scoring='f1_weighted'\n",
    "    )\n",
    "    rf_model = RandomForestClassifier(**rf_best_params)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    best_models['RandomForest'] = rf_model\n",
    "    \n",
    "    # 3. XGBoost\n",
    "    if XGB_AVAILABLE:\n",
    "        print(\"\\n--- Tuning XGBoost ---\")\n",
    "        def xgb_params(trial):\n",
    "            return {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 200, 500),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "                'random_state': RANDOM_STATE,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "        xgb_best_params = tune_hyperparameters(\n",
    "            xgb.XGBClassifier, X_train, y_train, xgb_params, n_trials=30, scoring='f1_weighted'\n",
    "        )\n",
    "        xgb_model = xgb.XGBClassifier(**xgb_best_params)\n",
    "        xgb_model.fit(X_train, y_train)\n",
    "        best_models['XGBoost'] = xgb_model\n",
    "        \n",
    "    # 4. Gradient Boosting\n",
    "    print(\"\\n--- Tuning Gradient Boosting ---\")\n",
    "    def gb_params(trial):\n",
    "        return {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 200, 500),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'random_state': RANDOM_STATE\n",
    "        }\n",
    "    gb_best_params = tune_hyperparameters(\n",
    "        GradientBoostingClassifier, X_train, y_train, gb_params, n_trials=30, scoring='f1_weighted'\n",
    "    )\n",
    "    gb_model = GradientBoostingClassifier(**gb_best_params)\n",
    "    gb_model.fit(X_train, y_train)\n",
    "    best_models['GradientBoosting'] = gb_model\n",
    "        \n",
    "    # 5. Neural Network (Deeper MLPClassifier)\n",
    "    if NN_AVAILABLE:\n",
    "        print(\"\\n--- Tuning Deep Neural Network (MLP) ---\")\n",
    "        def mlp_params(trial):\n",
    "            layer1 = trial.suggest_int('layer1', 128, 512, step=64)\n",
    "            layer2 = trial.suggest_int('layer2', 64, 256, step=32)\n",
    "            layer3 = trial.suggest_int('layer3', 32, 128, step=32)\n",
    "            return {\n",
    "                'hidden_layer_sizes': (layer1, layer2, layer3),\n",
    "                'activation': trial.suggest_categorical('activation', ['relu', 'tanh']),\n",
    "                'alpha': trial.suggest_float('alpha', 0.0001, 0.01, log=True),\n",
    "                'learning_rate_init': trial.suggest_float('learning_rate_init', 0.0001, 0.01, log=True),\n",
    "                'learning_rate': trial.suggest_categorical('learning_rate', ['adaptive', 'constant']),\n",
    "                'max_iter': 500,\n",
    "                'early_stopping': True,\n",
    "                'validation_fraction': 0.15,\n",
    "                'random_state': RANDOM_STATE\n",
    "            }\n",
    "        mlp_best_params_raw = tune_hyperparameters(\n",
    "            MLPClassifier, X_train, y_train, mlp_params, n_trials=30, scoring='f1_weighted'\n",
    "        )\n",
    "        # Manually construct the correct parameters\n",
    "        mlp_best_params = {\n",
    "            'hidden_layer_sizes': (mlp_best_params_raw['layer1'], mlp_best_params_raw['layer2'], mlp_best_params_raw['layer3']),\n",
    "            'activation': mlp_best_params_raw['activation'],\n",
    "            'alpha': mlp_best_params_raw['alpha'],\n",
    "            'learning_rate_init': mlp_best_params_raw['learning_rate_init'],\n",
    "            'learning_rate': mlp_best_params_raw['learning_rate'],\n",
    "            'max_iter': 500,\n",
    "            'early_stopping': True,\n",
    "            'validation_fraction': 0.15,\n",
    "            'random_state': RANDOM_STATE\n",
    "        }\n",
    "        mlp_model = MLPClassifier(**mlp_best_params)\n",
    "        mlp_model.fit(X_train, y_train)\n",
    "        print(\"‚úì Deep Neural Network training complete.\")\n",
    "        best_models['NeuralNetwork'] = mlp_model\n",
    "    \n",
    "    # 6. Stacking Ensemble (Meta-Learner)\n",
    "    print(\"\\n--- Building Stacking Ensemble ---\")\n",
    "    from sklearn.ensemble import StackingClassifier\n",
    "    \n",
    "    base_estimators = [\n",
    "        ('rf', best_models['RandomForest']),\n",
    "        ('lr', best_models['LogisticRegression'])\n",
    "    ]\n",
    "    if 'XGBoost' in best_models:\n",
    "        base_estimators.append(('xgb', best_models['XGBoost']))\n",
    "    if 'GradientBoosting' in best_models:\n",
    "        base_estimators.append(('gb', best_models['GradientBoosting']))\n",
    "    if 'NeuralNetwork' in best_models:\n",
    "        base_estimators.append(('nn', best_models['NeuralNetwork']))\n",
    "    \n",
    "    # Use Logistic Regression as meta-learner\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=base_estimators,\n",
    "        final_estimator=LogisticRegression(C=1.0, max_iter=1000, random_state=RANDOM_STATE),\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f\"Training stacking ensemble with {len(base_estimators)} base models...\")\n",
    "    stacking_model.fit(X_train, y_train)\n",
    "    best_models['StackingEnsemble'] = stacking_model\n",
    "    print(\"‚úì Stacking Ensemble training complete.\")\n",
    "\n",
    "        \n",
    "    return best_models\n",
    "\n",
    "# Train all models\n",
    "best_models = train_match_models(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a167a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Evaluation\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "# --- FIX: Use the class names from the label encoder ---\n",
    "class_names = list(label_encoder.classes_) if label_encoder else sorted(y_train.unique())\n",
    "\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    metrics = evaluate_classification_model(\n",
    "        model, X_test, y_test, \n",
    "        model_name=name, \n",
    "        class_names=class_names\n",
    "    )\n",
    "    results.append(metrics)\n",
    "    \n",
    "    # Feature Importance (Tree models only)\n",
    "    if name in ['RandomForest', 'XGBoost', 'GradientBoosting']:\n",
    "        print(f\"\\nFeature Importance for {name}:\")\n",
    "        plot_feature_importance(model, X_train.columns, model_name=name)\n",
    "        \n",
    "    # Save model\n",
    "    model_path = MODELS_DIR / f'match_winner_{name}.joblib'\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"\\n‚úì Model saved to: {model_path}\")\n",
    "\n",
    "# Comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "results_df.to_csv(REPORTS_DIR / 'model_comparison.csv', index=False)\n",
    "print(f\"\\n‚úì Comparison saved to: {REPORTS_DIR / 'model_comparison.csv'}\")\n",
    "\n",
    "# Identify best model\n",
    "best_idx = results_df['F1_Score'].idxmax()\n",
    "best_model_name = results_df.loc[best_idx, 'Model']\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "# Save best model\n",
    "best_model_path = MODELS_DIR / 'match_winner_best_model.joblib'\n",
    "joblib.dump(best_model, best_model_path)\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   F1 Score: {results_df.loc[best_idx, 'F1_Score']:.4f}\")\n",
    "print(f\"   Accuracy: {results_df.loc[best_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"‚úì Best model saved to: {best_model_path}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = {\n",
    "    'pipeline': 'Match Winner Prediction',\n",
    "    'problem_statement': 'PS4 - Match Winner',\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'best_model': best_model_name,\n",
    "    'target_classes': class_names,\n",
    "    'metrics': results_df[results_df['Model'] == best_model_name].to_dict('records')[0],\n",
    "    'all_results': results_df.to_dict('records'),\n",
    "    'features_used': X_train.columns.tolist(),\n",
    "    'target_column': 'match_outcome', # Hardcode as it's now standardized\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'test_size': TEST_SIZE\n",
    "}\n",
    "\n",
    "metadata_path = MODELS_DIR / 'ps4_match_winner_metadata.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "print(f\"‚úì Metadata saved to: {metadata_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ MATCH WINNER PIPELINE COMPLETED!\")\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
