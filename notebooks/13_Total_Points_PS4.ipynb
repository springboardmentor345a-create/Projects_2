{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e58b827",
   "metadata": {},
   "source": [
    "# Problem Statement 4: Total Points Prediction\n",
    "## Predict Team Total Points in Season\n",
    "\n",
    "**Author:** ScoreSight ML Team  \n",
    "**Date:** 2025-11-12  \n",
    "**Problem Type:** Regression (Points Tally)\n",
    "\n",
    "### Dataset\n",
    "- **File:** `data/data_engineered_league_points.csv`\n",
    "- **Task:** Predict team's total season points\n",
    "- **Features:** Team statistics (22+ engineered features)\n",
    "- **Target:** target_total_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877146d1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97590871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "\n",
    "# GitHub configuration\n",
    "GITHUB_REPO = 'https://raw.githubusercontent.com/springboardmentor345a-create/Projects_2/Prathamesh_Fuke'\n",
    "DATA_URL_BASE = f'{GITHUB_REPO}/data/engineered'\n",
    "\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"[OK] All libraries imported\")\n",
    "print(f\"XGBoost: {XGB_AVAILABLE} | LightGBM: {LGB_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73a323",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6166ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (same file as PS1, different target)\n",
    "# Use GitHub URL if on Colab, local path otherwise\n",
    "import os\n",
    "if os.path.exists('../data/corrected/league_winner_with_top4.csv'):\n",
    "    data_path = '../data/corrected/league_winner_with_top4.csv'\n",
    "    print(f\"[LOAD] Loading from local file: {data_path}\")\n",
    "else:\n",
    "    data_path = 'https://raw.githubusercontent.com/springboardmentor345a-create/Projects_2/Prathamesh_Fuke/data/corrected/league_winner_with_top4.csv'\n",
    "    print(f\"[LOAD] Loading from GitHub: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "print(f\"[OK] Shape: {df.shape}\")\n",
    "print(f\"\\nðŸ“Š Target (target_total_points) Statistics:\")\n",
    "print(f\"  Mean: {df['target_total_points'].mean():.2f} points\")\n",
    "print(f\"  Std: {df['target_total_points'].std():.2f}\")\n",
    "print(f\"  Min: {df['target_total_points'].min()}, Max: {df['target_total_points'].max()}\")\n",
    "print(f\"  Median: {df['target_total_points'].median():.1f}\")\n",
    "\n",
    "# Prepare features - exclude ALL targets and identifiers\n",
    "exclude_cols = ['target_total_points', 'target_league_position', 'target_champion', 'top4',\n",
    "                'unnamed:_0', 'season_encoded', 'team_encoded', 'team', 'season']\n",
    "feature_cols = [col for col in df.columns \n",
    "               if col not in exclude_cols and df[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df['target_total_points'].copy()\n",
    "\n",
    "# Handle missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(f\"\\nâš ï¸  Found {X.isnull().sum().sum()} missing values - filling with column means\")\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "print(f\"\\n[OK] Features: {feature_cols}\")\n",
    "print(f\"[OK] Number of features: {len(feature_cols)}\")\n",
    "print(f\"[OK] Samples: {len(X)}\")\n",
    "\n",
    "# Train/test split (80/20)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n[SPLIT] Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(f\"[SPLIT] Train target stats: Mean={y_train.mean():.2f}, Std={y_train.std():.2f}\")\n",
    "print(f\"[SPLIT] Test target stats: Mean={y_test.mean():.2f}, Std={y_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfb1d8",
   "metadata": {},
   "source": [
    "## 3. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAIN/TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"[SPLIT] Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(f\"[SPLIT] Train target - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}\")\n",
    "print(f\"[SPLIT] Test target  - Mean: {y_test.mean():.2f}, Std: {y_test.std():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETER SEARCH SPACE - Total Points Regression (Small Dataset)\n",
    "# ============================================================================\n",
    "\n",
    "param_grids = {\n",
    "    'Ridge': {\n",
    "        'model__alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'model__alpha': [0.001, 0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [50, 100, 150],\n",
    "        'model__max_depth': [5, 10, 15, None],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model__n_estimators': [50, 100, 150],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__subsample': [0.8, 0.9]\n",
    "    }\n",
    "}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    param_grids['XGBoost'] = {\n",
    "        'model__n_estimators': [50, 100, 150],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [3, 5, 7],\n",
    "        'model__subsample': [0.8, 0.9]\n",
    "    }\n",
    "\n",
    "if LGB_AVAILABLE:\n",
    "    param_grids['LightGBM'] = {\n",
    "        'model__n_estimators': [50, 100, 150],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__num_leaves': [20, 30, 40]\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING WITH HYPERPARAMETER TUNING\n",
    "# ============================================================================\n",
    "\n",
    "def create_pipeline(model, use_scaling=True):\n",
    "    steps = [('imputer', SimpleImputer(strategy='mean'))]\n",
    "    if use_scaling:\n",
    "        steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', model))\n",
    "    return Pipeline(steps)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING - RandomizedSearchCV (Regression)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "best_models = {}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models_to_train = {\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42, max_iter=10000),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    models_to_train['XGBoost'] = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "if LGB_AVAILABLE:\n",
    "    models_to_train['LightGBM'] = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)\n",
    "\n",
    "for model_name, model in models_to_train.items():\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(f\"[{model_name}] Hyperparameter Tuning...\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    pipeline = create_pipeline(model)\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        n_iter=20,\n",
    "        cv=cv,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[model_name] = search.best_estimator_\n",
    "    print(f\"\\n[BEST] Params: {search.best_params_}\")\n",
    "    print(f\"[CV] MAE: {-search.best_score_:.4f}\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    y_pred = best_models[model_name].predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'best_params': search.best_params_,\n",
    "        'cv_mae': float(-search.best_score_),\n",
    "        'test_mae': float(mae),\n",
    "        'test_rmse': float(rmse),\n",
    "        'test_r2': float(r2)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n[TEST] MAE:  {mae:.4f}\")\n",
    "    print(f\"[TEST] RMSE: {rmse:.4f}\")\n",
    "    print(f\"[TEST] RÂ²:   {r2:.4f}\")\n",
    "    \n",
    "    # Residuals analysis\n",
    "    residuals = y_test - y_pred\n",
    "    print(f\"[TEST] Residuals - Mean: {residuals.mean():.4f}, Std: {residuals.std():.4f}\")\n",
    "    \n",
    "    trained_models[model_name] = best_models[model_name]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaeb25d",
   "metadata": {},
   "source": [
    "## 4. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf38693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IDENTIFY BEST MODEL\n",
    "# ============================================================================\n",
    "\n",
    "best_model_name = min(results, key=lambda x: results[x]['test_mae'])\n",
    "best_metrics = results[best_model_name]\n",
    "\n",
    "print(f\"\\n[WINNER] Best Model: {best_model_name}\")\n",
    "print(f\"[WINNER] Test MAE: {best_metrics['test_mae']:.4f}\")\n",
    "print(f\"[WINNER] Test RMSE: {best_metrics['test_rmse']:.4f}\")\n",
    "print(f\"[WINNER] Test RÂ²: {best_metrics['test_r2']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE ONLY THE BEST MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SAVING BEST MODEL\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Save only the best model\n",
    "best_model_path = models_dir / 'ps4_total_points_best_model.joblib'\n",
    "joblib.dump(trained_models[best_model_name], best_model_path)\n",
    "print(f\"[SAVE] Best Model ({best_model_name}) -> {best_model_path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE TRAINING SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "summary = {\n",
    "    'problem_statement': 'PS4: Total Points Tally Prediction',\n",
    "    'task_type': 'Regression',\n",
    "    'best_model': best_model_name,\n",
    "    'best_test_mae': best_metrics['test_mae'],\n",
    "    'best_test_rmse': best_metrics['test_rmse'],\n",
    "    'best_test_r2': best_metrics['test_r2'],\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'data': {\n",
    "        'path': data_path,\n",
    "        'shape': list(df.shape),\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'n_features': len(feature_cols)\n",
    "    },\n",
    "    'features': feature_cols,\n",
    "    'cv_strategy': '5-Fold KFold',\n",
    "    'tuning_method': 'RandomizedSearchCV (20 iterations)',\n",
    "    'scoring_metric': 'neg_mean_absolute_error',\n",
    "    'best_params': best_metrics['best_params']\n",
    "}\n",
    "\n",
    "summary_path = models_dir / 'ps4_total_points_metadata.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"[SAVE] Metadata -> {summary_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… PS4: TOTAL POINTS PREDICTION - COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
