{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ScoreSight - Part 2: Data Cleaning\n",
    "\n",
    "**Author:** Prathamesh Fuke  \n",
    "**Branch:** Prathamesh_Fuke  \n",
    "**Date:** October 28, 2025\n",
    "\n",
    "## Objective\n",
    "Clean the datasets by:\n",
    "- Handling missing values\n",
    "- Removing duplicates\n",
    "- Fixing data type issues\n",
    "- Handling outliers\n",
    "- Standardizing column names\n",
    "- Correcting inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"\u2713 Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw datasets from previous notebook\n",
    "print(\"Loading raw datasets...\")\n",
    "match_data = pd.read_csv('../data/raw/data_raw_match.csv')\n",
    "player_data = pd.read_csv('../data/raw/data_raw_player.csv')\n",
    "league_data = pd.read_csv('../data/raw/data_raw_league.csv')\n",
    "print(f\"\u2713 Match data: {match_data.shape}\")\n",
    "print(f\"\u2713 Player data: {player_data.shape}\")\n",
    "print(f\"\u2713 League data: {league_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Match Winner Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CLEANING MATCH WINNER DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "match_clean = match_data.copy()\n",
    "print(f\"\\nOriginal shape: {match_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "duplicates = match_clean.duplicated().sum()\n",
    "print(f\"\\nDuplicates found: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    match_clean = match_clean.drop_duplicates()\n",
    "    print(f\"\u2713 Removed {duplicates} duplicates\")\n",
    "    print(f\"New shape: {match_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"\\nHandling missing values...\")\n",
    "missing_before = match_clean.isnull().sum().sum()\n",
    "print(f\"Total missing values: {missing_before}\")\n",
    "\n",
    "if missing_before > 0:\n",
    "    # Identify numeric and categorical columns\n",
    "    numeric_cols = match_clean.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = match_clean.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Fill numeric columns with median\n",
    "    for col in numeric_cols:\n",
    "        if match_clean[col].isnull().sum() > 0:\n",
    "            median_val = match_clean[col].median()\n",
    "            match_clean[col].fillna(median_val, inplace=True)\n",
    "            print(f\"  \u2713 Filled '{col}' with median: {median_val}\")\n",
    "    \n",
    "    # Fill categorical columns with mode or 'Unknown'\n",
    "    for col in categorical_cols:\n",
    "        if match_clean[col].isnull().sum() > 0:\n",
    "            if not match_clean[col].mode().empty:\n",
    "                mode_val = match_clean[col].mode()[0]\n",
    "                match_clean[col].fillna(mode_val, inplace=True)\n",
    "                print(f\"  \u2713 Filled '{col}' with mode: {mode_val}\")\n",
    "            else:\n",
    "                match_clean[col].fillna('Unknown', inplace=True)\n",
    "                print(f\"  \u2713 Filled '{col}' with 'Unknown'\")\n",
    "    \n",
    "    missing_after = match_clean.isnull().sum().sum()\n",
    "    print(f\"\\n\u2713 Missing values reduced from {missing_before} to {missing_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names (lowercase, replace spaces with underscores)\n",
    "print(\"\\nStandardizing column names...\")\n",
    "match_clean.columns = match_clean.columns.str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "print(\"\u2713 Column names standardized\")\n",
    "print(f\"Columns: {list(match_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\u2713 Match data cleaned! Final shape: {match_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Player Data (Goals & Assists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CLEANING PLAYER DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "player_clean = player_data.copy()\n",
    "print(f\"\\nOriginal shape: {player_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "duplicates = player_clean.duplicated().sum()\n",
    "print(f\"\\nDuplicates found: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    player_clean = player_clean.drop_duplicates()\n",
    "    print(f\"\u2713 Removed {duplicates} duplicates\")\n",
    "    print(f\"New shape: {player_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"\\nHandling missing values...\")\n",
    "missing_before = player_clean.isnull().sum().sum()\n",
    "print(f\"Total missing values: {missing_before}\")\n",
    "\n",
    "if missing_before > 0:\n",
    "    # For player stats, missing goals/assists likely means 0\n",
    "    numeric_cols = player_clean.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = player_clean.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Fill numeric columns (goals, assists) with 0\n",
    "    for col in numeric_cols:\n",
    "        if player_clean[col].isnull().sum() > 0:\n",
    "            player_clean[col].fillna(0, inplace=True)\n",
    "            print(f\"  \u2713 Filled '{col}' with 0\")\n",
    "    \n",
    "    # Fill categorical columns\n",
    "    for col in categorical_cols:\n",
    "        if player_clean[col].isnull().sum() > 0:\n",
    "            if not player_clean[col].mode().empty:\n",
    "                mode_val = player_clean[col].mode()[0]\n",
    "                player_clean[col].fillna(mode_val, inplace=True)\n",
    "                print(f\"  \u2713 Filled '{col}' with mode: {mode_val}\")\n",
    "            else:\n",
    "                player_clean[col].fillna('Unknown', inplace=True)\n",
    "                print(f\"  \u2713 Filled '{col}' with 'Unknown'\")\n",
    "    \n",
    "    missing_after = player_clean.isnull().sum().sum()\n",
    "    print(f\"\\n\u2713 Missing values reduced from {missing_before} to {missing_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names\n",
    "print(\"\\nStandardizing column names...\")\n",
    "player_clean.columns = player_clean.columns.str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "print(\"\u2713 Column names standardized\")\n",
    "print(f\"Columns: {list(player_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\u2713 Player data cleaned! Final shape: {player_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clean League Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CLEANING LEAGUE DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "league_clean = league_data.copy()\n",
    "print(f\"\\nOriginal shape: {league_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "duplicates = league_clean.duplicated().sum()\n",
    "print(f\"\\nDuplicates found: {duplicates}\")\n",
    "if duplicates > 0:\n",
    "    league_clean = league_clean.drop_duplicates()\n",
    "    print(f\"\u2713 Removed {duplicates} duplicates\")\n",
    "    print(f\"New shape: {league_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"\\nHandling missing values...\")\n",
    "missing_before = league_clean.isnull().sum().sum()\n",
    "print(f\"Total missing values: {missing_before}\")\n",
    "\n",
    "if missing_before > 0:\n",
    "    numeric_cols = league_clean.select_dtypes(include=[np.number]).columns\n",
    "    categorical_cols = league_clean.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    # Fill numeric columns with median\n",
    "    for col in numeric_cols:\n",
    "        if league_clean[col].isnull().sum() > 0:\n",
    "            median_val = league_clean[col].median()\n",
    "            league_clean[col].fillna(median_val, inplace=True)\n",
    "            print(f\"  \u2713 Filled '{col}' with median: {median_val}\")\n",
    "    \n",
    "    # Fill categorical columns\n",
    "    for col in categorical_cols:\n",
    "        if league_clean[col].isnull().sum() > 0:\n",
    "            if not league_clean[col].mode().empty:\n",
    "                mode_val = league_clean[col].mode()[0]\n",
    "                league_clean[col].fillna(mode_val, inplace=True)\n",
    "                print(f\"  \u2713 Filled '{col}' with mode: {mode_val}\")\n",
    "            else:\n",
    "                league_clean[col].fillna('Unknown', inplace=True)\n",
    "                print(f\"  \u2713 Filled '{col}' with 'Unknown'\")\n",
    "    \n",
    "    missing_after = league_clean.isnull().sum().sum()\n",
    "    print(f\"\\n\u2713 Missing values reduced from {missing_before} to {missing_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column names\n",
    "print(\"\\nStandardizing column names...\")\n",
    "league_clean.columns = league_clean.columns.str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "print(\"\u2713 Column names standardized\")\n",
    "print(f\"Columns: {list(league_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n\u2713 League data cleaned! Final shape: {league_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DATA QUALITY VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "datasets = {\n",
    "    'Match Data': (match_data, match_clean),\n",
    "    'Player Data': (player_data, player_clean),\n",
    "    'League Data': (league_data, league_clean)\n",
    "}\n",
    "\n",
    "for name, (original, cleaned) in datasets.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Original rows: {len(original):,} \u2192 Cleaned rows: {len(cleaned):,}\")\n",
    "    print(f\"  Missing values: {original.isnull().sum().sum():,} \u2192 {cleaned.isnull().sum().sum():,}\")\n",
    "    print(f\"  Duplicates: {original.duplicated().sum():,} \u2192 {cleaned.duplicated().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSaving cleaned datasets...\")\n",
    "match_clean.to_csv('../data/cleaned/data_cleaned_match.csv', index=False)\n",
    "player_clean.to_csv('../data/cleaned/data_cleaned_player.csv', index=False)\n",
    "league_clean.to_csv('../data/cleaned/data_cleaned_league.csv', index=False)\n",
    "print(\"\\n\u2713 All cleaned datasets saved!\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOTEBOOK 02 COMPLETED - Ready for Feature Engineering\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}