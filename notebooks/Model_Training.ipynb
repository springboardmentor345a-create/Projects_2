{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851d0edc",
   "metadata": {},
   "source": [
    "# ScoreSight: Unified Model Training Pipeline\n",
    "\n",
    "**Author:** Prathamesh Fuke  \n",
    "**Project:** EPL Football Analytics & Prediction  \n",
    "**Branch:** Prathamesh_Fuke  \n",
    "**Date:** November 13, 2025\n",
    "\n",
    "## Notebook Overview\n",
    "\n",
    "This notebook consolidates all model training tasks from the original 7 problem-specific notebooks (08, 10-14) into a single, comprehensive training pipeline.\n",
    "\n",
    "### Problem Statements Covered:\n",
    "\n",
    "| Problem | Type | Target | Dataset | Metric |\n",
    "|---------|------|--------|---------|--------|\n",
    "| **PS1** | Classification | League Champion | Points Tally | F1-Macro |\n",
    "| **PS2** | Classification | Match Winner (H/NH) | Match Winner | F1-Macro |\n",
    "| **PS3** | Regression | Top Scorer Goals | Top Scorer | MAE, R² |\n",
    "| **PS4** | Regression | Total Points | Points Tally | MAE, R² |\n",
    "| **PS5** | Classification | Match Result (H/D/A) | Raw Match | F1-Macro |\n",
    "| **v1** | Regression | Home Goals (FTHG) | Engineered Match v3 | MAE |\n",
    "\n",
    "### Key Features:\n",
    "- ✅ **Temporal Cross-Validation** - Respects time series nature of sports data\n",
    "- ✅ **Data Leakage Prevention** - Removes future information (e.g., `points_per_game`)\n",
    "- ✅ **Hyperparameter Tuning** - RandomizedSearchCV / GridSearchCV for optimization\n",
    "- ✅ **Model Persistence** - Saves best models and metadata for deployment\n",
    "- ✅ **Comprehensive Evaluation** - Final comparison across all problem statements\n",
    "\n",
    "### Expected Outputs:\n",
    "- `models/ps1_league_winner_*.joblib` & `*.json`\n",
    "- `models/ps2_match_winner_*.joblib` & `*.json`\n",
    "- `models/ps3_top_scorer_*.joblib` & `*.json`\n",
    "- `models/ps4_total_points_*.joblib` & `*.json`\n",
    "- `models/ps5_match_result_*.joblib` & `*.json`\n",
    "- `data/engineered/model_training_summary_v1.json`\n",
    "- `visualizations/final_model_performance_comparison.png`\n",
    "\n",
    "---\n",
    "\n",
    "## Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e026cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 1: Setup and Configuration\n",
    "# ==================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Force output to show immediately\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, RandomizedSearchCV, cross_val_score,\n",
    "    TimeSeriesSplit, StratifiedKFold, KFold, train_test_split\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor,\n",
    "    RandomForestClassifier, GradientBoostingClassifier\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"IMPORTING LIBRARIES...\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Try importing XGBoost and LightGBM\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "    print(\"XGBoost available\")\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "    print(\"XGBoost not installed\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "    print(\"LightGBM available\")\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "    print(\"LightGBM not installed\")\n",
    "\n",
    "# Global Configuration\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"CONFIGURING PATHS...\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Adjust working directory if needed\n",
    "try:\n",
    "    if os.path.exists('d:\\\\ScoreSight'):\n",
    "        os.chdir('d:\\\\ScoreSight')\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "except:\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Create directory structure\n",
    "MODELS_DIR = Path('models')\n",
    "VIZ_DIR = Path('visualizations')\n",
    "REPORTS_DIR = Path('reports')\n",
    "LOGS_DIR = Path('logs')\n",
    "\n",
    "for dir_path in [MODELS_DIR, VIZ_DIR, REPORTS_DIR, LOGS_DIR]:\n",
    "    dir_path.mkdir(exist_ok=True)\n",
    "    print(f\"Created/verified: {dir_path}\")\n",
    "\n",
    "# Dataset paths\n",
    "LEAGUE_WINNER_PATH = Path('data/league_winner/league_winner_data.csv')\n",
    "MATCH_WINNER_PATH = Path('data/match_winner/match_winner_data.csv')\n",
    "TOP_SCORER_PATH = Path('data/top_scorer/top_scorer_data.csv')\n",
    "MATCH_RESULT_PATH = Path('data/match_result/match_result_data.csv')\n",
    "POINTS_TALLY_PATH = Path('data/points_tally/points_tally_data.csv')\n",
    "\n",
    "# Display options\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Training session metadata\n",
    "TRAINING_SESSION = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'models_trained': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"PRODUCTION MODEL TRAINING PIPELINE\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nSession ID: {TRAINING_SESSION['timestamp']}\")\n",
    "print(\"\\nAll libraries imported and paths configured\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7030b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 2: Enhanced Helper Functions\n",
    "# ==================================================\n",
    "\n",
    "def display_feature_info(X, y, problem_name, target_col, excluded_cols):\n",
    "    \"\"\"Display comprehensive feature and target information\"\"\"\n",
    "    print(f\"\\n{'=' * 100}\")\n",
    "    print(f\"DATASET OVERVIEW: {problem_name}\")\n",
    "    print(f\"{'=' * 100}\")\n",
    "    \n",
    "    print(f\"\\nTARGET COLUMN: '{target_col}'\")\n",
    "    print(f\"   Distribution:\")\n",
    "    if y.dtype in ['int64', 'float64'] and y.nunique() < 20:\n",
    "        print(y.value_counts().to_string())\n",
    "    else:\n",
    "        print(f\"   Mean: {y.mean():.2f}, Std: {y.std():.2f}\")\n",
    "        print(f\"   Min: {y.min():.2f}, Max: {y.max():.2f}\")\n",
    "    \n",
    "    print(f\"\\nFEATURE COLUMNS ({len(X.columns)}):\")\n",
    "    for i, col in enumerate(X.columns, 1):\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nEXCLUDED COLUMNS ({len(excluded_cols)}):\")\n",
    "    for i, col in enumerate(excluded_cols, 1):\n",
    "        print(f\"   {i:2d}. {col}\")\n",
    "    \n",
    "    print(f\"\\nDATASET SHAPE: {X.shape[0]} samples x {X.shape[1]} features\")\n",
    "    print(f\"{'=' * 100}\\n\")\n",
    "\n",
    "\n",
    "def detect_outliers(X, threshold=1.5):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    print(f\"\\nOUTLIER DETECTION (IQR method, threshold={threshold})\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    outlier_info = {}\n",
    "    for col in X.columns:\n",
    "        Q1 = X[col].quantile(0.25)\n",
    "        Q3 = X[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        \n",
    "        outliers = X[(X[col] < lower_bound) | (X[col] > upper_bound)]\n",
    "        outlier_count = len(outliers)\n",
    "        outlier_pct = (outlier_count / len(X)) * 100\n",
    "        \n",
    "        outlier_info[col] = {\n",
    "            'count': outlier_count,\n",
    "            'percentage': outlier_pct,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound\n",
    "        }\n",
    "    \n",
    "    # Display top outliers\n",
    "    print(\"\\nTop 10 features with most outliers:\")\n",
    "    sorted_outliers = sorted(outlier_info.items(), \n",
    "                            key=lambda x: x[1]['count'], \n",
    "                            reverse=True)[:10]\n",
    "    \n",
    "    for col, stats in sorted_outliers:\n",
    "        if stats['count'] > 0:\n",
    "            print(f\"  {col}: {stats['count']} outliers ({stats['percentage']:.1f}%)\")\n",
    "    \n",
    "    return outlier_info\n",
    "\n",
    "\n",
    "def handle_outliers(X, outlier_info, method='cap'):\n",
    "    \"\"\"Handle outliers using capping method\"\"\"\n",
    "    print(f\"\\nHandling outliers using {method} method...\")\n",
    "    X_clean = X.copy()\n",
    "    \n",
    "    for col in X_clean.columns:\n",
    "        if col in outlier_info:\n",
    "            lower_bound = outlier_info[col]['lower_bound']\n",
    "            upper_bound = outlier_info[col]['upper_bound']\n",
    "            X_clean[col] = X_clean[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "    print(\"Outliers handled successfully\")\n",
    "    return X_clean\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, problem_name, save_dir):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'{problem_name} - Confusion Matrix\\n{model_name}', \n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    \n",
    "    save_path = save_dir / f'{problem_name.lower().replace(\" \", \"_\")}_confusion_matrix.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Confusion matrix saved to: {save_path}\")\n",
    "\n",
    "\n",
    "def plot_roc_curve(y_true, y_proba, model_name, problem_name, save_dir):\n",
    "    \"\"\"Plot ROC curve for binary classification\"\"\"\n",
    "    if len(np.unique(y_true)) == 2:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_proba[:, 1])\n",
    "        roc_auc = roc_auc_score(y_true, y_proba[:, 1])\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', \n",
    "                label='Random Classifier')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate', fontsize=12)\n",
    "        plt.ylabel('True Positive Rate', fontsize=12)\n",
    "        plt.title(f'{problem_name} - ROC Curve\\n{model_name}', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.legend(loc=\"lower right\", fontsize=11)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        save_path = save_dir / f'{problem_name.lower().replace(\" \", \"_\")}_roc_curve.png'\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"ROC curve saved to: {save_path}\")\n",
    "        return roc_auc\n",
    "    return None\n",
    "\n",
    "\n",
    "def plot_feature_importance(model, feature_names, problem_name, save_dir, top_n=15):\n",
    "    \"\"\"Plot feature importance for tree-based models\"\"\"\n",
    "    try:\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "        elif hasattr(model, 'named_steps') and hasattr(model.named_steps['model'], 'feature_importances_'):\n",
    "            importances = model.named_steps['model'].feature_importances_\n",
    "        else:\n",
    "            print(\"Model doesn't support feature importance\")\n",
    "            return\n",
    "        \n",
    "        feat_imp_df = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False).head(top_n)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.barplot(data=feat_imp_df, y='feature', x='importance', palette='viridis')\n",
    "        plt.title(f'{problem_name} - Top {top_n} Feature Importances', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Importance Score', fontsize=12)\n",
    "        plt.ylabel('Feature', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        save_path = save_dir / f'{problem_name.lower().replace(\" \", \"_\")}_feature_importance.png'\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        print(f\"Feature importance plot saved to: {save_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not plot feature importance: {e}\")\n",
    "\n",
    "\n",
    "def plot_regression_results(y_true, y_pred, model_name, problem_name, save_dir):\n",
    "    \"\"\"Plot regression predictions vs actual\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[0].scatter(y_true, y_pred, alpha=0.6, edgecolors='k', linewidths=0.5)\n",
    "    axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], \n",
    "                'r--', lw=2, label='Perfect Prediction')\n",
    "    axes[0].set_xlabel('Actual Values', fontsize=12)\n",
    "    axes[0].set_ylabel('Predicted Values', fontsize=12)\n",
    "    axes[0].set_title(f'{problem_name} - Predictions vs Actual\\n{model_name}', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Residuals\n",
    "    residuals = y_true - y_pred\n",
    "    axes[1].scatter(y_pred, residuals, alpha=0.6, edgecolors='k', linewidths=0.5)\n",
    "    axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    axes[1].set_xlabel('Predicted Values', fontsize=12)\n",
    "    axes[1].set_ylabel('Residuals', fontsize=12)\n",
    "    axes[1].set_title(f'{problem_name} - Residual Plot\\n{model_name}', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = save_dir / f'{problem_name.lower().replace(\" \", \"_\")}_regression_results.png'\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Regression results saved to: {save_path}\")\n",
    "\n",
    "\n",
    "print(\"Enhanced helper functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 3: Production Model Trainer Class\n",
    "# ==================================================\n",
    "\n",
    "class ProductionModelTrainer:\n",
    "    \"\"\"Production-grade model training with comprehensive logging and visualization\"\"\"\n",
    "    \n",
    "    def __init__(self, problem_name, task_type, target_col):\n",
    "        self.problem_name = problem_name\n",
    "        self.task_type = task_type\n",
    "        self.target_col = target_col\n",
    "        self.training_log = {\n",
    "            'problem': problem_name,\n",
    "            'task_type': task_type,\n",
    "            'target': target_col,\n",
    "            'start_time': datetime.now().isoformat(),\n",
    "            'models_attempted': [],\n",
    "            'best_model': None,\n",
    "            'training_duration_seconds': 0\n",
    "        }\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def train_with_logging(self, X_train, y_train, X_test, y_test, \n",
    "                          model_configs, param_grids, cv_strategy, scoring):\n",
    "        \"\"\"Train multiple models with comprehensive logging and visualization\"\"\"\n",
    "        print(f\"\\n{'=' * 100}\")\n",
    "        print(f\"TRAINING: {self.problem_name}\")\n",
    "        print(f\"{'=' * 100}\")\n",
    "        print(f\"Task Type: {self.task_type}\")\n",
    "        print(f\"Training samples: {X_train.shape[0]} | Test samples: {X_test.shape[0]}\")\n",
    "        print(f\"Features: {X_train.shape[1]}\")\n",
    "        print(f\"CV Strategy: {cv_strategy}\")\n",
    "        print(f\"Scoring: {scoring}\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for model_name, model in model_configs.items():\n",
    "            if model_name not in param_grids:\n",
    "                print(f\"\\nSkipping {model_name} (no param grid)\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n{'-' * 80}\")\n",
    "            print(f\"Training: {model_name}\")\n",
    "            print(f\"{'-' * 80}\")\n",
    "            \n",
    "            model_start = time.time()\n",
    "            \n",
    "            # Create pipeline with reduced complexity to avoid overfitting\n",
    "            pipeline = Pipeline([\n",
    "                ('imputer', SimpleImputer(strategy='median' if self.task_type == 'classification' else 'mean')),\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('model', model)\n",
    "            ])\n",
    "            \n",
    "            # Parameter search with reduced iterations\n",
    "            param_grid = param_grids[model_name]\n",
    "            \n",
    "            # Use fewer iterations to prevent overfitting\n",
    "            n_iter = min(10, np.prod([len(v) for v in param_grid.values()]))\n",
    "            \n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=pipeline,\n",
    "                param_distributions=param_grid,\n",
    "                n_iter=n_iter,\n",
    "                cv=cv_strategy,\n",
    "                scoring=scoring,\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "                verbose=0,\n",
    "                return_train_score=True\n",
    "            )\n",
    "            \n",
    "            search.fit(X_train, y_train)\n",
    "            y_pred = search.predict(X_test)\n",
    "            \n",
    "            test_metrics = {}\n",
    "            if self.task_type == 'classification':\n",
    "                test_metrics['accuracy'] = float(accuracy_score(y_test, y_pred))\n",
    "                test_metrics['f1_macro'] = float(f1_score(y_test, y_pred, average='macro'))\n",
    "                test_metrics['precision_macro'] = float(precision_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "                test_metrics['recall_macro'] = float(recall_score(y_test, y_pred, average='macro', zero_division=0))\n",
    "                \n",
    "                print(f\"{model_name} Results:\")\n",
    "                print(f\"  Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
    "                print(f\"  F1-Macro:  {test_metrics['f1_macro']:.4f}\")\n",
    "                print(f\"  Precision: {test_metrics['precision_macro']:.4f}\")\n",
    "                print(f\"  Recall:    {test_metrics['recall_macro']:.4f}\")\n",
    "                \n",
    "            else:  # Regression\n",
    "                test_metrics['mae'] = float(mean_absolute_error(y_test, y_pred))\n",
    "                test_metrics['mse'] = float(mean_squared_error(y_test, y_pred))\n",
    "                test_metrics['rmse'] = float(np.sqrt(test_metrics['mse']))\n",
    "                test_metrics['r2'] = float(r2_score(y_test, y_pred))\n",
    "                \n",
    "                print(f\"{model_name} Results:\")\n",
    "                print(f\"  MAE:  {test_metrics['mae']:.4f}\")\n",
    "                print(f\"  RMSE: {test_metrics['rmse']:.4f}\")\n",
    "                print(f\"  R2:   {test_metrics['r2']:.4f}\")\n",
    "            \n",
    "            # Calculate CV score variance to detect overfitting\n",
    "            cv_results = search.cv_results_\n",
    "            best_idx = search.best_index_\n",
    "            train_score = cv_results['mean_train_score'][best_idx]\n",
    "            val_score = cv_results['mean_test_score'][best_idx]\n",
    "            \n",
    "            print(f\"  CV Train Score: {abs(train_score):.4f}\")\n",
    "            print(f\"  CV Val Score:   {abs(val_score):.4f}\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            model_time = time.time() - model_start\n",
    "            print(f\"  Time: {model_time:.2f}s\")\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'model': search.best_estimator_,\n",
    "                'best_params': search.best_params_,\n",
    "                'cv_score': search.best_score_,\n",
    "                'test_metrics': test_metrics,\n",
    "                'y_pred': y_pred,\n",
    "                'train_score': train_score,\n",
    "                'val_score': val_score\n",
    "            }\n",
    "            \n",
    "            # Log to training session\n",
    "            self.training_log['models_attempted'].append({\n",
    "                'model_name': model_name,\n",
    "                'test_metrics': test_metrics,\n",
    "                'cv_score': float(search.best_score_),\n",
    "                'training_time': model_time\n",
    "            })\n",
    "        \n",
    "        # Determine best model\n",
    "        if self.task_type == 'classification':\n",
    "            best_name = max(results.keys(), key=lambda k: results[k]['test_metrics']['f1_macro'])\n",
    "        else:\n",
    "            best_name = min(results.keys(), key=lambda k: results[k]['test_metrics']['mae'])\n",
    "        \n",
    "        print(f\"\\n{'=' * 100}\")\n",
    "        print(f\"BEST MODEL: {best_name}\")\n",
    "        print(f\"{'=' * 100}\")\n",
    "        \n",
    "        self.training_log['best_model'] = best_name\n",
    "        self.training_log['end_time'] = datetime.now().isoformat()\n",
    "        self.training_log['training_duration_seconds'] = time.time() - self.start_time\n",
    "        \n",
    "        # Generate visualizations\n",
    "        best_model = results[best_name]['model']\n",
    "        y_pred_best = results[best_name]['y_pred']\n",
    "        \n",
    "        if self.task_type == 'classification':\n",
    "            # Confusion Matrix\n",
    "            plot_confusion_matrix(y_test, y_pred_best, best_name, self.problem_name, VIZ_DIR)\n",
    "            \n",
    "            # ROC Curve (if binary)\n",
    "            try:\n",
    "                y_proba = best_model.predict_proba(X_test)\n",
    "                plot_roc_curve(y_test, y_proba, best_name, self.problem_name, VIZ_DIR)\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            # Regression plots\n",
    "            plot_regression_results(y_test, y_pred_best, best_name, self.problem_name, VIZ_DIR)\n",
    "        \n",
    "        # Feature importance\n",
    "        plot_feature_importance(best_model, X_train.columns, self.problem_name, VIZ_DIR)\n",
    "        \n",
    "        return {\n",
    "            'best_model_name': best_name,\n",
    "            'best_model': best_model,\n",
    "            'all_results': results,\n",
    "            'training_log': self.training_log\n",
    "        }\n",
    "    \n",
    "    def save_results(self, results, model_path, metadata_path):\n",
    "        \"\"\"Save model and metadata\"\"\"\n",
    "        joblib.dump(results['best_model'], model_path)\n",
    "        \n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(results['training_log'], f, indent=2)\n",
    "        \n",
    "        print(f\"\\nModel saved: {model_path}\")\n",
    "        print(f\"Metadata saved: {metadata_path}\")\n",
    "\n",
    "\n",
    "print(\"ProductionModelTrainer class loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8139f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 4: PROBLEM STATEMENT 1 - LEAGUE WINNER PREDICTION\n",
    "# Binary Classification: Predict league champion\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"PS1: LEAGUE WINNER PREDICTION\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Load dataset\n",
    "print(f\"\\nLoading: {LEAGUE_WINNER_PATH}\")\n",
    "try:\n",
    "    df_ps1 = pd.read_csv(LEAGUE_WINNER_PATH)\n",
    "    print(f\"Loaded {df_ps1.shape[0]} samples, {df_ps1.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at {LEAGUE_WINNER_PATH}\")\n",
    "    print(\"Skipping PS1\")\n",
    "    df_ps1 = None\n",
    "\n",
    "if df_ps1 is not None:\n",
    "    # Normalize column names\n",
    "    df_ps1.columns = df_ps1.columns.str.lower().str.strip()\n",
    "    \n",
    "    # Display all available columns\n",
    "    print(f\"\\nAvailable columns in dataset:\")\n",
    "    for i, col in enumerate(df_ps1.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    # Define target column\n",
    "    TARGET_COL_PS1 = 'target_champion'\n",
    "    \n",
    "    # Verify target exists\n",
    "    if TARGET_COL_PS1 not in df_ps1.columns:\n",
    "        print(f\"\\nERROR: Target column '{TARGET_COL_PS1}' not found!\")\n",
    "        print(\"Skipping PS1\")\n",
    "    else:\n",
    "        # CRITICAL: Exclude columns that directly determine or are derived from the target\n",
    "        EXCLUDE_COLS_PS1 = [\n",
    "            'target_champion',     # Target itself\n",
    "            'target_top_4',        # Related classification targets\n",
    "            'target_top_6',\n",
    "            'target_relegated',\n",
    "            'wins',                # Wins/draws/losses directly determine points\n",
    "            'draws',\n",
    "            'losses',\n",
    "            'points',              # Directly correlated with champion\n",
    "            'points_per_game',     # Derived from points\n",
    "            'season',              # Identifier, not predictive\n",
    "            'team',                # Identifier\n",
    "            'unnamed: 0'           # Index column\n",
    "        ]\n",
    "        \n",
    "        # Select only numeric features not in exclude list\n",
    "        numeric_cols = df_ps1.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        feature_cols_ps1 = [c for c in numeric_cols \n",
    "                           if c not in [col.lower() for col in EXCLUDE_COLS_PS1]]\n",
    "        \n",
    "        # Filter out columns that exist in the dataframe\n",
    "        feature_cols_ps1 = [c for c in feature_cols_ps1 if c in df_ps1.columns]\n",
    "        \n",
    "        if len(feature_cols_ps1) == 0:\n",
    "            print(\"\\nERROR: No valid features found after exclusion!\")\n",
    "            print(\"Skipping PS1\")\n",
    "        else:\n",
    "            X_ps1 = df_ps1[feature_cols_ps1].copy()\n",
    "            y_ps1 = df_ps1[TARGET_COL_PS1].astype(int)\n",
    "            \n",
    "            # Display feature information\n",
    "            display_feature_info(X_ps1, y_ps1, 'PS1: League Winner', \n",
    "                               TARGET_COL_PS1, EXCLUDE_COLS_PS1)\n",
    "            \n",
    "            # Check for class imbalance\n",
    "            print(\"\\nClass distribution:\")\n",
    "            print(y_ps1.value_counts())\n",
    "            print(f\"\\nClass balance ratio: {y_ps1.value_counts().min() / y_ps1.value_counts().max():.2f}\")\n",
    "            \n",
    "            # Detect outliers\n",
    "            outliers_ps1 = detect_outliers(X_ps1, threshold=1.5)\n",
    "            \n",
    "            # Handle outliers\n",
    "            X_ps1_clean = handle_outliers(X_ps1, outliers_ps1, method='cap')\n",
    "            \n",
    "            # Stratified split to maintain class balance\n",
    "            X_train_ps1, X_test_ps1, y_train_ps1, y_test_ps1 = train_test_split(\n",
    "                X_ps1_clean, y_ps1, test_size=0.25, random_state=42, stratify=y_ps1\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nData split: {X_train_ps1.shape[0]} train / {X_test_ps1.shape[0]} test\")\n",
    "            print(f\"Train class distribution:\\n{y_train_ps1.value_counts()}\")\n",
    "            print(f\"Test class distribution:\\n{y_test_ps1.value_counts()}\")\n",
    "            \n",
    "            # Model configurations with regularization to prevent overfitting\n",
    "            models_ps1 = {\n",
    "                'RandomForest': RandomForestClassifier(\n",
    "                    random_state=42, \n",
    "                    class_weight='balanced',\n",
    "                    max_depth=10,  # Limit depth\n",
    "                    min_samples_leaf=5  # Require more samples per leaf\n",
    "                ),\n",
    "                'GradientBoosting': GradientBoostingClassifier(\n",
    "                    random_state=42,\n",
    "                    max_depth=5,  # Limit depth\n",
    "                    min_samples_leaf=5\n",
    "                )\n",
    "            }\n",
    "            \n",
    "            if XGB_AVAILABLE:\n",
    "                pos = y_train_ps1.sum()\n",
    "                neg = len(y_train_ps1) - pos\n",
    "                spw = max((neg / pos) if pos > 0 else 1.0, 1.0)\n",
    "                models_ps1['XGBoost'] = xgb.XGBClassifier(\n",
    "                    random_state=42, \n",
    "                    use_label_encoder=False,\n",
    "                    eval_metric='logloss', \n",
    "                    scale_pos_weight=spw,\n",
    "                    max_depth=5,  # Limit depth\n",
    "                    min_child_weight=5  # Regularization\n",
    "                )\n",
    "            \n",
    "            # Simplified parameter grids to reduce overfitting\n",
    "            param_grids_ps1 = {\n",
    "                'RandomForest': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__max_depth': [5, 10],\n",
    "                    'model__min_samples_leaf': [5, 10],\n",
    "                    'model__min_samples_split': [10, 20]\n",
    "                },\n",
    "                'GradientBoosting': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__max_depth': [3, 5],\n",
    "                    'model__subsample': [0.7, 0.8]\n",
    "                },\n",
    "                'XGBoost': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__max_depth': [3, 5],\n",
    "                    'model__subsample': [0.7, 0.8],\n",
    "                    'model__min_child_weight': [3, 5]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Train with enhanced infrastructure\n",
    "            trainer_ps1 = ProductionModelTrainer(\n",
    "                problem_name='PS1_League_Winner',\n",
    "                task_type='classification',\n",
    "                target_col=TARGET_COL_PS1\n",
    "            )\n",
    "            \n",
    "            # Use stratified k-fold with more splits for better validation\n",
    "            cv_strategy_ps1 = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            \n",
    "            results_ps1 = trainer_ps1.train_with_logging(\n",
    "                X_train=X_train_ps1,\n",
    "                y_train=y_train_ps1,\n",
    "                X_test=X_test_ps1,\n",
    "                y_test=y_test_ps1,\n",
    "                model_configs=models_ps1,\n",
    "                param_grids=param_grids_ps1,\n",
    "                cv_strategy=cv_strategy_ps1,\n",
    "                scoring='f1_macro'\n",
    "            )\n",
    "            \n",
    "            # Save results\n",
    "            trainer_ps1.save_results(\n",
    "                results=results_ps1,\n",
    "                model_path=MODELS_DIR / 'ps1_league_winner_best_model.joblib',\n",
    "                metadata_path=MODELS_DIR / 'ps1_league_winner_metadata.json'\n",
    "            )\n",
    "            \n",
    "            TRAINING_SESSION['models_trained'].append('PS1_League_Winner')\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 100)\n",
    "            print(\"PS1 TRAINING COMPLETE\")\n",
    "            print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6123fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 5: PROBLEM STATEMENT 3 - TOP SCORER PREDICTION\n",
    "# Regression: Predict top scorer goals\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"PS3: TOP SCORER PREDICTION\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Load dataset\n",
    "print(f\"\\nLoading: {TOP_SCORER_PATH}\")\n",
    "try:\n",
    "    df_ps3 = pd.read_csv(TOP_SCORER_PATH)\n",
    "    print(f\"Loaded {df_ps3.shape[0]} samples, {df_ps3.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at {TOP_SCORER_PATH}\")\n",
    "    print(\"Skipping PS3\")\n",
    "    df_ps3 = None\n",
    "\n",
    "if df_ps3 is not None:\n",
    "    # Normalize column names\n",
    "    df_ps3.columns = df_ps3.columns.str.lower().str.strip()\n",
    "    \n",
    "    # Display all available columns\n",
    "    print(f\"\\nAvailable columns in dataset:\")\n",
    "    for i, col in enumerate(df_ps3.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    # Define target column\n",
    "    TARGET_COL_PS3 = 'goals'\n",
    "    \n",
    "    # Verify target exists\n",
    "    if TARGET_COL_PS3 not in df_ps3.columns:\n",
    "        print(f\"\\nERROR: Target column '{TARGET_COL_PS3}' not found!\")\n",
    "        print(\"Skipping PS3\")\n",
    "    else:\n",
    "        # CRITICAL: Exclude columns that are derived from or directly reveal goals\n",
    "        EXCLUDE_COLS_PS3 = [\n",
    "            'goals',                  # Target itself\n",
    "            'unnamed: 0',             # Index column\n",
    "            'goals + assists',        # Linear combination with goals\n",
    "            'goals_+_assists',        # Alternative name\n",
    "            'goals per 90',           # Derived from goals\n",
    "            'goals_per_90',\n",
    "            'goals per match',        # Derived from goals\n",
    "            'goals_per_match',\n",
    "            'non-penalty goals',      # Subset of goals\n",
    "            'non-penalty_goals',\n",
    "            'npg',                    # Non-penalty goals abbreviation\n",
    "            'player',                 # Identifier\n",
    "            'season'                  # Identifier\n",
    "        ]\n",
    "        \n",
    "        # Select only numeric features not in exclude list\n",
    "        numeric_cols = df_ps3.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        feature_cols_ps3 = [c for c in numeric_cols \n",
    "                           if c not in [col.lower().replace(' ', '_') for col in EXCLUDE_COLS_PS3]\n",
    "                           and c not in [col.lower() for col in EXCLUDE_COLS_PS3]]\n",
    "        \n",
    "        # Filter out columns that exist in the dataframe\n",
    "        feature_cols_ps3 = [c for c in feature_cols_ps3 if c in df_ps3.columns]\n",
    "        \n",
    "        if len(feature_cols_ps3) == 0:\n",
    "            print(\"\\nERROR: No valid features found after exclusion!\")\n",
    "            print(\"Skipping PS3\")\n",
    "        else:\n",
    "            X_ps3 = df_ps3[feature_cols_ps3].copy()\n",
    "            y_ps3 = df_ps3[TARGET_COL_PS3]\n",
    "            \n",
    "            # Display feature information\n",
    "            display_feature_info(X_ps3, y_ps3, 'PS3: Top Scorer', \n",
    "                               TARGET_COL_PS3, EXCLUDE_COLS_PS3)\n",
    "            \n",
    "            # Check target distribution\n",
    "            print(f\"\\nTarget statistics:\")\n",
    "            print(f\"  Mean: {y_ps3.mean():.2f}\")\n",
    "            print(f\"  Median: {y_ps3.median():.2f}\")\n",
    "            print(f\"  Std: {y_ps3.std():.2f}\")\n",
    "            print(f\"  Min: {y_ps3.min():.2f}, Max: {y_ps3.max():.2f}\")\n",
    "            \n",
    "            # Detect outliers\n",
    "            outliers_ps3 = detect_outliers(X_ps3, threshold=2.0)  # Less aggressive\n",
    "            \n",
    "            # Handle outliers\n",
    "            X_ps3_clean = handle_outliers(X_ps3, outliers_ps3, method='cap')\n",
    "            \n",
    "            # Temporal split (80/20) for time series nature\n",
    "            split_idx = int(len(df_ps3) * 0.8)\n",
    "            X_train_ps3 = X_ps3_clean.iloc[:split_idx]\n",
    "            y_train_ps3 = y_ps3.iloc[:split_idx]\n",
    "            X_test_ps3 = X_ps3_clean.iloc[split_idx:]\n",
    "            y_test_ps3 = y_ps3.iloc[split_idx:]\n",
    "            \n",
    "            print(f\"\\nData split (temporal): {X_train_ps3.shape[0]} train / {X_test_ps3.shape[0]} test\")\n",
    "            \n",
    "            # Model configurations with STRONGER regularization\n",
    "            models_ps3 = {\n",
    "                'Ridge': Ridge(random_state=42, alpha=10.0),  # Increased alpha\n",
    "                'RandomForest': RandomForestRegressor(\n",
    "                    random_state=42, \n",
    "                    n_jobs=-1,\n",
    "                    max_depth=6,  # Reduced depth\n",
    "                    min_samples_leaf=15,  # Increased minimum samples\n",
    "                    min_samples_split=30,\n",
    "                    max_features='sqrt'\n",
    "                ),\n",
    "                'GradientBoosting': GradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    max_depth=3,  # Very shallow trees\n",
    "                    min_samples_leaf=15,\n",
    "                    min_samples_split=30,\n",
    "                    subsample=0.7,\n",
    "                    learning_rate=0.05\n",
    "                )\n",
    "            }\n",
    "            \n",
    "            if XGB_AVAILABLE:\n",
    "                models_ps3['XGBoost'] = xgb.XGBRegressor(\n",
    "                    random_state=42, \n",
    "                    n_jobs=-1,\n",
    "                    max_depth=5,\n",
    "                    min_child_weight=5\n",
    "                )\n",
    "            \n",
    "            if LGB_AVAILABLE:\n",
    "                models_ps3['LightGBM'] = lgb.LGBMRegressor(\n",
    "                    random_state=42, \n",
    "                    n_jobs=-1, \n",
    "                    verbose=-1,\n",
    "                    max_depth=5,\n",
    "                    min_child_samples=10\n",
    "                )\n",
    "            \n",
    "            # Simplified parameter grids\n",
    "            param_grids_ps3 = {\n",
    "                'Ridge': {\n",
    "                    'model__alpha': [0.1, 1.0, 10.0]\n",
    "                },\n",
    "                'RandomForest': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__max_depth': [10, 15],\n",
    "                    'model__min_samples_split': [5, 10],\n",
    "                    'model__min_samples_leaf': [5, 10]\n",
    "                },\n",
    "                'GradientBoosting': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__max_depth': [3, 5],\n",
    "                    'model__subsample': [0.7, 0.8]\n",
    "                },\n",
    "                'XGBoost': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__max_depth': [3, 5],\n",
    "                    'model__subsample': [0.7, 0.8]\n",
    "                },\n",
    "                'LightGBM': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__num_leaves': [20, 30]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Train with enhanced infrastructure\n",
    "            trainer_ps3 = ProductionModelTrainer(\n",
    "                problem_name='PS3_Top_Scorer',\n",
    "                task_type='regression',\n",
    "                target_col=TARGET_COL_PS3\n",
    "            )\n",
    "            \n",
    "            # Use regular k-fold for regression\n",
    "            cv_strategy_ps3 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            \n",
    "            results_ps3 = trainer_ps3.train_with_logging(\n",
    "                X_train=X_train_ps3,\n",
    "                y_train=y_train_ps3,\n",
    "                X_test=X_test_ps3,\n",
    "                y_test=y_test_ps3,\n",
    "                model_configs=models_ps3,\n",
    "                param_grids=param_grids_ps3,\n",
    "                cv_strategy=cv_strategy_ps3,\n",
    "                scoring='neg_mean_absolute_error'\n",
    "            )\n",
    "            \n",
    "            # Save results\n",
    "            trainer_ps3.save_results(\n",
    "                results=results_ps3,\n",
    "                model_path=MODELS_DIR / 'ps3_top_scorer_best_model.joblib',\n",
    "                metadata_path=MODELS_DIR / 'ps3_top_scorer_metadata.json'\n",
    "            )\n",
    "            \n",
    "            TRAINING_SESSION['models_trained'].append('PS3_Top_Scorer')\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 100)\n",
    "            print(\"PS3 TRAINING COMPLETE\")\n",
    "            print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c698052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 6: PROBLEM STATEMENT 4 - TOTAL POINTS PREDICTION\n",
    "# Regression: Predict team's total points\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"PS4: TOTAL POINTS PREDICTION\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Load dataset\n",
    "print(f\"\\nLoading: {POINTS_TALLY_PATH}\")\n",
    "try:\n",
    "    df_ps4 = pd.read_csv(POINTS_TALLY_PATH)\n",
    "    print(f\"Loaded {df_ps4.shape[0]} samples, {df_ps4.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at {POINTS_TALLY_PATH}\")\n",
    "    print(\"Skipping PS4\")\n",
    "    df_ps4 = None\n",
    "\n",
    "if df_ps4 is not None:\n",
    "    # Normalize column names\n",
    "    df_ps4.columns = df_ps4.columns.str.lower().str.strip()\n",
    "    \n",
    "    # Display all available columns\n",
    "    print(f\"\\nAvailable columns in dataset:\")\n",
    "    for i, col in enumerate(df_ps4.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    # Compute target if needed\n",
    "    if 'total_points' not in df_ps4.columns and 'points' in df_ps4.columns:\n",
    "        df_ps4['total_points'] = df_ps4['points'].copy()\n",
    "    elif 'total_points' not in df_ps4.columns and 'wins' in df_ps4.columns and 'draws' in df_ps4.columns:\n",
    "        df_ps4['total_points'] = (df_ps4['wins'] * 3 + df_ps4['draws']).astype(float)\n",
    "    \n",
    "    TARGET_COL_PS4 = 'total_points'\n",
    "    \n",
    "    # Verify target exists\n",
    "    if TARGET_COL_PS4 not in df_ps4.columns:\n",
    "        print(f\"\\nERROR: Target column '{TARGET_COL_PS4}' not found and cannot be computed!\")\n",
    "        print(\"Skipping PS4\")\n",
    "    else:\n",
    "        # CRITICAL: Exclude columns that directly determine or are derived from points\n",
    "        EXCLUDE_COLS_PS4 = [\n",
    "            'total_points',        # Target itself\n",
    "            'points',              # Same as target\n",
    "            'season',              # Identifier\n",
    "            'team',                # Identifier\n",
    "            'unnamed: 0',          # Index column\n",
    "            'target_top_4',        # Classification targets\n",
    "            'target_top_6',\n",
    "            'target_relegated',\n",
    "            'target_champion',\n",
    "            'wins',                # Directly calculate points (wins*3 + draws)\n",
    "            'draws',\n",
    "            'losses',\n",
    "            'points_per_game'      # Derived from points\n",
    "        ]\n",
    "        \n",
    "        # Select only numeric features not in exclude list\n",
    "        numeric_cols = df_ps4.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        feature_cols_ps4 = [c for c in numeric_cols \n",
    "                           if c not in [col.lower() for col in EXCLUDE_COLS_PS4]]\n",
    "        \n",
    "        # Filter out columns that exist in the dataframe\n",
    "        feature_cols_ps4 = [c for c in feature_cols_ps4 if c in df_ps4.columns]\n",
    "        \n",
    "        if len(feature_cols_ps4) == 0:\n",
    "            print(\"\\nERROR: No valid features found after exclusion!\")\n",
    "            print(\"Skipping PS4\")\n",
    "        else:\n",
    "            X_ps4 = df_ps4[feature_cols_ps4].copy()\n",
    "            y_ps4 = df_ps4[TARGET_COL_PS4]\n",
    "            \n",
    "            # Display feature information\n",
    "            display_feature_info(X_ps4, y_ps4, 'PS4: Total Points', \n",
    "                               TARGET_COL_PS4, EXCLUDE_COLS_PS4)\n",
    "            \n",
    "            # Check target distribution\n",
    "            print(f\"\\nTarget statistics:\")\n",
    "            print(f\"  Mean: {y_ps4.mean():.2f}\")\n",
    "            print(f\"  Median: {y_ps4.median():.2f}\")\n",
    "            print(f\"  Std: {y_ps4.std():.2f}\")\n",
    "            print(f\"  Min: {y_ps4.min():.2f}, Max: {y_ps4.max():.2f}\")\n",
    "            \n",
    "            # Detect outliers\n",
    "            outliers_ps4 = detect_outliers(X_ps4, threshold=2.0)\n",
    "            \n",
    "            # Handle outliers\n",
    "            X_ps4_clean = handle_outliers(X_ps4, outliers_ps4, method='cap')\n",
    "            \n",
    "            # Temporal split by season if available\n",
    "            if 'season' in df_ps4.columns:\n",
    "                seasons_ps4 = sorted(df_ps4['season'].dropna().unique())\n",
    "                if len(seasons_ps4) > 1:\n",
    "                    # Use last season for testing\n",
    "                    test_season_ps4 = seasons_ps4[-1]\n",
    "                    train_mask_ps4 = df_ps4['season'].isin(seasons_ps4[:-1])\n",
    "                    test_mask_ps4 = df_ps4['season'] == test_season_ps4\n",
    "                    X_train_ps4 = X_ps4_clean[train_mask_ps4]\n",
    "                    y_train_ps4 = y_ps4[train_mask_ps4]\n",
    "                    X_test_ps4 = X_ps4_clean[test_mask_ps4]\n",
    "                    y_test_ps4 = y_ps4[test_mask_ps4]\n",
    "                    print(f\"\\nTemporal split by season:\")\n",
    "                    print(f\"  Training seasons: {seasons_ps4[:-1]}\")\n",
    "                    print(f\"  Test season: {test_season_ps4}\")\n",
    "                else:\n",
    "                    X_train_ps4, X_test_ps4, y_train_ps4, y_test_ps4 = train_test_split(\n",
    "                        X_ps4_clean, y_ps4, test_size=0.25, random_state=42\n",
    "                    )\n",
    "                    print(\"\\nRandom 75/25 split (only one season)\")\n",
    "            else:\n",
    "                X_train_ps4, X_test_ps4, y_train_ps4, y_test_ps4 = train_test_split(\n",
    "                    X_ps4_clean, y_ps4, test_size=0.25, random_state=42\n",
    "                )\n",
    "                print(\"\\nRandom 75/25 split (no season column)\")\n",
    "            \n",
    "            print(f\"Data split: {X_train_ps4.shape[0]} train / {X_test_ps4.shape[0]} test\")\n",
    "            \n",
    "            # Model configurations with STRONGER regularization\n",
    "            models_ps4 = {\n",
    "                'Ridge': Ridge(random_state=42, alpha=10.0),  # Increased alpha\n",
    "                'RandomForest': RandomForestRegressor(\n",
    "                    random_state=42, \n",
    "                    n_jobs=-1,\n",
    "                    max_depth=6,  # Reduced depth\n",
    "                    min_samples_leaf=15,  # Increased minimum samples\n",
    "                    min_samples_split=30,\n",
    "                    max_features='sqrt'\n",
    "                ),\n",
    "                'GradientBoosting': GradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    max_depth=3,  # Very shallow trees\n",
    "                    min_samples_leaf=15,\n",
    "                    min_samples_split=30,\n",
    "                    subsample=0.7,\n",
    "                    learning_rate=0.05\n",
    "                )\n",
    "            }\n",
    "            \n",
    "            if XGB_AVAILABLE:\n",
    "                models_ps4['XGBoost'] = xgb.XGBRegressor(\n",
    "                    random_state=42, \n",
    "                    n_jobs=-1,\n",
    "                    max_depth=5,\n",
    "                    min_child_weight=5\n",
    "                )\n",
    "            \n",
    "            if LGB_AVAILABLE:\n",
    "                models_ps4['LightGBM'] = lgb.LGBMRegressor(\n",
    "                    random_state=42, \n",
    "                    n_jobs=-1, \n",
    "                    verbose=-1,\n",
    "                    max_depth=5,\n",
    "                    min_child_samples=10\n",
    "                )\n",
    "            \n",
    "            # Simplified parameter grids\n",
    "            param_grids_ps4 = {\n",
    "                'Ridge': {\n",
    "                    'model__alpha': [0.1, 1.0, 10.0]\n",
    "                },\n",
    "                'RandomForest': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__max_depth': [10, 15],\n",
    "                    'model__min_samples_split': [5, 10],\n",
    "                    'model__min_samples_leaf': [5, 10]\n",
    "                },\n",
    "                'GradientBoosting': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__max_depth': [3, 5],\n",
    "                    'model__subsample': [0.7, 0.8]\n",
    "                },\n",
    "                'XGBoost': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__max_depth': [3, 5],\n",
    "                    'model__subsample': [0.7, 0.8]\n",
    "                },\n",
    "                'LightGBM': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__num_leaves': [20, 30]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Train with enhanced infrastructure\n",
    "            trainer_ps4 = ProductionModelTrainer(\n",
    "                problem_name='PS4_Total_Points',\n",
    "                task_type='regression',\n",
    "                target_col=TARGET_COL_PS4\n",
    "            )\n",
    "            \n",
    "            # Use TimeSeriesSplit for temporal data\n",
    "            cv_strategy_ps4 = TimeSeriesSplit(n_splits=5)\n",
    "            \n",
    "            results_ps4 = trainer_ps4.train_with_logging(\n",
    "                X_train=X_train_ps4,\n",
    "                y_train=y_train_ps4,\n",
    "                X_test=X_test_ps4,\n",
    "                y_test=y_test_ps4,\n",
    "                model_configs=models_ps4,\n",
    "                param_grids=param_grids_ps4,\n",
    "                cv_strategy=cv_strategy_ps4,\n",
    "                scoring='neg_mean_absolute_error'\n",
    "            )\n",
    "            \n",
    "            # Save results\n",
    "            trainer_ps4.save_results(\n",
    "                results=results_ps4,\n",
    "                model_path=MODELS_DIR / 'ps4_total_points_best_model.joblib',\n",
    "                metadata_path=MODELS_DIR / 'ps4_total_points_metadata.json'\n",
    "            )\n",
    "            \n",
    "            TRAINING_SESSION['models_trained'].append('PS4_Total_Points')\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 100)\n",
    "            print(\"PS4 TRAINING COMPLETE\")\n",
    "            print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69631bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 8: PROBLEM STATEMENT 5 - MATCH RESULT PREDICTION\n",
    "# Multi-class Classification: Home/Draw/Away (H/D/A)\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"PS5: MATCH RESULT PREDICTION\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Load dataset\n",
    "print(f\"\\nLoading: {MATCH_RESULT_PATH}\")\n",
    "try:\n",
    "    df_ps5 = pd.read_csv(MATCH_RESULT_PATH)\n",
    "    df_ps5.columns = df_ps5.columns.str.lower().str.strip()\n",
    "    print(f\"Loaded {df_ps5.shape[0]} samples, {df_ps5.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: File not found at {MATCH_RESULT_PATH}\")\n",
    "    print(\"Skipping PS5\")\n",
    "    df_ps5 = None\n",
    "\n",
    "if df_ps5 is not None:\n",
    "    # Display all available columns\n",
    "    print(f\"\\nAvailable columns in dataset:\")\n",
    "    for i, col in enumerate(df_ps5.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "    \n",
    "    # Create target from fthg/ftag if not exists\n",
    "    if 'target' not in df_ps5.columns:\n",
    "        if 'fthg' in df_ps5.columns and 'ftag' in df_ps5.columns:\n",
    "            def create_target_ps5(row):\n",
    "                if row['fthg'] > row['ftag']:\n",
    "                    return 0  # Home win\n",
    "                elif row['fthg'] == row['ftag']:\n",
    "                    return 1  # Draw\n",
    "                else:\n",
    "                    return 2  # Away win\n",
    "            \n",
    "            y_ps5 = df_ps5.apply(create_target_ps5, axis=1)\n",
    "            TARGET_COL_PS5 = 'match_result'\n",
    "        else:\n",
    "            print(\"\\nERROR: Cannot create target - 'fthg' and 'ftag' columns not found!\")\n",
    "            print(\"Skipping PS5\")\n",
    "            y_ps5 = None\n",
    "    else:\n",
    "        TARGET_COL_PS5 = 'target'\n",
    "        y_ps5 = df_ps5[TARGET_COL_PS5]\n",
    "    \n",
    "    if y_ps5 is not None:\n",
    "        # CRITICAL: Comprehensive exclusion list\n",
    "        EXCLUDE_COLS_PS5 = [\n",
    "            # Target\n",
    "            'target',\n",
    "            \n",
    "            # Direct outcome indicators (ANY variation)\n",
    "            'fthg', 'ftag', 'ftr', 'result',\n",
    "            'fthg.1', 'ftag.1', 'ftr.1',  # CRITICAL: Duplicate columns with suffix\n",
    "            'home_goals', 'away_goals',\n",
    "            'total_goals', 'goal_difference',\n",
    "            'home_score', 'away_score',\n",
    "            \n",
    "            # Win/binary outcome indicators (these reveal the match result)\n",
    "            'home_win', 'away_win', 'draw',\n",
    "            'home_win_binary', 'away_win_binary',  # CRITICAL: Binary indicators\n",
    "            \n",
    "            # Identifiers\n",
    "            'unnamed: 0', 'match_id', 'date',\n",
    "            'home_team', 'away_team', 'season',\n",
    "            \n",
    "            # Features that may include current match result\n",
    "            'home_consecutive_wins', 'away_consecutive_wins',  # May include current match\n",
    "            'home_winning_momentum', 'away_winning_momentum',  # Derived from current results\n",
    "        ]\n",
    "        \n",
    "        # Select only numeric features not in exclude list\n",
    "        numeric_cols = df_ps5.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        # Create comprehensive exclusion filter\n",
    "        def should_exclude(col):\n",
    "            col_lower = col.lower()\n",
    "            # Check direct exclusions\n",
    "            if col_lower in [e.lower() for e in EXCLUDE_COLS_PS5]:\n",
    "                return True\n",
    "            # Check for goal-related columns with ANY suffix (very strict)\n",
    "            if 'fthg' in col_lower or 'ftag' in col_lower:\n",
    "                return True\n",
    "            if 'home_goals' in col_lower or 'away_goals' in col_lower:\n",
    "                return True\n",
    "            if 'total_goals' in col_lower or 'goal_difference' in col_lower:\n",
    "                return True\n",
    "            # Check for result indicators\n",
    "            if 'result' in col_lower or 'outcome' in col_lower:\n",
    "                return True\n",
    "            if col_lower.endswith('_win') or col_lower.endswith('_binary'):\n",
    "                return True\n",
    "            # Check for score-related columns\n",
    "            if 'score' in col_lower:\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        feature_cols_ps5 = [c for c in numeric_cols if not should_exclude(c)]\n",
    "        \n",
    "        # Additional safety check: remove columns with perfect correlation to target\n",
    "        if len(feature_cols_ps5) > 0:\n",
    "            X_temp = df_ps5[feature_cols_ps5].copy()\n",
    "            \n",
    "            # Check correlation for each feature\n",
    "            high_corr_cols = []\n",
    "            for col in feature_cols_ps5:\n",
    "                try:\n",
    "                    # For multi-class, check if column perfectly separates classes\n",
    "                    # by checking if unique values correspond to target classes\n",
    "                    unique_ratio = X_temp[col].nunique() / len(X_temp)\n",
    "                    if unique_ratio < 0.01:  # Very few unique values\n",
    "                        # Check if it perfectly predicts target\n",
    "                        temp_df = pd.DataFrame({'feature': X_temp[col], 'target': y_ps5})\n",
    "                        grouped = temp_df.groupby('feature')['target'].apply(lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0])\n",
    "                        predicted = X_temp[col].map(grouped)\n",
    "                        accuracy = (predicted == y_ps5).mean()\n",
    "                        if accuracy > 0.95:\n",
    "                            high_corr_cols.append(col)\n",
    "                            print(f\"  WARNING: Removing '{col}' (perfect prediction accuracy: {accuracy:.4f})\")\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            feature_cols_ps5 = [c for c in feature_cols_ps5 if c not in high_corr_cols]\n",
    "        \n",
    "        if len(feature_cols_ps5) == 0:\n",
    "            print(\"\\nERROR: No valid features found after exclusion!\")\n",
    "            print(\"Skipping PS5\")\n",
    "        else:\n",
    "            X_ps5 = df_ps5[feature_cols_ps5].copy()\n",
    "            \n",
    "            # Display feature information\n",
    "            display_feature_info(X_ps5, y_ps5, 'PS5: Match Result', \n",
    "                               TARGET_COL_PS5, EXCLUDE_COLS_PS5)\n",
    "            \n",
    "            # Check for class imbalance\n",
    "            print(\"\\nClass distribution:\")\n",
    "            print(y_ps5.value_counts())\n",
    "            print(f\"\\nClass balance ratio: {y_ps5.value_counts().min() / y_ps5.value_counts().max():.2f}\")\n",
    "            \n",
    "            # Detect outliers\n",
    "            outliers_ps5 = detect_outliers(X_ps5, threshold=2.5)\n",
    "            \n",
    "            # Handle outliers\n",
    "            X_ps5_clean = handle_outliers(X_ps5, outliers_ps5, method='cap')\n",
    "            \n",
    "            # Stratified split with larger test set\n",
    "            X_train_ps5, X_test_ps5, y_train_ps5, y_test_ps5 = train_test_split(\n",
    "                X_ps5_clean, y_ps5, test_size=0.30, random_state=42, stratify=y_ps5\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nData split: {X_train_ps5.shape[0]} train / {X_test_ps5.shape[0]} test\")\n",
    "            print(f\"Train class distribution:\\n{y_train_ps5.value_counts()}\")\n",
    "            print(f\"Test class distribution:\\n{y_test_ps5.value_counts()}\")\n",
    "            \n",
    "            # Model configurations with STRONG regularization\n",
    "            models_ps5 = {\n",
    "                'LogisticRegression': LogisticRegression(\n",
    "                    multi_class='multinomial',\n",
    "                    solver='lbfgs',\n",
    "                    max_iter=1000,\n",
    "                    random_state=42,\n",
    "                    C=0.01,  # Strong regularization\n",
    "                    penalty='l2'\n",
    "                ),\n",
    "                'RandomForest': RandomForestClassifier(\n",
    "                    random_state=42,\n",
    "                    class_weight='balanced',\n",
    "                    max_depth=8,  # Reduced depth\n",
    "                    min_samples_leaf=10,  # More samples required\n",
    "                    min_samples_split=20,\n",
    "                    max_features='sqrt'\n",
    "                ),\n",
    "                'GradientBoosting': GradientBoostingClassifier(\n",
    "                    random_state=42,\n",
    "                    max_depth=4,  # Very limited depth\n",
    "                    min_samples_leaf=10,\n",
    "                    min_samples_split=20,\n",
    "                    subsample=0.7\n",
    "                )\n",
    "            }\n",
    "            \n",
    "            if XGB_AVAILABLE:\n",
    "                models_ps5['XGBoost'] = xgb.XGBClassifier(\n",
    "                    random_state=42,\n",
    "                    use_label_encoder=False,\n",
    "                    eval_metric='mlogloss',\n",
    "                    objective='multi:softprob',\n",
    "                    num_class=3,\n",
    "                    max_depth=4,  # Very limited depth\n",
    "                    min_child_weight=10,  # Strong regularization\n",
    "                    gamma=0.1,  # Minimum loss reduction\n",
    "                    subsample=0.7,\n",
    "                    colsample_bytree=0.7,\n",
    "                    reg_alpha=0.1,  # L1 regularization\n",
    "                    reg_lambda=1.0  # L2 regularization\n",
    "                )\n",
    "            \n",
    "            # Very limited parameter grids\n",
    "            param_grids_ps5 = {\n",
    "                'LogisticRegression': {\n",
    "                    'model__C': [0.001, 0.01, 0.1]\n",
    "                },\n",
    "                'RandomForest': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__max_depth': [5, 8],\n",
    "                    'model__min_samples_split': [20, 30]\n",
    "                },\n",
    "                'GradientBoosting': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__max_depth': [3, 4]\n",
    "                },\n",
    "                'XGBoost': {\n",
    "                    'model__n_estimators': [50, 100],\n",
    "                    'model__learning_rate': [0.01, 0.05],\n",
    "                    'model__max_depth': [3, 4],\n",
    "                    'model__min_child_weight': [10, 15]\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Train with enhanced infrastructure\n",
    "            trainer_ps5 = ProductionModelTrainer(\n",
    "                problem_name='PS5_Match_Result',\n",
    "                task_type='classification',\n",
    "                target_col=TARGET_COL_PS5\n",
    "            )\n",
    "            \n",
    "            # Use more CV folds for better validation\n",
    "            cv_strategy_ps5 = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "            \n",
    "            results_ps5 = trainer_ps5.train_with_logging(\n",
    "                X_train=X_train_ps5,\n",
    "                y_train=y_train_ps5,\n",
    "                X_test=X_test_ps5,\n",
    "                y_test=y_test_ps5,\n",
    "                model_configs=models_ps5,\n",
    "                param_grids=param_grids_ps5,\n",
    "                cv_strategy=cv_strategy_ps5,\n",
    "                scoring='f1_macro'\n",
    "            )\n",
    "            \n",
    "            # Save results\n",
    "            trainer_ps5.save_results(\n",
    "                results=results_ps5,\n",
    "                model_path=MODELS_DIR / 'ps5_match_result_model.joblib',\n",
    "                metadata_path=MODELS_DIR / 'ps5_match_result_metrics.json'\n",
    "            )\n",
    "            \n",
    "            TRAINING_SESSION['models_trained'].append('PS5_Match_Result')\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 100)\n",
    "            print(\"PS5 TRAINING COMPLETE\")\n",
    "            print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f4c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# Cell 9: FINAL MODEL PERFORMANCE SUMMARY\n",
    "# ==================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"FINAL MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Define paths to all metric files\n",
    "METRICS_PATHS = {\n",
    "    'PS1: League Winner': MODELS_DIR / 'ps1_league_winner_metadata.json',\n",
    "    'PS2: Match Winner': MODELS_DIR / 'ps2_match_winner_metadata.json',\n",
    "    'PS3: Top Scorer': MODELS_DIR / 'ps3_top_scorer_metadata.json',\n",
    "    'PS4: Total Points': MODELS_DIR / 'ps4_total_points_metadata.json',\n",
    "    'PS5: Match Result': MODELS_DIR / 'ps5_match_result_metrics.json'\n",
    "}\n",
    "\n",
    "# Collect metrics\n",
    "summary_data = []\n",
    "print(\"\\nLoading model metrics...\\n\")\n",
    "\n",
    "for name, path in METRICS_PATHS.items():\n",
    "    if not path.exists():\n",
    "        print(f\"  {name}: Metric file not found, skipping\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        # Extract best model name\n",
    "        best_model = metrics.get('best_model', 'Unknown')\n",
    "        \n",
    "        # Extract primary metric based on problem type\n",
    "        if 'PS1' in name or 'PS2' in name or 'PS5' in name:\n",
    "            # Classification\n",
    "            metric_name = 'F1-Macro'\n",
    "            score = None\n",
    "            \n",
    "            # Try different paths for the metric\n",
    "            if 'models_attempted' in metrics and metrics['models_attempted']:\n",
    "                for attempt in metrics['models_attempted']:\n",
    "                    if attempt.get('model_name') == best_model:\n",
    "                        score = attempt.get('test_metrics', {}).get('f1_macro')\n",
    "                        break\n",
    "            \n",
    "            if score is None and 'test_metrics' in metrics:\n",
    "                score = metrics['test_metrics'].get('f1_macro')\n",
    "        \n",
    "        elif 'PS3' in name or 'PS4' in name:\n",
    "            # Regression\n",
    "            metric_name = 'MAE'\n",
    "            score = None\n",
    "            \n",
    "            if 'models_attempted' in metrics and metrics['models_attempted']:\n",
    "                for attempt in metrics['models_attempted']:\n",
    "                    if attempt.get('model_name') == best_model:\n",
    "                        score = attempt.get('test_metrics', {}).get('mae')\n",
    "                        break\n",
    "            \n",
    "            if score is None and 'test_metrics' in metrics:\n",
    "                score = metrics['test_metrics'].get('mae')\n",
    "        \n",
    "        if score is not None:\n",
    "            summary_data.append({\n",
    "                'Problem': name,\n",
    "                'Best Model': best_model,\n",
    "                'Primary Metric': metric_name,\n",
    "                'Score': float(score)\n",
    "            })\n",
    "            print(f\"  {name}: {best_model} ({metric_name} = {score:.4f})\")\n",
    "        else:\n",
    "            print(f\"  {name}: Could not extract metric\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  {name}: Error loading - {e}\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "if summary_data:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "    print(\"=\" * 100)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    print(\"=\" * 100)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Separate by metric type\n",
    "    classification_df = summary_df[summary_df['Primary Metric'] == 'F1-Macro']\n",
    "    regression_df = summary_df[summary_df['Primary Metric'] == 'MAE']\n",
    "    \n",
    "    y_pos = []\n",
    "    values = []\n",
    "    colors = []\n",
    "    labels = []\n",
    "    \n",
    "    if not classification_df.empty:\n",
    "        for idx, row in classification_df.iterrows():\n",
    "            y_pos.append(row['Problem'])\n",
    "            values.append(row['Score'])\n",
    "            colors.append('skyblue')\n",
    "            labels.append(f\"{row['Score']:.3f}\\n{row['Best Model']}\")\n",
    "    \n",
    "    if not regression_df.empty:\n",
    "        # For MAE, normalize for visualization (lower is better)\n",
    "        max_mae = regression_df['Score'].max()\n",
    "        for idx, row in regression_df.iterrows():\n",
    "            y_pos.append(row['Problem'])\n",
    "            # Normalize: convert to 0-1 scale where 1 is best (0 MAE)\n",
    "            normalized = 1 - (row['Score'] / (max_mae * 1.5))\n",
    "            values.append(max(normalized, 0.1))  # Ensure visibility\n",
    "            colors.append('lightcoral')\n",
    "            labels.append(f\"MAE: {row['Score']:.3f}\\n{row['Best Model']}\")\n",
    "    \n",
    "    bars = ax.barh(y_pos, values, color=colors, alpha=0.8)\n",
    "    \n",
    "    # Add labels\n",
    "    for bar, label in zip(bars, labels):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + 0.02, bar.get_y() + bar.get_height()/2, \n",
    "               label, va='center', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Score (F1-Macro for Classification, Normalized for Regression)', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Problem Statement', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Final Model Performance Comparison\\nScoreSight ML Pipeline', \n",
    "                fontsize=16, fontweight='bold', pad=20)\n",
    "    ax.set_xlim([0, max(values) * 1.3])\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    output_path = VIZ_DIR / 'final_model_performance_comparison.png'\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nPerformance comparison saved to: {output_path}\")\n",
    "    \n",
    "    # Save training session summary\n",
    "    session_path = REPORTS_DIR / 'training_session_summary.json'\n",
    "    with open(session_path, 'w') as f:\n",
    "        json.dump(TRAINING_SESSION, f, indent=2)\n",
    "    \n",
    "    print(f\"Training session summary saved to: {session_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo model metrics were loaded. Training may not have completed successfully.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"MODEL TRAINING PIPELINE COMPLETE!\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nModels trained: {len(TRAINING_SESSION['models_trained'])}\")\n",
    "for model in TRAINING_SESSION['models_trained']:\n",
    "    print(f\"   {model}\")\n",
    "\n",
    "print(f\"\\nAll outputs saved to:\")\n",
    "print(f\"   Models: {MODELS_DIR}/\")\n",
    "print(f\"   Visualizations: {VIZ_DIR}/\")\n",
    "print(f\"   Reports: {REPORTS_DIR}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
