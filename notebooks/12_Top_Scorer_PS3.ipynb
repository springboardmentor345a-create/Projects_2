{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3dadfac",
   "metadata": {},
   "source": [
    "# Problem Statement 3: Top Scorer Prediction\n",
    "## Predict Player Goals Scored\n",
    "\n",
    "**Author:** ScoreSight ML Team  \n",
    "**Date:** 2025-11-12  \n",
    "**Problem Type:** Regression (Goals Prediction)\n",
    "\n",
    "### Dataset\n",
    "- **File:** `data/data_engineered_top_scorer.csv`\n",
    "- **Task:** Predict total goals scored by player\n",
    "- **Features:** Player statistics (44+ engineered features)\n",
    "- **Target:** goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7b77f",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e8f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    LGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LGB_AVAILABLE = False\n",
    "\n",
    "# GitHub configuration\n",
    "GITHUB_REPO = 'https://raw.githubusercontent.com/springboardmentor345a-create/Projects_2/Prathamesh_Fuke'\n",
    "DATA_URL_BASE = f'{GITHUB_REPO}/data/engineered'\n",
    "\n",
    "models_dir = Path('models')\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"[OK] All libraries imported\")\n",
    "print(f\"XGBoost: {XGB_AVAILABLE} | LightGBM: {LGB_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007bdd95",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1db94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = '../data/corrected/top_scorer_corrected.csv'\n",
    "print(f\"[LOAD] Loading from: {data_path}\")\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "print(f\"[OK] Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nðŸ“Š Target (goals) Statistics:\")\n",
    "print(f\"  Mean: {df['goals'].mean():.2f} goals\")\n",
    "print(f\"  Std: {df['goals'].std():.2f}\")\n",
    "print(f\"  Min: {df['goals'].min()}, Max: {df['goals'].max()}\")\n",
    "print(f\"  Median: {df['goals'].median():.1f}\")\n",
    "\n",
    "# Prepare features - exclude targets and identifiers\n",
    "exclude_cols = ['goals', 'non_penalty_goals', 'penalty_goals_made',\n",
    "                'player_encoded', 'nation_encoded', 'pos_encoded', \n",
    "                'unnamed:_0', 'player', 'nation', 'position']\n",
    "feature_cols = [col for col in df.columns \n",
    "               if col not in exclude_cols and df[col].dtype in ['float64', 'int64']]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df['goals'].copy()\n",
    "\n",
    "# Handle missing values\n",
    "if X.isnull().sum().sum() > 0:\n",
    "    print(f\"\\nâš ï¸  Found {X.isnull().sum().sum()} missing values - filling with column means\")\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "print(f\"\\n[OK] Features ({len(feature_cols)}): {feature_cols}\")\n",
    "print(f\"[OK] Samples: {len(X)}\")\n",
    "\n",
    "# Train/test split (80/20)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n[SPLIT] Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(f\"[SPLIT] Train target stats: Mean={y_train.mean():.2f}, Std={y_train.std():.2f}\")\n",
    "print(f\"[SPLIT] Test target stats: Mean={y_test.mean():.2f}, Std={y_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f40339",
   "metadata": {},
   "source": [
    "## 3. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876702f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAIN/TEST SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"[SPLIT] Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(f\"[SPLIT] Train target - Mean: {y_train.mean():.2f}, Std: {y_train.std():.2f}\")\n",
    "print(f\"[SPLIT] Test target  - Mean: {y_test.mean():.2f}, Std: {y_test.std():.2f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# HYPERPARAMETER SEARCH SPACE - Top Scorer Regression\n",
    "# ============================================================================\n",
    "\n",
    "param_grids = {\n",
    "    'Ridge': {\n",
    "        'model__alpha': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "    },\n",
    "    'Lasso': {\n",
    "        'model__alpha': [0.001, 0.01, 0.1, 1, 10]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__max_depth': [10, 15, 20, None],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "        'model__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [5, 7, 9],\n",
    "        'model__subsample': [0.8, 0.9]\n",
    "    }\n",
    "}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    param_grids['XGBoost'] = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__max_depth': [5, 7, 9],\n",
    "        'model__subsample': [0.8, 0.9]\n",
    "    }\n",
    "\n",
    "if LGB_AVAILABLE:\n",
    "    param_grids['LightGBM'] = {\n",
    "        'model__n_estimators': [100, 200, 300],\n",
    "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'model__num_leaves': [30, 50, 70]\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING WITH HYPERPARAMETER TUNING\n",
    "# ============================================================================\n",
    "\n",
    "def create_pipeline(model, use_scaling=True):\n",
    "    steps = [('imputer', SimpleImputer(strategy='mean'))]\n",
    "    if use_scaling:\n",
    "        steps.append(('scaler', StandardScaler()))\n",
    "    steps.append(('model', model))\n",
    "    return Pipeline(steps)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING - RandomizedSearchCV (Regression)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {}\n",
    "trained_models = {}\n",
    "best_models = {}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models_to_train = {\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42, max_iter=10000),\n",
    "    'RandomForest': RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    'GradientBoosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "if XGB_AVAILABLE:\n",
    "    models_to_train['XGBoost'] = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "if LGB_AVAILABLE:\n",
    "    models_to_train['LightGBM'] = lgb.LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1)\n",
    "\n",
    "for model_name, model in models_to_train.items():\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(f\"[{model_name}] Hyperparameter Tuning...\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    pipeline = create_pipeline(model)\n",
    "    param_grid = param_grids[model_name]\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        n_iter=20,\n",
    "        cv=cv,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    best_models[model_name] = search.best_estimator_\n",
    "    print(f\"\\n[BEST] Params: {search.best_params_}\")\n",
    "    print(f\"[CV] MAE: {-search.best_score_:.4f}\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    y_pred = best_models[model_name].predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'best_params': search.best_params_,\n",
    "        'cv_mae': float(-search.best_score_),\n",
    "        'test_mae': float(mae),\n",
    "        'test_rmse': float(rmse),\n",
    "        'test_r2': float(r2)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n[TEST] MAE:  {mae:.4f}\")\n",
    "    print(f\"[TEST] RMSE: {rmse:.4f}\")\n",
    "    print(f\"[TEST] RÂ²:   {r2:.4f}\")\n",
    "    \n",
    "    # Residuals analysis\n",
    "    residuals = y_test - y_pred\n",
    "    print(f\"[TEST] Residuals - Mean: {residuals.mean():.4f}, Std: {residuals.std():.4f}\")\n",
    "    \n",
    "    trained_models[model_name] = best_models[model_name]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca76dfb",
   "metadata": {},
   "source": [
    "## 4. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c1a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IDENTIFY BEST MODEL\n",
    "# ============================================================================\n",
    "\n",
    "best_model_name = min(results, key=lambda x: results[x]['test_mae'])\n",
    "best_metrics = results[best_model_name]\n",
    "\n",
    "print(f\"\\n[WINNER] Best Model: {best_model_name}\")\n",
    "print(f\"[WINNER] Test MAE: {best_metrics['test_mae']:.4f}\")\n",
    "print(f\"[WINNER] Test RMSE: {best_metrics['test_rmse']:.4f}\")\n",
    "print(f\"[WINNER] Test RÂ²: {best_metrics['test_r2']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE ALL MODELS\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SAVING MODELS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    path = models_dir / f\"ps3_top_scorer_{name.lower().replace(' ', '_')}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"[SAVE] {name:20} -> {path}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE TRAINING SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "summary = {\n",
    "    'problem_statement': 'PS3: Top Scorer Goals Prediction',\n",
    "    'task_type': 'Regression',\n",
    "    'best_model': best_model_name,\n",
    "    'best_test_mae': best_metrics['test_mae'],\n",
    "    'best_test_rmse': best_metrics['test_rmse'],\n",
    "    'best_test_r2': best_metrics['test_r2'],\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'data': {\n",
    "        'url': data_url,\n",
    "        'shape': df.shape,\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'n_features': len(feature_cols)\n",
    "    },\n",
    "    'cv_strategy': '5-Fold KFold',\n",
    "    'tuning_method': 'RandomizedSearchCV (20 iterations)',\n",
    "    'scoring_metric': 'neg_mean_absolute_error',\n",
    "    'all_models': results\n",
    "}\n",
    "\n",
    "summary_path = models_dir / 'ps3_top_scorer_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n[SAVE] Summary -> {summary_path}\")\n",
    "print(f\"\\n{json.dumps(summary, indent=2, default=str)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
