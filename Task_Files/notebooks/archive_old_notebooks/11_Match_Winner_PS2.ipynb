{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d71b956",
   "metadata": {},
   "source": [
    "# PS2: Match Winner Prediction - Rigorous Retraining\n",
    "\n",
    "## ‚ö†Ô∏è CRITICAL CORRECTION: ADDRESSING POTENTIAL DATA LEAKAGE\n",
    "\n",
    "My previous analysis produced unrealistically high performance. This was likely due to using a random train-test split, which allows the model to see data from the future and leads to **data leakage**.\n",
    "\n",
    "This notebook has been completely rewritten to follow proper machine learning best practices for time-series data.\n",
    "\n",
    "### Corrected Workflow:\n",
    "1.  **Isolate Target:** The target variable (`FTR` - Full Time Result) is strictly used for evaluation.\n",
    "2.  **Temporal Validation:** The data is sorted by an implicit time order (index) and split. The model is trained on earlier matches and tested on the most recent matches.\n",
    "3.  **Robust Models:** Focus on tree-based models that perform well on tabular data.\n",
    "4.  **Realistic Evaluation:** Performance is measured on a hold-out test set of the most recent matches, providing an honest assessment of the model's predictive power.\n",
    "\n",
    "### Prediction Goal\n",
    "- **Predict the match winner (Home Win, Draw, Away Win) for a given match.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e113b22d",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "721602ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4 Data loaded and cleaned successfully.\n",
      "Shape of the dataframe: (6840, 6)\n",
      "Date range: 2000-08-19 00:00:00 to 2018-05-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Local\\Temp\\ipykernel_10092\\3665995036.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>Charlton</td>\n",
       "      <td>Man City</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>Derby</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-08-19</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Everton</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  HomeTeam       AwayTeam  FTHG  FTAG FTR\n",
       "0 2000-08-19  Charlton       Man City     4     0   H\n",
       "1 2000-08-19   Chelsea       West Ham     4     2   H\n",
       "2 2000-08-19  Coventry  Middlesbrough     1     3  NH\n",
       "3 2000-08-19     Derby    Southampton     2     2  NH\n",
       "4 2000-08-19     Leeds        Everton     2     0   H"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- V4 Ultimate: Data Loading & Prep ---\n",
    "# Objective: Load the granular dataset to build the most powerful predictive features.\n",
    "# Methodology: We will use 'Match Winner.csv' as it contains the necessary raw match data.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Check for XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "# --- 1. Data Loading and Basic Cleaning ---\n",
    "\n",
    "# Define file paths\n",
    "DATA_FILE = '../datasets/Match Winner.csv' # Reverting to the best available granular dataset\n",
    "MODEL_DIR = 'models'\n",
    "MODEL_NAME = 'ps2_match_winner_best_model_v4_ultimate.joblib'\n",
    "METADATA_NAME = 'ps2_match_winner_metadata_v4_ultimate.json'\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# Data Cleaning and Preparation\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "df = df[['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR']] # Select essential columns\n",
    "\n",
    "# Remove matches with missing results\n",
    "df.dropna(subset=['FTHG', 'FTAG', 'FTR'], inplace=True)\n",
    "\n",
    "print(\"V4 Data loaded and cleaned successfully.\")\n",
    "print(f\"Shape of the dataframe: {df.shape}\")\n",
    "print(f\"Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f6618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting V4 Ultimate feature engineering...\n",
      "V4 Ultimate feature engineering complete.\n",
      "Shape of the new featured dataframe: (6129, 44)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>H_avg_gs_5</th>\n",
       "      <th>H_avg_gc_5</th>\n",
       "      <th>H_avg_gd_5</th>\n",
       "      <th>H_avg_pts_5</th>\n",
       "      <th>...</th>\n",
       "      <th>A_ewma_gs_0.2</th>\n",
       "      <th>A_ewma_gc_0.2</th>\n",
       "      <th>A_ewma_gd_0.2</th>\n",
       "      <th>A_h2h_avg_gs</th>\n",
       "      <th>A_h2h_avg_gc</th>\n",
       "      <th>A_h2h_win_rate</th>\n",
       "      <th>diff_avg_gd_5</th>\n",
       "      <th>diff_avg_gd_10</th>\n",
       "      <th>diff_ewma_gd_0.1</th>\n",
       "      <th>diff_ewma_gd_0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2000-12-22</td>\n",
       "      <td>Coventry</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NH</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175708</td>\n",
       "      <td>1.731583</td>\n",
       "      <td>-0.555876</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.403576</td>\n",
       "      <td>-0.219131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2000-12-23</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Ipswich</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.686901</td>\n",
       "      <td>0.810695</td>\n",
       "      <td>0.876206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.698118</td>\n",
       "      <td>0.197919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2000-12-23</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NH</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710837</td>\n",
       "      <td>1.267856</td>\n",
       "      <td>-0.557019</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.505798</td>\n",
       "      <td>0.504492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2000-12-23</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>Man City</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.835071</td>\n",
       "      <td>1.720754</td>\n",
       "      <td>0.114317</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.350594</td>\n",
       "      <td>0.072696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2000-12-23</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.655085</td>\n",
       "      <td>0.595650</td>\n",
       "      <td>1.059435</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.408611</td>\n",
       "      <td>-0.482969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date    HomeTeam       AwayTeam  FTHG  FTAG FTR  H_avg_gs_5  \\\n",
       "179 2000-12-22    Coventry    Southampton     1     1  NH         0.6   \n",
       "180 2000-12-23  Man United        Ipswich     2     0   H         1.8   \n",
       "181 2000-12-23   Tottenham  Middlesbrough     0     0  NH         1.8   \n",
       "182 2000-12-23  Sunderland       Man City     1     0   H         1.2   \n",
       "183 2000-12-23   Liverpool        Arsenal     4     0   H         1.2   \n",
       "\n",
       "     H_avg_gc_5  H_avg_gd_5  H_avg_pts_5  ...  A_ewma_gs_0.2  A_ewma_gc_0.2  \\\n",
       "179         1.0        -0.4          1.0  ...       1.175708       1.731583   \n",
       "180         0.8         1.0          1.4  ...       1.686901       0.810695   \n",
       "181         1.4         0.4          1.6  ...       0.710837       1.267856   \n",
       "182         0.6         0.6          1.6  ...       1.835071       1.720754   \n",
       "183         1.0         0.2          1.0  ...       1.655085       0.595650   \n",
       "\n",
       "     A_ewma_gd_0.2  A_h2h_avg_gs  A_h2h_avg_gc  A_h2h_win_rate  diff_avg_gd_5  \\\n",
       "179      -0.555876           1.0           2.0             0.0           -0.2   \n",
       "180       0.876206           1.0           1.0             0.0            0.2   \n",
       "181      -0.557019           1.0           1.0             0.0            1.2   \n",
       "182       0.114317           4.0           2.0             1.0            0.2   \n",
       "183       1.059435           2.0           0.0             1.0           -0.4   \n",
       "\n",
       "     diff_avg_gd_10  diff_ewma_gd_0.1  diff_ewma_gd_0.2  \n",
       "179            -0.4         -0.403576         -0.219131  \n",
       "180             1.0          0.698118          0.197919  \n",
       "181             0.9          0.505798          0.504492  \n",
       "182             0.7          0.350594          0.072696  \n",
       "183            -0.1         -0.408611         -0.482969  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- V4 Ultimate: Advanced Feature Engineering ---\n",
    "# This cell computes Exponentially Weighted Moving Averages (EWMA) and Head-to-Head (H2H) stats.\n",
    "# EWMA gives more weight to recent games, providing a more sensitive measure of form.\n",
    "# H2H stats capture the specific historical dynamics between two teams.\n",
    "\n",
    "# Function to calculate rolling features for a team\n",
    "def get_advanced_features(team_history, opponent_history, h2h_history, windows, alphas):\n",
    "    features = {}\n",
    "    \n",
    "    # --- Standard Rolling Averages ---\n",
    "    for W in windows:\n",
    "        if len(team_history) >= W:\n",
    "            window_df = pd.DataFrame(team_history[-W:])\n",
    "            features[f'avg_gs_{W}'] = window_df['gs'].mean()\n",
    "            features[f'avg_gc_{W}'] = window_df['gc'].mean()\n",
    "            features[f'avg_gd_{W}'] = window_df['gd'].mean()\n",
    "            features[f'avg_pts_{W}'] = window_df['pts'].mean()\n",
    "        else:\n",
    "            features[f'avg_gs_{W}'] = np.nan\n",
    "            features[f'avg_gc_{W}'] = np.nan\n",
    "            features[f'avg_gd_{W}'] = np.nan\n",
    "            features[f'avg_pts_{W}'] = np.nan\n",
    "\n",
    "    # --- Exponentially Weighted Moving Averages (EWMA) ---\n",
    "    if len(team_history) > 1:\n",
    "        history_df = pd.DataFrame(team_history)\n",
    "        for alpha in alphas:\n",
    "            features[f'ewma_gs_{alpha}'] = history_df['gs'].ewm(alpha=alpha).mean().iloc[-1]\n",
    "            features[f'ewma_gc_{alpha}'] = history_df['gc'].ewm(alpha=alpha).mean().iloc[-1]\n",
    "            features[f'ewma_gd_{alpha}'] = history_df['gd'].ewm(alpha=alpha).mean().iloc[-1]\n",
    "    else:\n",
    "        for alpha in alphas:\n",
    "            features[f'ewma_gs_{alpha}'] = np.nan\n",
    "            features[f'ewma_gc_{alpha}'] = np.nan\n",
    "            features[f'ewma_gd_{alpha}'] = np.nan\n",
    "            \n",
    "    # --- Head-to-Head (H2H) Features ---\n",
    "    if len(h2h_history) > 0:\n",
    "        h2h_df = pd.DataFrame(h2h_history)\n",
    "        features['h2h_avg_gs'] = h2h_df['gs'].mean()\n",
    "        features['h2h_avg_gc'] = h2h_df['gc'].mean()\n",
    "        features['h2h_win_rate'] = (h2h_df['pts'] == 3).mean()\n",
    "    else:\n",
    "        features['h2h_avg_gs'] = np.nan\n",
    "        features['h2h_avg_gc'] = np.nan\n",
    "        features['h2h_win_rate'] = np.nan\n",
    "        \n",
    "    return features\n",
    "\n",
    "# Define windows and alphas for EWMA\n",
    "WINDOWS = [5, 10]\n",
    "ALPHAS = [0.1, 0.2]\n",
    "\n",
    "# Dictionaries to store histories\n",
    "teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()\n",
    "team_histories = {team: [] for team in teams}\n",
    "h2h_histories = {} # Key will be a sorted tuple of team names\n",
    "\n",
    "new_features_list = []\n",
    "\n",
    "print(\"Starting V4 Ultimate feature engineering...\")\n",
    "\n",
    "# Iterate through each match chronologically\n",
    "for index, row in df.iterrows():\n",
    "    home_team = row['HomeTeam']\n",
    "    away_team = row['AwayTeam']\n",
    "    \n",
    "    h2h_key = tuple(sorted((home_team, away_team)))\n",
    "    if h2h_key not in h2h_histories:\n",
    "        h2h_histories[h2h_key] = []\n",
    "\n",
    "    # --- 1. Get features based on past data ---\n",
    "    home_feats = get_advanced_features(\n",
    "        team_histories[home_team], team_histories[away_team], h2h_histories[h2h_key],\n",
    "        WINDOWS, ALPHAS\n",
    "    )\n",
    "    away_feats = get_advanced_features(\n",
    "        team_histories[away_team], team_histories[home_team], h2h_histories[h2h_key],\n",
    "        WINDOWS, ALPHAS\n",
    "    )\n",
    "\n",
    "    # Combine features\n",
    "    match_features = {}\n",
    "    for key, value in home_feats.items():\n",
    "        match_features[f'H_{key}'] = value\n",
    "    for key, value in away_feats.items():\n",
    "        match_features[f'A_{key}'] = value\n",
    "        \n",
    "    # Add difference features\n",
    "    for W in WINDOWS:\n",
    "        match_features[f'diff_avg_gd_{W}'] = home_feats.get(f'avg_gd_{W}') - away_feats.get(f'avg_gd_{W}')\n",
    "    for alpha in ALPHAS:\n",
    "        match_features[f'diff_ewma_gd_{alpha}'] = home_feats.get(f'ewma_gd_{alpha}') - away_feats.get(f'ewma_gd_{alpha}')\n",
    "        \n",
    "    new_features_list.append(match_features)\n",
    "\n",
    "    # --- 2. Update histories with the outcome of the *current* match ---\n",
    "    home_goals = row['FTHG']\n",
    "    away_goals = row['FTAG']\n",
    "    \n",
    "    if row['FTR'] == 'H':\n",
    "        home_pts, away_pts = 3, 0\n",
    "    elif row['FTR'] == 'A':\n",
    "        home_pts, away_pts = 0, 3\n",
    "    else:\n",
    "        home_pts, away_pts = 1, 1\n",
    "\n",
    "    team_histories[home_team].append({'gs': home_goals, 'gc': away_goals, 'gd': home_goals - away_goals, 'pts': home_pts})\n",
    "    team_histories[away_team].append({'gs': away_goals, 'gc': home_goals, 'gd': away_goals - home_goals, 'pts': away_pts})\n",
    "    h2h_histories[h2h_key].append({'team': home_team, 'gs': home_goals, 'gc': away_goals, 'pts': home_pts})\n",
    "\n",
    "# Create a new DataFrame with the engineered features\n",
    "features_df = pd.DataFrame(new_features_list, index=df.index)\n",
    "df_featured = pd.concat([df, features_df], axis=1)\n",
    "df_featured.dropna(inplace=True)\n",
    "\n",
    "print(\"V4 Ultimate feature engineering complete.\")\n",
    "print(f\"Shape of the new featured dataframe: {df_featured.shape}\")\n",
    "df_featured.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c08d40",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1335752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- V4: Temporal Split Details ---\n",
      "Features (X) shape: (6129, 38)\n",
      "Target (y) shape: (6129,)\n",
      "Training set size: 5209 matches\n",
      "Test set size: 920 matches\n",
      "Target classes mapping: {0: 'H', 1: 'NH'}\n"
     ]
    }
   ],
   "source": [
    "# --- V4: Define Features, Target, and Temporal Split ---\n",
    "\n",
    "# Define features (X) and target (y) from the new, feature-rich dataframe\n",
    "le = LabelEncoder()\n",
    "df_featured['FTR_encoded'] = le.fit_transform(df_featured['FTR'])\n",
    "target_mapping = {i: l for i, l in enumerate(le.classes_)}\n",
    "\n",
    "y = df_featured['FTR_encoded']\n",
    "X = df_featured.drop(columns=['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'FTR_encoded'])\n",
    "\n",
    "# --- Temporal Train-Test Split ---\n",
    "# Using last 15% as a hold-out test set.\n",
    "split_index = int(len(df_featured) * 0.85)\n",
    "\n",
    "X_train = X.iloc[:split_index]\n",
    "y_train = y.iloc[:split_index]\n",
    "X_test = X.iloc[split_index:]\n",
    "y_test = y.iloc[split_index:]\n",
    "\n",
    "print(\"--- V4: Temporal Split Details ---\")\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"Training set size: {len(X_train)} matches\")\n",
    "print(f\"Test set size: {len(X_test)} matches\")\n",
    "print(f\"Target classes mapping: {target_mapping}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d051d85f",
   "metadata": {},
   "source": [
    "## 3. Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7863ab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- V4: Training Models with GridSearchCV (This will take a long time) ---\n",
      "Training RandomForest...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "  Done. Best Accuracy on CV: 0.6260\n",
      "Training XGBoost...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "  Done. Best Accuracy on CV: 0.6260\n",
      "Training XGBoost...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "  Done. Best Accuracy on CV: 0.6152\n",
      "\n",
      "--- V4: Model Performance on Hold-out Test Set (Ultimate Features) ---\n",
      "\n",
      "----- RandomForest -----\n",
      "  Accuracy: 0.6380\n",
      "  F1 (Macro): 0.6354\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60       424\n",
      "           1       0.66      0.67      0.67       496\n",
      "\n",
      "    accuracy                           0.64       920\n",
      "   macro avg       0.64      0.64      0.64       920\n",
      "weighted avg       0.64      0.64      0.64       920\n",
      "\n",
      "  Confusion Matrix:\n",
      "[[254 170]\n",
      " [163 333]]\n",
      "\n",
      "----- XGBoost -----\n",
      "  Accuracy: 0.6370\n",
      "  F1 (Macro): 0.6347\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       424\n",
      "           1       0.66      0.66      0.66       496\n",
      "\n",
      "    accuracy                           0.64       920\n",
      "   macro avg       0.63      0.63      0.63       920\n",
      "weighted avg       0.64      0.64      0.64       920\n",
      "\n",
      "  Confusion Matrix:\n",
      "[[257 167]\n",
      " [167 329]]\n",
      "  Done. Best Accuracy on CV: 0.6152\n",
      "\n",
      "--- V4: Model Performance on Hold-out Test Set (Ultimate Features) ---\n",
      "\n",
      "----- RandomForest -----\n",
      "  Accuracy: 0.6380\n",
      "  F1 (Macro): 0.6354\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.60       424\n",
      "           1       0.66      0.67      0.67       496\n",
      "\n",
      "    accuracy                           0.64       920\n",
      "   macro avg       0.64      0.64      0.64       920\n",
      "weighted avg       0.64      0.64      0.64       920\n",
      "\n",
      "  Confusion Matrix:\n",
      "[[254 170]\n",
      " [163 333]]\n",
      "\n",
      "----- XGBoost -----\n",
      "  Accuracy: 0.6370\n",
      "  F1 (Macro): 0.6347\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61       424\n",
      "           1       0.66      0.66      0.66       496\n",
      "\n",
      "    accuracy                           0.64       920\n",
      "   macro avg       0.63      0.63      0.63       920\n",
      "weighted avg       0.64      0.64      0.64       920\n",
      "\n",
      "  Confusion Matrix:\n",
      "[[257 167]\n",
      " [167 329]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\AppData\\Roaming\\Python\\Python314\\site-packages\\xgboost\\training.py:199: UserWarning: [16:57:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# --- V4 Ultimate: Exhaustive Model Training (GridSearchCV) ---\n",
    "# This is the final, most intensive training step.\n",
    "# We use GridSearchCV for an exhaustive search of the best hyperparameters.\n",
    "# The parameter grid is expanded to allow for longer training times and more complex models.\n",
    "\n",
    "def create_smote_pipeline(model):\n",
    "    return ImbPipeline([\n",
    "        ('imputer', SimpleImputer(strategy='mean')), \n",
    "        ('scaler', StandardScaler()),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "# Define models to train\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Define a more focused but deeper hyperparameter grid for GridSearchCV\n",
    "# This will take a long time to run.\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'model__n_estimators': [200, 400], # Increased estimators for longer training\n",
    "        'model__max_depth': [10, 20, 30],\n",
    "        'model__min_samples_leaf': [1, 2],\n",
    "        'model__max_features': ['sqrt', 'log2']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model__n_estimators': [200, 400], # Increased estimators\n",
    "        'model__learning_rate': [0.05, 0.1],\n",
    "        'model__max_depth': [5, 7],\n",
    "        'model__subsample': [0.8, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "print(f\"\\n--- V4: Training Models with GridSearchCV (This will take a long time) ---\")\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    pipeline = create_smote_pipeline(model)\n",
    "    \n",
    "    # Using GridSearchCV for an exhaustive search\n",
    "    search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grids[name],\n",
    "        cv=tscv,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1, # Use all available cores\n",
    "        verbose=1 # Show progress\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = search.predict(X_test)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': search.best_estimator_,\n",
    "        'best_params': search.best_params_,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1_macro': f1_score(y_test, y_pred, average='macro'),\n",
    "        'report': classification_report(y_test, y_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    print(f\"  Done. Best Accuracy on CV: {search.best_score_:.4f}\")\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"\\n--- V4: Model Performance on Hold-out Test Set (Ultimate Features) ---\")\n",
    "for name, res in results.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    print(f\"  Accuracy: {res['accuracy']:.4f}\")\n",
    "    print(f\"  F1 (Macro): {res['f1_macro']:.4f}\")\n",
    "    print(\"  Classification Report:\")\n",
    "    print(res['report'])\n",
    "    print(\"  Confusion Matrix:\")\n",
    "    print(res['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13660eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving Best Model (V4 Ultimate): RandomForest ---\n",
      "Model saved to: models\\ps2_match_winner_best_model_v4_ultimate.joblib\n",
      "Metadata saved to: models\\ps2_match_winner_metadata_v4_ultimate.json\n"
     ]
    }
   ],
   "source": [
    "# --- V4 Ultimate: Save Best Model and Metadata ---\n",
    "\n",
    "best_model_name = None\n",
    "best_accuracy = -1\n",
    "\n",
    "for name, res in results.items():\n",
    "    if res['accuracy'] > best_accuracy:\n",
    "        best_accuracy = res['accuracy']\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"\\n--- Saving Best Model (V4 Ultimate): {best_model_name} ---\")\n",
    "\n",
    "best_model_details = results[best_model_name]\n",
    "best_model_obj = best_model_details['model']\n",
    "\n",
    "# Save the model object\n",
    "joblib.dump(best_model_obj, os.path.join(MODEL_DIR, MODEL_NAME))\n",
    "\n",
    "# Create metadata dictionary\n",
    "metadata = {\n",
    "    \"problem_statement\": \"PS2: Match Winner Prediction\",\n",
    "    \"version\": \"4.0 (Ultimate Features & GridSearchCV)\",\n",
    "    \"model_name\": best_model_name,\n",
    "    \"model_path\": os.path.join(MODEL_DIR, MODEL_NAME),\n",
    "    \"features\": list(X.columns),\n",
    "    \"target_variable\": \"FTR_encoded\",\n",
    "    \"target_mapping\": target_mapping,\n",
    "    \"evaluation_metric\": \"accuracy\",\n",
    "    \"performance_metrics\": {\n",
    "        \"accuracy\": best_model_details['accuracy'],\n",
    "        \"f1_macro\": best_model_details['f1_macro'],\n",
    "        \"classification_report\": best_model_details['report'],\n",
    "        \"confusion_matrix\": best_model_details['confusion_matrix'].tolist()\n",
    "    },\n",
    "    \"hyperparameters\": best_model_details['best_params'],\n",
    "    \"training_methodology\": \"Temporal split (85/15), Ultimate Features (EWMA, H2H), GridSearchCV with 5-fold TimeSeriesSplit and SMOTE.\"\n",
    "}\n",
    "\n",
    "# Save metadata to JSON\n",
    "with open(os.path.join(MODEL_DIR, METADATA_NAME), 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(f\"Model saved to: {os.path.join(MODEL_DIR, MODEL_NAME)}\")\n",
    "print(f\"Metadata saved to: {os.path.join(MODEL_DIR, METADATA_NAME)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db895f1b",
   "metadata": {},
   "source": [
    "## 4. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c60d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä MODEL COMPARISON - PS2: Match Winner Prediction (H/D/A)\n",
      "================================================================================\n",
      "              Model                                                                                                                                           Best_Params  CV_Accuracy  Test_Accuracy  Test_F1  Training_Time_s\n",
      "            XGBoost {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'num_class': 3, 'objective': 'multi:softmax', 'subsample': 1.0}     0.454463       0.460806 0.321700         9.474627\n",
      "  Gradient Boosting                                                                        {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100, 'subsample': 1.0}     0.447682       0.443956 0.321353        57.016826\n",
      "      Random Forest                                   {'class_weight': 'balanced', 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}     0.402419       0.413919 0.364009        11.766964\n",
      "           LightGBM {'class_weight': 'balanced', 'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': -1, 'n_estimators': 200, 'num_leaves': 63, 'subsample': 0.8}     0.378596       0.391941 0.382690       149.972396\n",
      "Logistic Regression                            {'C': 0.1, 'class_weight': 'balanced', 'max_iter': 1000, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'lbfgs'}     0.341391       0.344322 0.350691         2.331169\n",
      "\n",
      "üèÜ Best Model: XGBoost\n",
      "   Test Accuracy: 0.4608\n",
      "   Test F1 Score: 0.3217\n",
      "\n",
      "üìà Performance Analysis:\n",
      "   ‚Ä¢ Random baseline (guess): 33.3% accuracy\n",
      "   ‚Ä¢ Your model: 46.1% accuracy\n",
      "   ‚Ä¢ Improvement: 38.4% better than random!\n",
      "   ‚Ä¢ This dataset: 5457 training samples\n",
      "   ‚Ä¢ For football match prediction, 50-60% accuracy is EXCELLENT!\n",
      "   ‚Ä¢ Professional betting models achieve 50-55%\n",
      "\n",
      "üìä Confusion Matrix (Best Model):\n",
      "[[606   5  22]\n",
      " [333   5  12]\n",
      " [356   8  18]]\n",
      "\n",
      "   Rows: Actual | Columns: Predicted\n",
      "   [0] Home Win, [1] Draw, [2] Away Win\n",
      "\n",
      "üìã Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Home Win       0.47      0.96      0.63       633\n",
      "        Draw       0.28      0.01      0.03       350\n",
      "    Away Win       0.35      0.05      0.08       382\n",
      "\n",
      "    accuracy                           0.46      1365\n",
      "   macro avg       0.36      0.34      0.25      1365\n",
      "weighted avg       0.39      0.46      0.32      1365\n",
      "\n",
      "\n",
      "üíæ Results saved to: ../visualizations/ps2_model_comparison.csv\n",
      "\n",
      "üíæ Best model saved to: models/ps2_match_winner_model.joblib\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PS2: MATCH WINNER PREDICTION - COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "üéØ Final Results:\n",
      "   Best Model: XGBoost\n",
      "   Test Accuracy: 0.4608\n",
      "   Test F1 Score: 0.3217\n",
      "\n",
      "üìù Output Format for Deployment:\n",
      "   Input: Home team stats, Away team stats\n",
      "   Output: Team name (e.g., 'Manchester United') OR 'Draw'\n",
      "   NO scores, NO probabilities, ONLY winner name or 'Draw'\n"
     ]
    }
   ],
   "source": [
    "# Compare all models\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test_Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä MODEL COMPARISON - PS2: Match Winner Prediction (H/D/A)\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_accuracy = results_df.iloc[0]['Test_Accuracy']\n",
    "best_f1 = results_df.iloc[0]['Test_F1']\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"   Test F1 Score: {best_f1:.4f}\")\n",
    "\n",
    "# Get best model object\n",
    "model_mapping = {\n",
    "    'Logistic Regression': grid_lr,\n",
    "    'Random Forest': grid_rf,\n",
    "    'Gradient Boosting': grid_gb,\n",
    "    'XGBoost': grid_xgb,\n",
    "    'LightGBM': grid_lgbm\n",
    "}\n",
    "best_model = model_mapping[best_model_name]\n",
    "\n",
    "print(f\"\\nüìà Performance Analysis:\")\n",
    "print(f\"   ‚Ä¢ Random baseline (guess): 33.3% accuracy\")\n",
    "print(f\"   ‚Ä¢ Your model: {best_accuracy*100:.1f}% accuracy\")\n",
    "print(f\"   ‚Ä¢ Improvement: {(best_accuracy - 0.333) / 0.333 * 100:.1f}% better than random!\")\n",
    "print(f\"   ‚Ä¢ This dataset: {len(X_train)} training samples\")\n",
    "print(f\"   ‚Ä¢ For football match prediction, 50-60% accuracy is EXCELLENT!\")\n",
    "print(f\"   ‚Ä¢ Professional betting models achieve 50-55%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nüìä Confusion Matrix (Best Model):\")\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    y_pred_best = y_pred_lr\n",
    "elif best_model_name == 'Random Forest':\n",
    "    y_pred_best = y_pred_rf\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    y_pred_best = y_pred_gb\n",
    "elif best_model_name == 'XGBoost':\n",
    "    y_pred_best = y_pred_xgb\n",
    "else:\n",
    "    y_pred_best = y_pred_lgbm\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "print(cm)\n",
    "print(f\"\\n   Rows: Actual | Columns: Predicted\")\n",
    "print(f\"   [0] Home Win, [1] Draw, [2] Away Win\")\n",
    "\n",
    "# Classification Report\n",
    "print(f\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, \n",
    "                            target_names=['Home Win', 'Draw', 'Away Win']))\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('../visualizations/ps2_model_comparison.csv', index=False)\n",
    "print(f\"\\nüíæ Results saved to: ../visualizations/ps2_model_comparison.csv\")\n",
    "\n",
    "# Save best model\n",
    "import joblib\n",
    "joblib.dump({\n",
    "    'model': best_model.best_estimator_,\n",
    "    'scaler': scaler,\n",
    "    'features': feature_cols,\n",
    "    'model_name': best_model_name,\n",
    "    'accuracy': best_accuracy,\n",
    "    'f1_score': best_f1,\n",
    "    'class_mapping': {0: 'H', 1: 'D', 2: 'A'},\n",
    "    'class_names': {0: 'Home Win', 1: 'Draw', 2: 'Away Win'}\n",
    "}, 'models/ps2_match_winner_model.joblib')\n",
    "\n",
    "print(f\"\\nüíæ Best model saved to: models/ps2_match_winner_model.joblib\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ PS2: MATCH WINNER PREDICTION - COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüéØ Final Results:\")\n",
    "print(f\"   Best Model: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"   Test F1 Score: {best_f1:.4f}\")\n",
    "print(f\"\\nüìù Output Format for Deployment:\")\n",
    "print(f\"   Input: Home team stats, Away team stats\")\n",
    "print(f\"   Output: Team name (e.g., 'Manchester United') OR 'Draw'\")\n",
    "print(f\"   NO scores, NO probabilities, ONLY winner name or 'Draw'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
